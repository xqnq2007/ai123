-- MySQL dump 10.13  Distrib 5.7.18, for Linux (x86_64)
--
-- Host: localhost    Database: ai123
-- ------------------------------------------------------
-- Server version	5.7.18-0ubuntu0.16.04.1

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `ai_article`
--

DROP TABLE IF EXISTS `ai_article`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `ai_article` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `title` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  `brief` varchar(50) COLLATE utf8_unicode_ci NOT NULL,
  `content` text COLLATE utf8_unicode_ci NOT NULL,
  `page` int(11) NOT NULL,
  `pub_date` datetime DEFAULT NULL,
  `last_modify` datetime NOT NULL,
  `is_raw` int(1) NOT NULL,
  `refer_url` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  `author_name` varchar(50) COLLATE utf8_unicode_ci NOT NULL,
  `author_username` varchar(50) COLLATE utf8_unicode_ci NOT NULL,
  `ai_subcate_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `ai_article_cateid` (`ai_subcate_id`),
  KEY `ai_article_authorusername` (`author_username`)
) ENGINE=InnoDB AUTO_INCREMENT=22 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `ai_article`
--

LOCK TABLES `ai_article` WRITE;
/*!40000 ALTER TABLE `ai_article` DISABLE KEYS */;
INSERT INTO `ai_article` VALUES (1,'问题由来','linear-regression-history','<h3>线性回归</h3><h4>1.1 回归由来</h4><p>FrancisGalton，英国生物学家，他研究了父母身高与子女身高之间关系后得出，若父母身高高于平均大众身高，则其子女身高倾向于倒退生长，即会比其父母身高矮一些而更接近于大众平均身高。若父母身高小于平均身高，则其子女身高倾向于向上生长，以更接近于大众平均身高。此现象，被Galton称之为回归现象，即regression。</p><h4>1.2 什么是线性回归</h4><pre><code class=\"lang-bash\">3.0000   10.0000\r\n3.1000   10.3000\r\n3.2000   10.6000\r\n3.3000   10.9000\r\n3.4000   11.2000\r\n3.5000   11.5000\r\n3.6000   11.8000\r\n3.7000   12.1000\r\n3.8000   12.4000\r\n3.9000   12.7000\r\n4.0000   13.0000\r\n4.1000   13.3000\r\n4.2000   13.6000\r\n4.3000   13.9000\r\n4.4000   14.2000\r\n4.5000   14.5000\r\n4.6000   14.8000\r\n4.7000   15.1000\r\n4.8000   15.4000\r\n4.9000   15.7000\r\n5.0000   16.0000<br></code></pre><p>如上所示，给定上面一组数，假设每一行表示一个点，即 (3,11),(3.1,10.3)...,在坐标系下画出来，如下图所示：</p><p><img alt=\"leneardata.png\" src=\"/uploads/2017/12/16/leneardata.png\" width=\"562\" height=\"421\"><br></p><p>线性回归说的就是一些数据，基本呈线性分布，前期可以这么直接地理解，说到线性，大家中学时都学过直线方程，y=kx+b，这里也一样，f(x)=wx+b所以问题的目标就是找出合适的w和b，使得对于所有的点都能尽可能落在直线上，观察上图，可以知道不存在一条能完全拟合所有点的直线，但是我们可以找到一条与数据拟合程度最好的直线，那么这条直接就能体现数据的规律，如果再给出你一个横坐标，那你就可以找出符合这个规律的纵坐标，即可以利用这个规律来作预测。<br></p>',1,'2017-12-03 14:36:00','2017-12-16 14:04:00',1,'0','wang','admin',1001),(2,'最小二乘法','linear-regression-resolution','<h3><span></span>线性回归</h3><h4>2.1 最小二乘法法求解线性回归</h4><p style=\"text-align: center;\"><span></span><img alt=\"linearregression.png\" src=\"/uploads/2017/12/17/linearregression.png\" width=\"346\" height=\"252\"><br></p><p>如上图所示，假设图中直线为最拟合数据点的那条直线，设该直线方程为：</p><p><span></span></p><p style=\"margin-left: 200px;\"><span style=\"font-size: 122%;\">y=a+bx</span></p><p></p><p>用该直线拟合数据点时，总误差为</p><p style=\"text-align: center;\"><img alt=\"屏幕快照 2017-12-17 下午3.42.22.png\" src=\"/uploads/2017/12/17/2017-12-17-34222.png\" width=\"110\" height=\"66\"><br></p><p style=\"\">由于实际值<span></span><span style=\"\"><span style=\"font-size: 122%;\">y<span></span><span style=\"font-size: 70.7%;\">i</span><span></span><span></span></span><span></span></span>y_i和由直线得到的预测值<span></span><span style=\"\"><span style=\"font-size: 122%;\">y<span></span><span style=\"font-size: 70.7%;\">i</span><span></span><span></span>^<span></span><span></span></span><span></span></span>\\hat{y_i}的差值可正可负，即实际点可能位于直线上方或下法，因为为了统一正负，将差值取平方，即：</p><p style=\"text-align: center;\"><img alt=\"屏幕快照 2017-12-17 下午3.49.59.png\" src=\"/uploads/2017/12/17/2017-12-17-34959.png\" width=\"276\" height=\"74\"></p><p style=\"\">作为总误差，如果能找到合适的a和b,使得Q值最小 ，则我们就找到了那条直线。</p><p style=\"\">为求a和b,首先给出两个基本公式：</p><p style=\"\"><img alt=\"屏幕快照 2017-12-17 下午3.53.53.png\" src=\"/uploads/2017/12/17/2017-12-17-35353.png\" width=\"790\" height=\"325\"><br><span style=\"font-size: 15.86px;\">y_i</span></p><p style=\"\"><img alt=\"屏幕快照 2017-12-17 下午3.54.11.png\" src=\"/uploads/2017/12/17/2017-12-17-35411.png\" width=\"651\" height=\"336\"><br></p><p style=\"\">下面开始利用总误差Q来求最优的a和b,</p><p style=\"\"><img alt=\"20170221092327974.png\" src=\"/uploads/2017/12/17/20170221092327974.png\" width=\"650\" height=\"516\"><br></p><p style=\"\"><img alt=\"20170221092357740.png\" src=\"/uploads/2017/12/17/20170221092357740.png\" width=\"704\" height=\"233\"><br></p><p style=\"\">推导到这里，我们可以看到后面两项是与a，b无关的，要想使Q最小，只需使</p><p style=\"\"><img alt=\"20170221092039017.jpeg\" src=\"/uploads/2017/12/17/20170221092039017.jpeg\" width=\"293\" height=\"44\"><br></p><p style=\"\">因此：</p><p style=\"\"><img alt=\"20170221092103530.jpeg\" src=\"/uploads/2017/12/17/20170221092103530.jpeg\" width=\"289\" height=\"69\"><br></p><p style=\"\">总结一下，上面的求解思路，先是找到一个误差方程式，然后想办法使这个误差最小，误差最小，也就是最优的直线，在对误差公式整理过程中，思路就是将式子中与a,b无关的项分离出来，无关的项分离出来后，再令含a,b的式子为零，这样就能求出a和b了。</p>',2,'2017-12-03 00:00:00','2017-12-17 14:06:00',1,'0','wang','admin',1001),(3,'梯度下降法','gradient-descent','<h3>线性回归</h3><h4>2.1梯度下降法</h4><p><img alt=\"1346902296_9917.png\" src=\"/uploads/2017/12/17/1346902296_9917_JgNVnu6.png\" width=\"692\" height=\"343\"><br></p><p>如上图所示，，如果站在红圈的位置，如何最快的走到山的最低点呢，可以每一步都向当前坡度最大的方向走，这个坡度最大的</p><p>方向，对应数学上，就是梯度的负方向，</p><p><img alt=\"屏幕快照 2017-12-17 下午10.39.09.png\" src=\"/uploads/2017/12/17/2017-12-17-103909.png\" width=\"632\" height=\"361\"><br></p><p>如果不理解为啥是梯度的负方向，首先可以以直线举例，比如上图的直线（请无视那些数字），如果要从高处走到最低处，肯定</p><p>是沿着斜率的方向向下走，这个方向刚好就是-k的方向，如果用k表示斜率的话，对于曲线函数 ，比如右图的曲线，从高处走到</p><p>低谷点，也是沿着当前点斜率的方向向下走，其实相对于坐标的移动来说，也就是x向左边移动，这是因为直线和上面的曲线，</p><p>都是一元函数，比如上面的曲面，则当前点的梯度其实是当前点最大的斜率，也就是最陡峭的地方，</p><p><img alt=\"屏幕快照 2017-12-17 下午10.58.20.png\" src=\"/uploads/2017/12/17/2017-12-17-105820.png\" width=\"398\" height=\"311\"><br></p><p>再比如对于上面的曲线，如果当前点为A，则</p><p style=\"text-align: center;\"><img alt=\"屏幕快照 2017-12-17 下午10.59.34.png\" src=\"/uploads/2017/12/17/2017-12-17-105934.png\" width=\"239\" height=\"98\"><br></p><p style=\"\">当x=x1时，此时斜率为负值，则减负值，为加正值，x就向右走，同时，如果x=x2，此时斜率为正，则减正值，就向左走，无论哪种</p><p style=\"\">情况，都是向最低点而去，所以说梯度下降法刚好就是走的最低点的方向。</p><p style=\"\">下面开始梯度下降法的公式推导，首先假设线性方程如下:</p><p style=\"text-align: center;\"><img alt=\"屏幕快照 2017-12-18 下午10.45.07.png\" src=\"/uploads/2017/12/18/2017-12-18-104507.png\" width=\"423\" height=\"70\"><br></p><p style=\"\">表示矩阵形式为</p><p style=\"margin-left: 40px; text-align: center;\"><img alt=\"屏幕快照 2017-12-18 下午10.45.19.png\" src=\"/uploads/2017/12/18/2017-12-18-104519.png\" width=\"399\" height=\"73\"></p><p style=\"margin-left: 40px;\">其中x0=1,则最终要求的就是最优的\\(theta_T\\)<br></p><p style=\"margin-left: 40px;\">则损失函数可表示为</p><p style=\"margin-left: 40px; text-align: center;\"><img alt=\"屏幕快照 2017-12-18 下午10.45.25.png\" src=\"/uploads/2017/12/18/2017-12-18-104525.png\" width=\"449\" height=\"87\"><br></p><p style=\"margin-left: 40px;\">根据之前的分析，即要想取极小值，就要向梯度的反向走，即更新公式：</p><p style=\"margin-left: 40px; text-align: center;\"><img alt=\"屏幕快照 2017-12-18 下午10.45.33.png\" src=\"/uploads/2017/12/18/2017-12-18-104533.png\" width=\"319\" height=\"89\"><br></p><p style=\"margin-left: 40px;\">其中：</p><p style=\"margin-left: 40px;\"><img alt=\"屏幕快照 2017-12-18 下午10.45.43.png\" src=\"/uploads/2017/12/18/2017-12-18-104543_abq1MQ3.png\" width=\"720\" height=\"452\"><br></p><p style=\"margin-left: 40px;\">所以：</p><p style=\"margin-left: 40px;\"><img alt=\"屏幕快照 2017-12-18 下午10.45.48.png\" src=\"/uploads/2017/12/18/2017-12-18-104548.png\" width=\"651\" height=\"100\"><br></p><p style=\"margin-left: 40px;\">如果有m个样本，则求导时要加上求和符号：</p><p style=\"margin-left: 40px;\"><img alt=\"屏幕快照 2017-12-18 下午10.45.58.png\" src=\"/uploads/2017/12/18/2017-12-18-104558.png\" width=\"564\" height=\"86\"><br></p><p style=\"margin-left: 40px;\">初始时ΘT可设为零向量，然后用上式迭代计算向量中的每个参数，直到收敛，这种求解方法由于每次迭代时用了整个样本集，所以</p><p style=\"margin-left: 40px;\">称为批量梯度下降算法。如果每次只选取一个样本进行更新，则称为随机梯度下降算法。更新公式如下：</p><p style=\"margin-left: 40px;\"><img alt=\"屏幕快照 2017-12-18 下午11.06.18.png\" src=\"/uploads/2017/12/18/2017-12-18-110618.png\" width=\"909\" height=\"322\"><br></p><h5><span style=\"font-size: small;\">即每次读取一条样本，就迭代对ΘT进行更新，然后判断其是否收敛，若没收敛，则继续读取样本进行处理，如果所有样本都读取完毕了，则循环重新从头开始读取样本进行处理。这样迭代一次的算法复杂度为O(n)。对于大数据集，很有可能只需读取一小部分数据，函数J(Θ)就收敛了。比如样本集数据量为100万，有可能读取几千条或几万条时，函数就达到了收敛值。所以当数据量很大时，更倾向于选择随机梯度下降算法。但是，相较于批量梯度下降算法而言，随机梯度下降算法使得J(Θ)趋近于最小值的速度更快，但是有可能造成永远不可能收敛于最小值，有可能一直会在最小值周围震荡，但是实践中，大部分值都能够接近于最小值，效果也都还不错。</span></h5><p><br></p><h5><br></h5>',3,'2017-12-17 14:35:00','2017-12-18 15:09:22',1,'0','wang','admin',1001),(4,'矩阵法','linear-regression-matrix','<p>矩阵法求解线性回归<br></p><p>由于梯度下降算法需要多次迭代，并且需要指定下降速率，如果下降速度过快则可能错过最优点，如果过慢则需要迭代多次，因此还可选用矩阵法求解。首先给出一些基本数学知识：矩阵的迹trace为矩阵主对角线元素之和：<br></p><p style=\"text-align: center;\"><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_rieKCMh.png\" width=\"128\" height=\"80\"><br></p><p style=\"\">首先给出一些基本数学知识：矩阵的迹trace为矩阵主对角线元素之和：<br></p><p style=\"text-align: center;\"><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_lKa8qUW.png\" width=\"128\" height=\"80\"><br></p><p style=\"\">tr(a)=a ,如果a为实数以下是关于矩阵迹的一些性质：</p><p style=\"text-align: center;\"><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_ZEu1g00.png\" width=\"442\" height=\"345\"></p><p style=\"\">对于多元线性回归，将所有训练数据作为一个矩阵，多元线性回归，也就是多个自变量的线性方程，类似y=a1x1+a2x2+a3x3...：<br></p><p style=\"text-align: center;\"><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_bBCWoJB.png\" width=\"205\" height=\"125\"><br></p><p style=\"\">将y值也作为一个矩阵：<br></p><p style=\"text-align: center;\"><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_3dFFeyG.png\" width=\"117\" height=\"114\"><br></p><p style=\"\">则可得<img alt=\"image.png\" src=\"/uploads/2017/12/21/image_uYrzwpk.png\" width=\"157\" height=\"44\"><br></p><p style=\"\">则误差为：</p><p style=\"\"></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_9IzYFPQ.png\" width=\"336\" height=\"185\">转变为平方后：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_L4eNFdl.png\" width=\"412\" height=\"109\"></p><p>其中转变为平方主要为了统一为正值，前面乘以1/2是方便求导后的计算。对J(θ)求导<img alt=\"image.png\" src=\"/uploads/2017/12/21/image_74JDi7Z.png\" width=\"477\" height=\"256\"></p><p>其中用到上面的求迹公式，以及求导公式，令上式为0，</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_BLkVKu9.png\" width=\"188\" height=\"101\"></p><p>则可求出最优的系数，矩阵方求解相对简单，不需要多次迭代，但当数据量过大时，即设计矩阵X过大时，对矩阵的乘法即求逆有很大计算复杂度，因此此方法适用于小规模数据。另外，用矩阵法时不需要对输入特征数据中心化。</p>',4,'2017-12-19 13:29:00','2017-12-21 14:05:41',1,'0','wang','admin',1001),(5,'逻辑回归由来','logistic-regression-history','<h3>逻辑回归</h3><h4>1.1 回归由来</h4><p>逻辑回归是将数据拟合到一个logit函数(或者叫做logistic函数)中，从而能够完成对事件发生的概率进行预测，也就是将无界的数据拟合到0-1之间，因为logit函数的取值范围是0-1。<br></p><p>要说逻辑回归，我们得追溯到线性回归，想必大家对线性回归都有一定的了解，即对于多维空间中存在的样本点，我们用特征的线性组合去拟合空间中点的分布和轨迹。如下图所示：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_tXdXCn6.png\" width=\"500\" height=\"399.57716701902746\"><br></p><p>线性回归能对连续值结果进行预测，而现实生活中常见的另外一类问题是，分类问题。最简单的情况是是与否的二分类问题。比如说医生需要判断病人是否生病，银行要判断一个人的信用程度是否达到可以给他发信用卡的程度，邮件收件箱要自动对邮件分类为正常邮件和垃圾邮件等等。&nbsp;&nbsp;&nbsp;&nbsp;当然，我们最直接的想法是，既然能够用线性回归预测出连续值结果，那根据结果设定一个阈值是不是就可以解决这个问题了呢？事实是，对于很标准的情况，确实可以的，这里我们套用Andrew Ng老师的课件中的例子，下图中X为数据点肿瘤的大小，Y为观测结果是否是恶性肿瘤。通过构建线性回归模型，如hθ(x)所示，构建线性回归模型后，我们设定一个阈值0.5，预测hθ(x)≥0.5的这些点为恶性肿瘤，而hθ(x)&lt;0.5为良性肿瘤。<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_hAzUBDL.png\" width=\"500\" height=\"197.16494845360825\"><br></p><p>但很多实际的情况下，我们需要学习的分类数据并没有这么精准，比如说上述例子中突然有一个不按套路出牌的数据点出现，如下图所示：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_GY626PI.png\" width=\"500\" height=\"210.74380165289256\"><br></p><p>你看，现在你再设定0.5，这个判定阈值就失效了，而现实生活的分类问题的数据，会比例子中这个更为复杂，而这个时候我们借助于线性回归+阈值的方式，已经很难完成一个鲁棒性很好的分类器了。&nbsp;&nbsp;&nbsp;&nbsp;在这样的场景下，逻辑回归就诞生了。它的核心思想是，如果线性回归的结果输出是一个连续值，而值的范围是无法限定的，那我们有没有办法把这个结果值映射为可以帮助我们判断的结果呢。而如果输出结果是 (0,1) 的一个概率值，这个问题就很清楚了。我们在数学上找了一圈，还真就找着这样一个简单的函数了，就是很神奇的sigmoid函数(如下)：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_xQMK2Om.png\" width=\"150\" height=\"65.59322033898304\"><br></p><p>如果把sigmoid函数图像画出来，是如下的样子：<br></p><p><br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_Qfqs41T.png\" width=\"350\" height=\"222.4887556221889\"><br></p><p>&nbsp;从函数图上可以看出，函数y=g(z)在z=0的时候取值为1/2，而随着z逐渐变小，函数值趋于0，z逐渐变大的同时函数值逐渐趋于1，而这正是一个概率的范围。&nbsp;&nbsp;&nbsp;&nbsp;所以我们定义线性回归的预测函数为Y=WTX，那么逻辑回归的输出Y=&nbsp;g(WTX)，其中y=g(z)函数正是上述sigmoid函数(或者简单叫做S形函数)。<br></p>',1,'2017-12-21 14:06:00','2017-12-21 14:21:14',0,'http://blog.csdn.net/han_xiaoyang/article/details/49123419','寒小阳 && 龙心尘','admin',1002),(6,'代价函数与梯度下降','logistic-regression-costfunction','<p>我们通过对判定边界的说明，知道会有合适的参数θ使得θTx=0成为很好的分类判定边界，那么问题就来了，我们如何判定我们的参数θ是否合适，有多合适呢？更进一步，我们有没有办法去求得这样的合适参数θ呢？&nbsp;&nbsp;&nbsp;&nbsp;这就是我们要提到的代价函数与梯度下降了。&nbsp;&nbsp;&nbsp;&nbsp;所谓的代价函数Cost Function，其实是一种衡量我们在这组参数下预估的结果和实际结果差距的函数，比如说线性回归的代价函数定义为:<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_730AmOl.png\" width=\"150\" height=\"43.82716049382716\"><br></p><p>当然我们可以和线性回归类比得到一个代价函数，实际就是上述公式中hθ(x)取为逻辑回归中的g(θTx)，但是这会引发代价函数为“非凸”函数的问题，简单一点说就是这个函数有很多个局部最低点，如下图所示：<br></p><p><img alt=\"屏幕快照 2017-12-21 下午10.24.37.png\" src=\"/uploads/2017/12/21/2017-12-21-102437.png\" width=\"411\" height=\"227\"><br></p><p>而我们希望我们的代价函数是一个如下图所示，碗状结构的凸函数，这样我们算法求解到局部最低点，就一定是全局最小值点。<br></p><p><img alt=\"Image\" src=\"http://52opencourse.com/?qa=blob&amp;qa_blobid=847516551720124317\" width=\"355\" height=\"245\"><br></p><p>因此，上述的Cost Function对于逻辑回归是不可行的，我们需要其他形式的Cost Function来保证逻辑回归的成本函数是凸函数。&nbsp; &nbsp; &nbsp; 我们跳过大量的数学推导，直接出结论了，我们找到了一个适合逻辑回归的代价函数:<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/21/image_qqYZSAX.png\" width=\"200\" height=\"36.75417661097852\"><br></p><p>Andrew Ng老师解释了一下这个代价函数的合理性，我们首先看当y=1的情况：<br></p><p><img alt=\"下载.png\" src=\"/uploads/2017/12/21/ofarni.png\" width=\"329\" height=\"300\"><br></p><p>如果我们的类别y = 1, 而判定的hθ(x)=1，则Cost = 0，此时预测的值和真实的值完全相等，代价本该为0；而如果判断hθ(x)→0，代价-&gt;∞，这很好地惩罚了最后的结果。&nbsp; &nbsp; &nbsp; &nbsp;而对于y=0的情况，如下图所示，也同样合理：<br></p><p><img alt=\"下载 (1).png\" src=\"/uploads/2017/12/22/1.png\" width=\"343\" height=\"325\"><br></p><p>下面我们说说梯度下降，梯度下降算法是调整参数θ使得代价函数J(θ)取得最小值的最基本方法之一。从直观上理解，就是我们在碗状结构的凸函数上取一个初始值，然后挪动这个值一步步靠近最低点的过程，如下图所示：<br></p><p><img alt=\"20151014125344499 (2).png\" src=\"/uploads/2017/12/22/20151014125344499-2.png\" width=\"405\" height=\"417\"><br></p><p>我们先简化一下逻辑回归的代价函数：<br></p><p><img alt=\"下载 (4).png\" src=\"/uploads/2017/12/22/4.png\" width=\"827\" height=\"165\"><br></p><p>&nbsp;从数学上理解，我们为了找到最小值点，就应该朝着下降速度最快的方向(导函数/偏导方向)迈进，每次迈进一小步，再看看此时的下降最快方向是哪，再朝着这个方向迈进，直至最低点。&nbsp; &nbsp; &nbsp; &nbsp;用迭代公式表示出来的最小化J(θ)的梯度下降算法如下：<br></p><p><img alt=\"下载 (5).png\" src=\"/uploads/2017/12/22/5.png\" width=\"693\" height=\"262\"></p><p><img alt=\"下载 (6).png\" src=\"/uploads/2017/12/22/6.png\" width=\"585\" height=\"185\"><br></p>',2,'2017-12-21 14:21:00','2017-12-22 00:03:24',1,'0','wang','admin',1002),(7,'代码与实现','logistic-code','<p>我们来一起看两个具体数据上做逻辑回归分类的例子，其中一份数据为线性判定边界，另一份为非线性。&nbsp;&nbsp;&nbsp;&nbsp;示例1。&nbsp;&nbsp;&nbsp;&nbsp;第一份数据为data1.txt，部分内容如下：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/22/image.png\" width=\"538\" height=\"616\"><br></p><p>我们先来看看数据在空间的分布，代码如下。<br></p><pre><code class=\"lang-python\">from&nbsp;numpy&nbsp;import&nbsp;loadtxt,&nbsp;where&nbsp;&nbsp;\r\nfrom&nbsp;pylab&nbsp;import&nbsp;scatter,&nbsp;show,&nbsp;legend,&nbsp;xlabel,&nbsp;ylabel&nbsp;&nbsp;\r\n&nbsp;&nbsp;\r\n#load&nbsp;the&nbsp;dataset&nbsp;&nbsp;\r\ndata&nbsp;=&nbsp;loadtxt(’/home/HanXiaoyang/data/data1.txt’,&nbsp;delimiter=‘,’)&nbsp;&nbsp;\r\n&nbsp;&nbsp;\r\nX&nbsp;=&nbsp;data[:,&nbsp;0:2]&nbsp;&nbsp;\r\ny&nbsp;=&nbsp;data[:,&nbsp;2]&nbsp;&nbsp;\r\n&nbsp;&nbsp;\r\npos&nbsp;=&nbsp;where(y&nbsp;==&nbsp;1)&nbsp;&nbsp;\r\nneg&nbsp;=&nbsp;where(y&nbsp;==&nbsp;0)&nbsp;&nbsp;\r\nscatter(X[pos,&nbsp;0],&nbsp;X[pos,&nbsp;1],&nbsp;marker=‘o’,&nbsp;c=‘b’)&nbsp;&nbsp;\r\nscatter(X[neg,&nbsp;0],&nbsp;X[neg,&nbsp;1],&nbsp;marker=‘x’,&nbsp;c=‘r’)&nbsp;&nbsp;\r\nxlabel(’Feature1/Exam&nbsp;1&nbsp;score’)&nbsp;&nbsp;\r\nylabel(’Feature2/Exam&nbsp;2&nbsp;score’)&nbsp;&nbsp;\r\nlegend([’Fail’,&nbsp;‘Pass’])&nbsp;&nbsp;\r\nshow()&nbsp;&nbsp;<br></code></pre><p>得到的结果如下：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/22/image_zY0YeIN.png\" width=\"500\" height=\"381.44329896907215\"><br></p><p>下面我们写好计算sigmoid函数、代价函数、和梯度下降的程序：<br></p><pre><code>def&nbsp;sigmoid(X):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;””’Compute&nbsp;sigmoid&nbsp;function&nbsp;”’&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;den&nbsp;=1.0+&nbsp;e&nbsp;**(-1.0*&nbsp;X)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;gz&nbsp;=1.0/&nbsp;den&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;gz&nbsp;&nbsp;\r\ndef&nbsp;compute_cost(theta,X,y):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;””’computes&nbsp;cost&nbsp;given&nbsp;predicted&nbsp;and&nbsp;actual&nbsp;values”’&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;m&nbsp;=&nbsp;X.shape[0]#number&nbsp;of&nbsp;training&nbsp;examples&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;theta&nbsp;=&nbsp;reshape(theta,(len(theta),1))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;J&nbsp;=(1./m)*(-transpose(y).dot(log(sigmoid(X.dot(theta))))-&nbsp;transpose(1-y).dot(log(1-sigmoid(X.dot(theta)))))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;grad&nbsp;=&nbsp;transpose((1./m)*transpose(sigmoid(X.dot(theta))-&nbsp;y).dot(X))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#optimize.fmin&nbsp;expects&nbsp;a&nbsp;single&nbsp;value,&nbsp;so&nbsp;cannot&nbsp;return&nbsp;grad&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;J[0][0]#,grad&nbsp;&nbsp;\r\ndef&nbsp;compute_grad(theta,&nbsp;X,&nbsp;y):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;””’compute&nbsp;gradient”’&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;theta.shape&nbsp;=(1,3)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;grad&nbsp;=&nbsp;zeros(3)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;h&nbsp;=&nbsp;sigmoid(X.dot(theta.T))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;delta&nbsp;=&nbsp;h&nbsp;-&nbsp;y&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;l&nbsp;=&nbsp;grad.size&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(l):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sumdelta&nbsp;=&nbsp;delta.T.dot(X[:,&nbsp;i])&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grad[i]=(1.0/&nbsp;m)*&nbsp;sumdelta&nbsp;*-1&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;theta.shape&nbsp;=(3,)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;&nbsp;grad&nbsp;&nbsp;\r\n</code></pre><p><br></p><p>我们用梯度下降算法得到的结果判定边界是如下的样子：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/22/image_toAVLBN.png\" width=\"500\" height=\"378.29457364341084\"><br></p><p>最后我们使用我们的判定边界对training data做一个预测，然后比对一下准确率：<br></p><pre><code>def&nbsp;predict(theta,&nbsp;X):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;””’Predict&nbsp;label&nbsp;using&nbsp;learned&nbsp;logistic&nbsp;regression&nbsp;parameters”’&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;m,&nbsp;n&nbsp;=&nbsp;X.shape&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;p&nbsp;=&nbsp;zeros(shape=(m,1))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;h&nbsp;=&nbsp;sigmoid(X.dot(theta.T))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;it&nbsp;in&nbsp;range(0,&nbsp;h.shape[0]):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;h[it]&gt;0.5:&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p[it,0]=1&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p[it,0]=0&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;p&nbsp;&nbsp;\r\n#Compute&nbsp;accuracy&nbsp;on&nbsp;our&nbsp;training&nbsp;set&nbsp;&nbsp;\r\np&nbsp;=&nbsp;predict(array(theta),&nbsp;it)&nbsp;&nbsp;\r\nprint‘Train&nbsp;Accuracy:&nbsp;%f’%((y[where(p&nbsp;==&nbsp;y)].size&nbsp;/&nbsp;float(y.size))*100.0)&nbsp;&nbsp;\r\n<br></code></pre><p><br></p><p>计算出来的结果是89.2%<br></p><p>示例2.&nbsp;&nbsp;&nbsp;&nbsp;第二份数据为data2.txt，部分内容如下：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/22/image_ONYwqZ2.png\" width=\"290\" height=\"684\"><br></p><p>我们同样把数据的分布画出来，如下：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/22/image_PyvJgR8.png\" width=\"500\" height=\"346.6299862448418\"><br></p><p>我们发现在这个例子中，我们没有办法再用一条直线把两类样本点近似分开了，所以我们打算试试多项式的判定边界，那么我们先要对给定的两个feature做一个多项式特征的映射。比如说，我们做了如下的一个映射：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/22/image_3aMFn4L.png\" width=\"300\" height=\"276.3157894736842\"><br></p><p>代码如下：<br></p><pre><code>def&nbsp;map_feature(x1,&nbsp;x2):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;””’&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;Maps&nbsp;the&nbsp;two&nbsp;input&nbsp;features&nbsp;to&nbsp;polonomial&nbsp;features.&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;Returns&nbsp;a&nbsp;new&nbsp;feature&nbsp;array&nbsp;with&nbsp;more&nbsp;features&nbsp;of&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;X1,&nbsp;X2,&nbsp;X1&nbsp;**&nbsp;2,&nbsp;X2&nbsp;**&nbsp;2,&nbsp;X1*X2,&nbsp;X1*X2&nbsp;**&nbsp;2,&nbsp;etc…&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;”’&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;x1.shape&nbsp;=(x1.size,1)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;x2.shape&nbsp;=(x2.size,1)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;degree&nbsp;=6&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;mapped_fea&nbsp;=&nbsp;ones(shape=(x1[:,0].size,1))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;m,&nbsp;n&nbsp;=&nbsp;mapped_fea.shape&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;degree&nbsp;+1):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;j&nbsp;in&nbsp;range(i&nbsp;+1):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r&nbsp;=(x1&nbsp;**(i&nbsp;-&nbsp;j))*(x2&nbsp;**&nbsp;j)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mapped_fea&nbsp;=&nbsp;append(&lt;span&nbsp;style=”font-family:&nbsp;Arial,&nbsp;Helvetica,&nbsp;sans-serif;”&gt;mapped_fea&lt;/span&gt;&lt;span&nbsp;style=“font-family:&nbsp;Arial,&nbsp;Helvetica,&nbsp;sans-serif;”&gt;,&nbsp;r,&nbsp;axis=1)&lt;/span&gt;&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;mapped_fea&nbsp;&nbsp;\r\nmapped_fea&nbsp;=&nbsp;map_feature(X[:,0],&nbsp;X[:,1])&nbsp;&nbsp;<br></code></pre><p>接着做梯度下降：<br></p><pre><code>def&nbsp;cost_function_reg(theta,&nbsp;X,&nbsp;y,&nbsp;l):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;””’Compute&nbsp;the&nbsp;cost&nbsp;and&nbsp;partial&nbsp;derivatives&nbsp;as&nbsp;grads&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;”’&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;h&nbsp;=&nbsp;sigmoid(X.dot(theta))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;thetaR&nbsp;=&nbsp;theta[1:,0]&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;J&nbsp;=(1.0/&nbsp;m)*((-y.T.dot(log(h)))-((1-&nbsp;y.T).dot(log(1.0-&nbsp;h))))&nbsp;\\&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+(l&nbsp;/(2.0*&nbsp;m))*(thetaR.T.dot(thetaR))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;delta&nbsp;=&nbsp;h&nbsp;-&nbsp;y&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;sum_delta&nbsp;=&nbsp;delta.T.dot(X[:,1])&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;grad1&nbsp;=(1.0/&nbsp;m)*&nbsp;sumdelta&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;XR&nbsp;=&nbsp;X[:,1:X.shape[1]]&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;sum_delta&nbsp;=&nbsp;delta.T.dot(XR)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;grad&nbsp;=(1.0/&nbsp;m)*(sum_delta&nbsp;+&nbsp;l&nbsp;*&nbsp;thetaR)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;out&nbsp;=&nbsp;zeros(shape=(grad.shape[0],&nbsp;grad.shape[1]+1))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;out[:,0]=&nbsp;grad1&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;out[:,1:]=&nbsp;grad&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;J.flatten(),&nbsp;out.T.flatten()&nbsp;&nbsp;\r\nm,&nbsp;n&nbsp;=&nbsp;X.shape&nbsp;&nbsp;\r\ny.shape&nbsp;=(m,1)&nbsp;&nbsp;\r\nit&nbsp;=&nbsp;map_feature(X[:,0],&nbsp;X[:,1])&nbsp;&nbsp;\r\n#Initialize&nbsp;theta&nbsp;parameters&nbsp;&nbsp;\r\ninitial_theta&nbsp;=&nbsp;zeros(shape=(it.shape[1],1))&nbsp;&nbsp;\r\n#Use&nbsp;regularization&nbsp;and&nbsp;set&nbsp;parameter&nbsp;lambda&nbsp;to&nbsp;1&nbsp;&nbsp;\r\nl&nbsp;=1&nbsp;&nbsp;\r\n#&nbsp;Compute&nbsp;and&nbsp;display&nbsp;initial&nbsp;cost&nbsp;and&nbsp;gradient&nbsp;for&nbsp;regularized&nbsp;logistic&nbsp;&nbsp;\r\n#&nbsp;regression&nbsp;&nbsp;\r\ncost,&nbsp;grad&nbsp;=&nbsp;cost_function_reg(initial_theta,&nbsp;it,&nbsp;y,&nbsp;l)&nbsp;&nbsp;\r\ndef&nbsp;decorated_cost(theta):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;cost_function_reg(theta,&nbsp;it,&nbsp;y,&nbsp;l)&nbsp;&nbsp;\r\nprint&nbsp;fmin_bfgs(decorated_cost,&nbsp;initial_theta,&nbsp;maxfun=500)&nbsp;&nbsp;\r\n<br></code></pre><p>接着在数据点上画出判定边界：<br></p><pre><code>#Plot&nbsp;Boundary&nbsp;&nbsp;\r\nu&nbsp;=&nbsp;linspace(-1,1.5,50)&nbsp;&nbsp;\r\nv&nbsp;=&nbsp;linspace(-1,1.5,50)&nbsp;&nbsp;\r\nz&nbsp;=&nbsp;zeros(shape=(len(u),&nbsp;len(v)))&nbsp;&nbsp;\r\nfor&nbsp;i&nbsp;in&nbsp;range(len(u)):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;j&nbsp;in&nbsp;range(len(v)):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;z[i,&nbsp;j]=(map_feature(array(u[i]),&nbsp;array(v[j])).dot(array(theta)))&nbsp;&nbsp;\r\nz&nbsp;=&nbsp;z.T&nbsp;&nbsp;\r\ncontour(u,&nbsp;v,&nbsp;z)&nbsp;&nbsp;\r\ntitle(’lambda&nbsp;=&nbsp;%f’%&nbsp;l)&nbsp;&nbsp;\r\nxlabel(’Microchip&nbsp;Test&nbsp;1’)&nbsp;&nbsp;\r\nylabel(’Microchip&nbsp;Test&nbsp;2’)&nbsp;&nbsp;\r\nlegend([’y&nbsp;=&nbsp;1’,‘y&nbsp;=&nbsp;0’,‘Decision&nbsp;boundary’])&nbsp;&nbsp;\r\nshow()&nbsp;&nbsp;\r\ndef&nbsp;predict(theta,&nbsp;X):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;””’Predict&nbsp;whether&nbsp;the&nbsp;label&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;0&nbsp;or&nbsp;1&nbsp;using&nbsp;learned&nbsp;logistic&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;regression&nbsp;parameters&nbsp;”’&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;m,&nbsp;n&nbsp;=&nbsp;X.shape&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;p&nbsp;=&nbsp;zeros(shape=(m,1))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;h&nbsp;=&nbsp;sigmoid(X.dot(theta.T))&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;it&nbsp;in&nbsp;range(0,&nbsp;h.shape[0]):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;h[it]&gt;0.5:&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p[it,0]=1&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p[it,0]=0&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;p&nbsp;&nbsp;\r\n#%&nbsp;Compute&nbsp;accuracy&nbsp;on&nbsp;our&nbsp;training&nbsp;set&nbsp;&nbsp;\r\np&nbsp;=&nbsp;predict(array(theta),&nbsp;it)&nbsp;&nbsp;\r\nprint‘Train&nbsp;Accuracy:&nbsp;%f’%((y[where(p&nbsp;==&nbsp;y)].size&nbsp;/&nbsp;float(y.size))*100.0)&nbsp;&nbsp;<br></code></pre><p>得到的结果如下图所示：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/22/image_O5Wjmwx.png\" width=\"500\" height=\"396.2406015037594\"><br></p><p>&nbsp;我们发现我们得到的这条曲线确实将两类点区分开来了。<br></p>',3,'2017-12-22 00:03:00','2017-12-22 00:17:58',0,'http://blog.csdn.net/u010480899/article/details/52807684','wang','admin',1002),(8,'总结','logistic-summary','<p>最后我们总结一下逻辑回归。它始于输出结果为有实际意义的连续值的线性回归，但是线性回归对于分类的问题没有办法准确而又具备鲁棒性地分割，因此我们设计出了逻辑回归这样一个算法，它的输出结果表征了某个样本属于某类别的概率。&nbsp; &nbsp; &nbsp; &nbsp;逻辑回归的成功之处在于，将原本输出结果范围可以非常大的θTX&nbsp;通过sigmoid函数映射到(0,1)，从而完成概率的估测。&nbsp; &nbsp; &nbsp; &nbsp; 而直观地在二维空间理解逻辑回归，是sigmoid函数的特性，使得判定的阈值能够映射为平面的一条判定边界，当然随着特征的复杂化，判定边界可能是多种多样的样貌，但是它能够较好地把两类样本点分隔开，解决分类问题。&nbsp; &nbsp; &nbsp; &nbsp;求解逻辑回归参数的传统方法是梯度下降，构造为凸函数的代价函数后，每次沿着偏导方向(下降速度最快方向)迈进一小部分，直至N次迭代后到达最低点。<br></p><p>&nbsp;本文的2份数据可在<a href=\"http://pan.baidu.com/s/1pKxJl1p\">http://pan.baidu.com/s/1pKxJl1p</a>上下载到，分别为data1.txt和data2.txt，欢迎大家自己动手尝试。&nbsp; &nbsp; &nbsp; 关于逻辑回归的完整ipython notebook示例代码可以在我的github上(<a href=\"https://github.com/HanXiaoyang/ML_examples/tree/master/logistic_regression\">https://github.com/HanXiaoyang/ML_examples/tree/master/logistic_regression</a>)下载到，欢迎指正。<br></p>',4,'2017-12-22 00:18:00','2017-12-22 00:19:51',0,'http://blog.csdn.net/u010480899/article/details/52807684','寒小阳 && 龙心尘','admin',1002),(9,'决策树由来','decesion-tree-history','<h3>决策树由来</h3><p>通俗来说，决策树分类的思想类似于找对象。现想象一个女孩的母亲要给这个女孩介绍男朋友，于是有了下面的对话：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 女儿：多大年纪了？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 母亲：26。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 女儿：长的帅不帅？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 母亲：挺帅的。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 女儿：收入高不？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 母亲：不算很高，中等情况。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 女儿：是公务员不？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 母亲：是，在税务局上班呢。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 女儿：那好，我去见见。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这个女孩的决策过程就是典型的分类树决策。相当于通过年龄、长相、收入和是否公务员对将男人分为两个类别：见和不见。假设这个女孩对男人的要求是：30岁以下、长相中等以上并且是高收入者或中等以上收入的公务员，那么这个可以用下图表示女孩的决策逻辑<br></p><p><img alt=\"屏幕快照 2017-12-25 上午7.27.58.png\" src=\"/uploads/2017/12/25/2017-12-25-72758.png\" width=\"500\" height=\"459.11528150134046\"><br></p><p>上图完整表达了这个女孩决定是否见一个约会对象的策略，其中绿色节点表示判断条件，橙色节点表示决策结果，箭头表示在一个判断条件在不同情况下的决策路径，图中红色箭头表示了上面例子中女孩的决策过程。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这幅图基本可以算是一颗决策树，说它“基本可以算”是因为图中的判定条件没有量化，如收入高中低等等，还不能算是严格意义上的决策树，如果将所有条件量化，则就变成真正的决策树了。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 有了上面直观的认识，我们可以正式定义决策树了：<br></p><p>决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 可以看到，决策树的决策过程非常直观，容易被人理解。目前决策树已经成功运用于医学、制造产业、天文学、分支生物学以及商业等诸多领域。知道了决策树的定义以及其应用方法，下面介绍决策树的构造算法。<br></p>',1,'2017-12-24 23:20:00','2017-12-24 23:29:11',1,'0','wang','admin',1003),(10,'决策树构造','decesion-tree-build','<h3>决策树构造</h3><p>决策树的构造过程不依赖领域知识，它使用属性选择度量来选择将元组最好地划分成不同的类的属性。所谓决策树的构造就是进行属性选择度量确定各个特征属性之间的拓扑结构。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 构造决策树的关键步骤是分裂属性。所谓分裂属性就是在某个节点处按照某一特征属性的不同划分构造不同的分支，其目标是让各个分裂子集尽可能地“纯”。尽可能“纯”就是尽量让一个分裂子集中待分类项属于同一类别。分裂属性分为三种不同的情况：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1、属性是离散值且不要求生成二叉决策树。此时用属性的每一个划分作为一个分支。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2、属性是离散值且要求生成二叉决策树。此时使用属性划分的一个子集进行测试，按照“属于此子集”和“不属于此子集”分成两个分支。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3、属性是连续值。此时确定一个值作为分裂点split_point，按照&gt;split_point和&lt;=split_point生成两个分支。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 构造决策树的关键性内容是进行属性选择度量，属性选择度量是一种选择分裂准则，是将给定的类标记的训练集合的数据划分D“最好”地分成个体类的启发式方法，它决定了拓扑结构及分裂点split_point的选择。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 属性选择度量算法有很多，一般使用自顶向下递归分治法，并采用不回溯的贪心策略。这里介绍ID3和C4.5两种常用算法。<br></p><h4>ID3算法</h4><p>&nbsp;从信息论知识中我们直到，期望信息越小，信息增益越大，从而纯度越高。所以ID3算法的核心思想就是以信息增益度量属性选择，选择分裂后信息增益最大的属性进行分裂。下面先定义几个要用到的概念。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 设D为用类别对训练元组进行的划分，则D的熵（entropy）表示为：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image.png\" width=\"208\" height=\"51\"><br></p><p>其中pi表示第i个类别在整个训练元组中出现的概率，可以用属于此类别元素的数量除以训练元组元素总数量作为估计。熵的实际意义表示是D中元组的类标号所需要的平均信息量。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 现在我们假设将训练元组D按属性A进行划分，则A对D划分的期望信息为：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_Z1fsr5O.png\" width=\"236\" height=\"53\"><br></p><p>而信息增益即为两者的差值：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_NWueOwf.png\" width=\"250\" height=\"18\"><br></p><p>&nbsp;ID3算法就是在每次需要分裂时，计算每个属性的增益率，然后选择增益率最大的属性进行分裂。下面我们继续用SNS社区中不真实账号检测的例子说明如何使用ID3算法构造决策树。为了简单起见，我们假设训练集合包含10个元素：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午7.36.25.png\" src=\"/uploads/2017/12/25/2017-12-25-73625.png\" width=\"697\" height=\"505\"><br></p><p>其中s、m和l分别表示小、中和大。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 设L、F、H和R表示日志密度、好友密度、是否使用真实头像和账号是否真实，下面计算各属性的信息增益。<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_ffvJyhW.png\" width=\"592\" height=\"75\"><br></p><p>&nbsp;因此日志密度的信息增益是0.276。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 用同样方法得到H和F的信息增益分别为0.033和0.553。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 因为F具有最大的信息增益，所以第一次分裂选择F为分裂属性，分裂后的结果如下图表示：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午7.37.18.png\" src=\"/uploads/2017/12/25/2017-12-25-73718.png\" width=\"632\" height=\"604\"><br></p><p>在上图的基础上，再递归使用这个方法计算子节点的分裂属性，最终就可以得到整个决策树。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 上面为了简便，将特征属性离散化了，其实日志密度和好友密度都是连续的属性。对于特征属性为连续值，可以如此使用ID3算法：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 先将D中元素按照特征属性排序，则每两个相邻元素的中间点可以看做潜在分裂点，从第一个潜在分裂点开始，分裂D并计算两个集合的期望信息，具有最小期望信息的点称为这个属性的最佳分裂点，其信息期望作为此属性的信息期望。<br></p><h4>C4.5算法</h4><p>ID3算法存在一个问题，就是偏向于多值属性，例如，如果存在唯一标识属性ID，则ID3会选择它作为分裂属性，这样虽然使得划分充分纯净，但这种划分对分类几乎毫无用处。ID3的后继算法C4.5使用增益率（gain ratio）的信息增益扩充，试图克服这个偏倚。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; C4.5算法首先定义了“分裂信息”，其定义可以表示成：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_sHmzxRf.png\" width=\"303\" height=\"53\"><br></p><p>其中各符号意义与ID3算法相同，然后，增益率被定义为：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_9FQtalK.png\" width=\"240\" height=\"43\"><br></p><p>&nbsp;C4.5选择具有最大增益率的属性作为分裂属性，其具体应用与ID3类似，不再赘述。<br></p>',2,'2017-12-24 23:29:00','2017-12-24 23:39:26',1,'0','wang','admin',1003),(11,'支持向量机一','support-vector-machine-1','<h3>支持向量机一</h3><p>首先给出一个非常非常简单的分类问题（线性可分），我们要用一条直线，将下图中黑色的点和白色的点分开，很显然，图上的这条直线就是我们要求的直线之一（可以有无数条这样的直线）&nbsp;</p><p>&nbsp;<img alt=\"屏幕快照 2017-12-25 上午7.47.42.png\" src=\"/uploads/2017/12/25/2017-12-25-74742.png\" width=\"390\" height=\"316\"><br></p><p>&nbsp; 假如说，我们令黑色的点 = -1， 白色的点 =&nbsp; +1，直线f(x) = w.x + b，这儿的x、w是向量，其实写成这种形式也是等价的f(x) = w1x1 + w2x2 … + wnxn + b, 当向量x的维度=2的时候，f(x) 表示二维空间中的一条直线， 当x的维度=3的时候，f(x) 表示3维空间中的一个平面，当x的维度=n &gt; 3的时候，表示n维空间中的n-1维超平面。这些都是比较基础的内容，如果不太清楚，可能需要复习一下微积分、线性代数的内容。&nbsp;&nbsp;&nbsp; 刚刚说了，我们令黑色白色两类的点分别为+1, -1，所以当有一个新的点x需要预测属于哪个分类的时候，我们用sgn(f(x))，就可以预测了，sgn表示符号函数，当f(x) &gt; 0的时候，sgn(f(x)) = +1, 当f(x) &lt; 0的时候sgn(f(x)) = –1。&nbsp;&nbsp;&nbsp; 但是，我们怎样才能取得一个最优的划分直线f(x)呢？下图的直线表示几条可能的f(x)<br></p><p><img alt=\"屏幕快照 2017-12-25 上午7.48.35.png\" src=\"/uploads/2017/12/25/2017-12-25-74835.png\" width=\"296\" height=\"287\"><br></p><p>一个很直观的感受是，让这条直线到给定样本中最近的点最远，这句话读起来比较拗口，下面给出几个图，来说明一下：&nbsp;&nbsp;&nbsp; 第一种分法：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午7.48.43.png\" src=\"/uploads/2017/12/25/2017-12-25-74843.png\" width=\"326\" height=\"312\"><br></p><p>第二种分法：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午7.48.48.png\" src=\"/uploads/2017/12/25/2017-12-25-74848.png\" width=\"347\" height=\"318\"><br></p><p>这两种分法哪种更好呢？从直观上来说，就是分割的间隙越大越好，把两个类别的点分得越开越好。就像我们平时判断一个人是男还是女，就是很难出现分错的情况，这就是男、女两个类别之间的间隙非常的大导致的，让我们可以更准确的进行分类。在SVM中，称为Maximum Marginal，是SVM的一个理论基础之一。选择使得间隙最大的函数作为分割平面是由很多道理的，比如说从概率的角度上来说，就是使得置信度最小的点置信度最大（听起来很拗口），从实践的角度来说，这样的效果非常好，等等。这里就不展开讲，作为一个结论就ok了，:)&nbsp;&nbsp;&nbsp; 上图被红色和蓝色的线圈出来的点就是所谓的支持向量(support vector)。<br></p><p><img alt=\"屏幕快照 2017-12-25 上午7.48.56.png\" src=\"/uploads/2017/12/25/2017-12-25-74856.png\" width=\"599\" height=\"228\"><br></p><p>上图就是一个对之前说的类别中的间隙的一个描述。Classifier Boundary就是f(x)，红色和蓝色的线（plus plane与minus plane）就是support vector所在的面，红色、蓝色线之间的间隙就是我们要最大化的分类间的间隙。<img alt=\"屏幕快照 2017-12-25 上午7.49.01.png\" src=\"/uploads/2017/12/25/2017-12-25-74901.png\" width=\"486\" height=\"195\"><br></p>',1,'2017-12-24 23:45:00','2017-12-24 23:55:32',1,'0','wang','admin',1004),(12,'支持向量机二','support-vector-machine-2','<h3>SVM求解</h3><p>这里直接给出M的式子：（从高中的解析几何就可以很容易的得到了，也可以参考后面Moore的ppt）<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.01.54.png\" src=\"/uploads/2017/12/25/2017-12-25-80154.png\" width=\"203\" height=\"116\"><br></p><p>另外支持向量位于wx + b = 1与wx + b = -1的直线上，我们在前面乘上一个该点所属的类别y（还记得吗?y不是+1就是-1），就可以得到支持向量的表达式为：y(wx + b) = 1，这样就可以更简单的将支持向量表示出来了。&nbsp;&nbsp;&nbsp; 当支持向量确定下来的时候，分割函数就确定下来了，两个问题是等价的。得到支持向量，还有一个作用是，让支持向量后方那些点就不用参与计算了。这点在后面将会更详细的讲讲。&nbsp;&nbsp;&nbsp; 在这个小节的最后，给出我们要优化求解的表达式：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.01.59.png\" src=\"/uploads/2017/12/25/2017-12-25-80159.png\" width=\"345\" height=\"103\"><br></p><p>&nbsp;||w||的意思是w的二范数，跟上面的M表达式的分母是一个意思，之前得到，M = 2 / ||w||，最大化这个式子等价于最小化||w||, 另外由于||w||是一个单调函数，我们可以对其加入平方，和前面的系数，熟悉的同学应该很容易就看出来了，这个式子是为了方便求导。&nbsp;&nbsp;&nbsp; 这个式子有还有一些限制条件，完整的写下来，应该是这样的：（原问题）<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.02.02.png\" src=\"/uploads/2017/12/25/2017-12-25-80202.png\" width=\"496\" height=\"94\"><br></p><p>s.t的意思是subject to，也就是在后面这个限制条件下的意思，这个词在svm的论文里面非常容易见到。这个其实是一个带约束的二次规划(quadratic programming, QP)问题，是一个凸问题，凸问题就是指的不会有局部最优解，可以想象一个漏斗，不管我们开始的时候将一个小球放在漏斗的什么位置，这个小球最终一定可以掉出漏斗，也就是得到全局最优解。s.t.后面的限制条件可以看做是一个凸多面体，我们要做的就是在这个凸多面体中找到最优解。这些问题这里不展开，因为展开的话，一本书也写不完。如果有疑问请看看wikipedia。<br></p><h4>转化为对偶问题，并优化求解:<br></h4><p>这个优化问题可以用拉格朗日乘子法去解，使用了KKT条件的理论，这里直接作出这个式子的拉格朗日目标函数：</p><p><img alt=\"屏幕快照 2017-12-25 上午8.02.06.png\" src=\"/uploads/2017/12/25/2017-12-25-80206.png\" width=\"577\" height=\"94\"></p><p>求解这个式子的过程需要拉格朗日对偶性的相关知识（另外pluskid也有一篇文章专门讲这个问题），并且有一定的公式推导，如果不感兴趣，可以直接跳到后面用蓝色公式表示的结论，该部分推导主要参考自plukids的文章。&nbsp;&nbsp;&nbsp; 首先让L关于w，b最小化，分别令L关于w，b的偏导数为0，得到关于原问题的一个表达式</p><p><img alt=\"屏幕快照 2017-12-25 上午8.02.11.png\" src=\"/uploads/2017/12/25/2017-12-25-80211.png\" width=\"393\" height=\"167\"></p><p>将两式带回L(w,b,a)得到对偶问题的表达式</p><p><img alt=\"屏幕快照 2017-12-25 上午8.02.14.png\" src=\"/uploads/2017/12/25/2017-12-25-80214.png\" width=\"559\" height=\"104\"></p><p>&nbsp;新问题加上其限制条件是（对偶问题）:</p><p><img alt=\"屏幕快照 2017-12-25 上午8.02.18.png\" src=\"/uploads/2017/12/25/2017-12-25-80218.png\" width=\"428\" height=\"213\"></p><p>&nbsp;这个就是我们需要最终优化的式子。至此，得到了线性可分问题的优化式子。&nbsp;&nbsp;&nbsp; 求解这个式子，有很多的方法，比如SMO等等，个人认为，求解这样的一个带约束的凸优化问题与得到这个凸优化问题是比较独立的两件事情，所以在这篇文章中准备完全不涉及如何求解这个话题，如果之后有时间可以补上一篇文章来谈谈:)。</p>',2,'2017-12-24 23:55:00','2017-12-25 00:05:13',0,'https://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/basic-of-svm.html','wang','admin',1004),(13,'朴素贝叶斯简介','naive-bayes-summary','<h3>朴素贝叶斯简介<br></h3><p>对于分类问题，其实谁都不会陌生，说我们每个人每天都在执行分类操作一点都不夸张，只是我们没有意识到罢了。例如，当你看到一个陌生人，你的脑子下意识判断TA是男是女；你可能经常会走在路上对身旁的朋友说“这个人一看就很有钱、那边有个非主流”之类的话，其实这就是一种分类操作。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 从数学角度来说，分类问题可做如下定义：<br></p><p>已知集合：<img alt=\"屏幕快照 2017-12-25 上午8.09.48.png\" src=\"/uploads/2017/12/25/2017-12-25-80948.png\" width=\"185\" height=\"45\">和<img alt=\"屏幕快照 2017-12-25 上午8.09.51.png\" src=\"/uploads/2017/12/25/2017-12-25-80951.png\" width=\"217\" height=\"47\">确定映射规则y=f(x)，使得任意<img alt=\"屏幕快照 2017-12-25 上午8.10.01.png\" src=\"/uploads/2017/12/25/2017-12-25-81001_KI7kBWE.png\" width=\"64\" height=\"35\">有且仅有一个<img alt=\"屏幕快照 2017-12-25 上午8.10.03.png\" src=\"/uploads/2017/12/25/2017-12-25-81003.png\" width=\"74\" height=\"41\">使得<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.10.07.png\" src=\"/uploads/2017/12/25/2017-12-25-81007.png\" width=\"101\" height=\"39\">成立。（不考虑模糊数学里的模糊集情况）。<br></p><p>其中C叫做类别集合，其中每一个元素是一个类别，而I叫做项集合，其中每一个元素是一个待分类项，f叫做分类器。分类算法的任务就是构造分类器f。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这里要着重强调，分类问题往往采用经验性方法构造映射规则，即一般情况下的分类问题缺少足够的信息来构造100%正确的映射规则，而是通过对经验数据的学习从而实现一定概率意义上正确的分类，因此所训练出的分类器并不是一定能将每个待分类项准确映射到其分类，分类器的质量与分类器构造方法、待分类数据的特性以及训练样本数量等诸多因素有关。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 例如，医生对病人进行诊断就是一个典型的分类过程，任何一个医生都无法直接看到病人的病情，只能观察病人表现出的症状和各种化验检测数据来推断病情，这时医生就好比一个分类器，而这个医生诊断的准确率，与他当初受到的教育方式（构造方法）、病人的症状是否突出（待分类数据的特性）以及医生的经验多少（训练样本数量）都有密切关系。<br></p><h4>贝叶斯定理</h4><p>每次提到贝叶斯定理，我心中的崇敬之情都油然而生，倒不是因为这个定理多高深，而是因为它特别有用。这个定理解决了现实生活里经常遇到的问题：已知某条件概率，如何得到两个事件交换后的概率，也就是在已知P(A|B)的情况下如何求得P(B|A)。这里先解释什么是条件概率：<br></p><p>P(B|A)表示事件B已经发生的前提下，事件A发生的概率，叫做事件B发生下事件A的条件概率。其基本求解公式为：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.13.03.png\" src=\"/uploads/2017/12/25/2017-12-25-81303.png\" width=\"180\" height=\"65\"><br></p><p>贝叶斯定理之所以有用，是因为我们在生活中经常遇到这种情况：我们可以很容易直接得出P(A|B)，P(B|A)则很难直接得出，但我们更关心P(B|A)，贝叶斯定理就为我们打通从P(A|B)获得P(B|A)的道路。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 下面不加证明地直接给出贝叶斯定理：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.13.29.png\" src=\"/uploads/2017/12/25/2017-12-25-81329.png\" width=\"280\" height=\"79\"><br></p>',1,'2017-12-25 00:05:00','2017-12-25 00:14:16',0,'https://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html','wang','admin',1005),(14,'贝叶斯分类流程','naive-bayes-process','<h3>贝叶斯分类流程<br></h3><p>朴素贝叶斯分类是一种十分简单的分类算法，叫它朴素贝叶斯分类是因为这种方法的思想真的很朴素，朴素贝叶斯的思想基础是这样的：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。通俗来说，就好比这么个道理，你在街上看到一个黑人，我问你你猜这哥们哪里来的，你十有八九猜非洲。为什么呢？因为黑人中非洲人的比率最高，当然人家也可能是美洲人或亚洲人，但在没有其它可用信息下，我们会选择条件概率最大的类别，这就是朴素贝叶斯的思想基础。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 朴素贝叶斯分类的正式定义如下：<br></p><p>&nbsp;1、设<img alt=\"屏幕快照 2017-12-25 上午8.15.28.png\" src=\"/uploads/2017/12/25/2017-12-25-81528.png\" width=\"184\" height=\"47\">为一个待分类项，而每个a为x的一个特征属性。<br></p><p>2、有类别集合<img alt=\"屏幕快照 2017-12-25 上午8.15.33.png\" src=\"/uploads/2017/12/25/2017-12-25-81533.png\" width=\"183\" height=\"47\">。<br></p><p>3、计算<img alt=\"屏幕快照 2017-12-25 上午8.15.36.png\" src=\"/uploads/2017/12/25/2017-12-25-81536.png\" width=\"275\" height=\"50\"><br></p><p>4、如果<img alt=\"屏幕快照 2017-12-25 上午8.15.39.png\" src=\"/uploads/2017/12/25/2017-12-25-81539_3btHlqq.png\" width=\"445\" height=\"51\">，则<img alt=\"屏幕快照 2017-12-25 上午8.15.42.png\" src=\"/uploads/2017/12/25/2017-12-25-81542.png\" width=\"62\" height=\"35\">。</p><p>那么现在的关键就是如何计算第3步中的各个条件概率。我们可以这么做：&nbsp; &nbsp; &nbsp; &nbsp;</p><p>1、找到一个已知分类的待分类项集合，这个集合叫做训练样本集。&nbsp; &nbsp;&nbsp;</p><p>&nbsp; 2、统计得到在各类别下各个特征属性的条件概率估计。即<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.15.45.png\" src=\"/uploads/2017/12/25/2017-12-25-81545.png\" width=\"998\" height=\"57\"><br></p><p>&nbsp; &nbsp; 3、如果各个特征属性是条件独立的，则根据贝叶斯定理有如下推导：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.15.52.png\" src=\"/uploads/2017/12/25/2017-12-25-81552.png\" width=\"294\" height=\"88\"><br></p><p>因为分母对于所有类别为常数，因为我们只要将分子最大化皆可。又因为各特征属性是条件独立的，所以有：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.15.55.png\" src=\"/uploads/2017/12/25/2017-12-25-81555.png\" width=\"686\" height=\"103\"><br></p><p>根据上述分析，朴素贝叶斯分类的流程可以由下图表示（暂时不考虑验证）：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.18.33.png\" src=\"/uploads/2017/12/25/2017-12-25-81833.png\" width=\"837\" height=\"699\"><br></p><p>可以看到，整个朴素贝叶斯分类分为三个阶段：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第一阶段——准备工作阶段，这个阶段的任务是为朴素贝叶斯分类做必要的准备，主要工作是根据具体情况确定特征属性，并对每个特征属性进行适当划分，然后由人工对一部分待分类项进行分类，形成训练样本集合。这一阶段的输入是所有待分类数据，输出是特征属性和训练样本。这一阶段是整个朴素贝叶斯分类中唯一需要人工完成的阶段，其质量对整个过程将有重要影响，分类器的质量很大程度上由特征属性、特征属性划分及训练样本质量决定。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第二阶段——分类器训练阶段，这个阶段的任务就是生成分类器，主要工作是计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率估计，并将结果记录。其输入是特征属性和训练样本，输出是分类器。这一阶段是机械性阶段，根据前面讨论的公式可以由程序自动计算完成。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第三阶段——应用阶段。这个阶段的任务是使用分类器对待分类项进行分类，其输入是分类器和待分类项，输出是待分类项与类别的映射关系。这一阶段也是机械性阶段，由程序完成。<br></p>',2,'2017-12-25 00:14:00','2017-12-25 00:19:38',0,'https://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html','wang','admin',1005),(15,'Laplace校准','naive-bayes-laplace','<p>这一节讨论P(a|y)的估计。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 由上文看出，计算各个划分的条件概率P(a|y)是朴素贝叶斯分类的关键性步骤，当特征属性为离散值时，只要很方便的统计训练样本中各个划分在每个类别中出现的频率即可用来估计P(a|y)，下面重点讨论特征属性是连续值的情况。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当特征属性为连续值时，通常假定其值服从高斯分布（也称正态分布）。即：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.20.22.png\" src=\"/uploads/2017/12/25/2017-12-25-82022.png\" width=\"336\" height=\"74\"><br></p><p>而<img alt=\"屏幕快照 2017-12-25 上午8.20.25.png\" src=\"/uploads/2017/12/25/2017-12-25-82025.png\" width=\"258\" height=\"57\"></p><p>因此只要计算出训练样本中各个类别中此特征项划分的各均值和标准差，代入上述公式即可得到需要的估计值。均值与标准差的计算在此不再赘述。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 另一个需要讨论的问题就是当P(a|y)=0怎么办，当某个类别下某个特征项划分没有出现时，就是产生这种现象，这会令分类器质量大大降低。为了解决这个问题，我们引入Laplace校准，它的思想非常简单，就是对没类别下所有划分的计数加1，这样如果训练样本集数量充分大时，并不会对结果产生影响，并且解决了上述频率为0的尴尬局面。<br></p>',3,'2017-12-25 00:19:00','2017-12-25 00:21:31',0,'https://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html','wang','admin',1005),(16,'贝叶斯分类实例','naive-bayes-sample','<h3>贝叶斯分类实例<br></h3><p>下面讨论一个使用朴素贝叶斯分类解决实际问题的例子，为了简单起见，对例子中的数据做了适当的简化。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这个问题是这样的，对于SNS社区来说，不真实账号（使用虚假身份或用户的小号）是一个普遍存在的问题，作为SNS社区的运营商，希望可以检测出这些不真实账号，从而在一些运营分析报告中避免这些账号的干扰，亦可以加强对SNS社区的了解与监管。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 如果通过纯人工检测，需要耗费大量的人力，效率也十分低下，如能引入自动检测机制，必将大大提升工作效率。这个问题说白了，就是要将社区中所有账号在真实账号和不真实账号两个类别上进行分类，下面我们一步一步实现这个过程。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 首先设C=0表示真实账号，C=1表示不真实账号。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1、确定特征属性及划分&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这一步要找出可以帮助我们区分真实账号与不真实账号的特征属性，在实际应用中，特征属性的数量是很多的，划分也会比较细致，但这里为了简单起见，我们用少量的特征属性以及较粗的划分，并对数据做了修改。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们选择三个特征属性：a1：日志数量/注册天数，a2：好友数量/注册天数，a3：是否使用真实头像。在SNS社区中这三项都是可以直接从数据库里得到或计算出来的。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 下面给出划分：a1：{a&lt;=0.05, 0.05&lt;a&lt;0.2, a&gt;=0.2}，a1：{a&lt;=0.1, 0.1&lt;a&lt;0.8, a&gt;=0.8}，a3：{a=0（不是）,a=1（是）}。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2、获取训练样本&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这里使用运维人员曾经人工检测过的1万个账号作为训练样本。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3、计算训练样本中每个类别的频率&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 用训练样本中真实账号和不真实账号数量分别除以一万，得到：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.22.46.png\" src=\"/uploads/2017/12/25/2017-12-25-82246.png\" width=\"362\" height=\"90\"><br></p><p>&nbsp;4、计算每个类别条件下各个特征属性划分的频率<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.23.06.png\" src=\"/uploads/2017/12/25/2017-12-25-82306.png\" width=\"403\" height=\"743\"><br></p><p>&nbsp;&nbsp;&nbsp;5、使用分类器进行鉴别&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 下面我们使用上面训练得到的分类器鉴别一个账号，这个账号使用非真实头像，日志数量与注册天数的比率为0.1，好友数与注册天数的比率为0.2。<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.23.14.png\" src=\"/uploads/2017/12/25/2017-12-25-82314.png\" width=\"780\" height=\"153\"><br></p><p>可以看到，虽然这个用户没有使用真实头像，但是通过分类器的鉴别，更倾向于将此账号归入真实账号类别。这个例子也展示了当特征属性充分多时，朴素贝叶斯分类对个别属性的抗干扰性。<br></p>',4,'2017-12-25 00:21:00','2017-12-25 00:24:17',0,'https://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html','wang','admin',1005),(17,'KNN算法','knn','<p>一：什么是看KNN算法？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>&nbsp;kNN算法全称是k-最近邻算法（K-Nearest Neighbor）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。下边举例说明：<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.28.27.png\" src=\"/uploads/2017/12/25/2017-12-25-82827.png\" width=\"625\" height=\"184\"><br></p><p>即使不知道未知电影属于哪种类型，我们也可以通过某种方法计算出来，如下图<br></p><p><img alt=\"屏幕快照 2017-12-25 上午8.28.31.png\" src=\"/uploads/2017/12/25/2017-12-25-82831.png\" width=\"419\" height=\"199\"><br></p><p>现在我们得到了样本集中与未知电影的距离，按照距离的递增顺序，可以找到k个距离最近的电影，假定k=3，则三个最靠近的电影是和he is not realy into Dudes,Beautiful women, California man kNN算法按照距离最近的三部电影类型决定未知电影类型，这三部都是爱情片，所以未知电影的类型也为爱情片<br></p><p>二：KNN算法的一般流程step.1---初始化距离为最大值step.2---计算未知样本和每个训练样本的距离diststep.3---得到目前K个最临近样本中的最大距离maxdiststep.4---如果dist小于maxdist，则将该训练样本作为K-最近邻样本step.5---重复步骤2、3、4，直到未知样本和所有训练样本的距离都算完step.6---统计K-最近邻样本中每个类标号出现的次数step.7---选择出现频率最大的类标号作为未知样本的类标号<br></p><p>三、KNN算法的Python代码实现<br></p><pre><code>#encoding:utf-8&nbsp;&nbsp;\r\nfrom&nbsp;numpy&nbsp;import&nbsp;*&nbsp;&nbsp;\r\nimport&nbsp;operator&nbsp;&nbsp;\r\n&nbsp;&nbsp;\r\ndef&nbsp;createDataSet():&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;group&nbsp;=&nbsp;array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;labels&nbsp;=&nbsp;[\'A\',\'A\',\'B\',\'B\']&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;group,labels&nbsp;&nbsp;\r\n&nbsp;&nbsp;\r\ndef&nbsp;classify0(inX,dataSet,labels,k):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#返回“数组”的行数，如果shape[1]返回的则是数组的列数&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;dataSetSize&nbsp;=&nbsp;dataSet.shape[0]&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#两个“数组”相减，得到新的数组&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;diffMat&nbsp;=&nbsp;tile(inX,(dataSetSize,1))-&nbsp;dataSet&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#求平方&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;sqDiffMat&nbsp;=&nbsp;diffMat&nbsp;**2&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#求和，返回的是一维数组&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;sqDistances&nbsp;=&nbsp;sqDiffMat.sum(axis=1)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#开方，即测试点到其余各个点的距离&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;distances&nbsp;=&nbsp;sqDistances&nbsp;**0.5&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#排序，返回值是原数组从小到大排序的下标值&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;sortedDistIndicies&nbsp;=&nbsp;distances.argsort()&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#定义一个空的字典&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;classCount&nbsp;=&nbsp;{}&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(k):&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#返回距离最近的k个点所对应的标签值&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;voteIlabel&nbsp;=&nbsp;labels[sortedDistIndicies[i]]&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#存放到字典中&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classCount[voteIlabel]&nbsp;=&nbsp;classCount.get(voteIlabel,0)+1&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#排序&nbsp;classCount.iteritems()&nbsp;输出键值对&nbsp;key代表排序的关键字&nbsp;True代表降序&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;sortedClassCount&nbsp;=&nbsp;sorted(classCount.iteritems(),key&nbsp;=&nbsp;operator.itemgetter(1),reverse&nbsp;=&nbsp;True)&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#返回距离最小的点对应的标签&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;return&nbsp;sortedClassCount[0][0]&nbsp;&nbsp;<br></code></pre><p>调用方式：打开CMD，进入kNN.py文件所在的目录，输入Python，依次输入import kNN&nbsp;&nbsp;&nbsp;&nbsp; group，labels = kNN.createDataSet()&nbsp;&nbsp;&nbsp; kNN.classify0([0,0],group,lables,3)<br></p>',1,'2017-12-25 00:24:00','2017-12-25 00:30:23',0,'http://blog.csdn.net/gamer_gyt/article/details/47418223','wang','admin',1006),(18,'k均值算法','k-means','<h3>k均值算法<br></h3><p>分类作为一种监督学习方法，要求必须事先明确知道各个类别的信息，并且断言所有待分类项都有一个类别与之对应。但是很多时候上述条件得不到满足，尤其是在处理海量数据的时候，如果通过预处理使得数据满足分类算法的要求，则代价非常大，这时候可以考虑使用聚类算法。聚类属于无监督学习，相比于分类，聚类不依赖预定义的类和类标号的训练实例。本文首先介绍聚类的基础——距离与相异度，然后介绍一种常见的聚类算法——k均值和k中心点聚类，最后会举一个实例：应用聚类方法试图解决一个在体育界大家颇具争议的问题——中国男足近几年在亚洲到底处于几流水平。<br></p><p>&nbsp;在正式讨论聚类前，我们要先弄清楚一个问题：如何定量计算两个可比较元素间的相异度。用通俗的话说，相异度就是两个东西差别有多大，例如人类与章鱼的相异度明显大于人类与黑猩猩的相异度，这是能我们直观感受到的。但是，计算机没有这种直观感受能力，我们必须对相异度在数学上进行定量定义。<br></p><p>设<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_5BdNd2N.png\" width=\"303\" height=\"19\">，其中X，Y是两个元素项，各自具有n个可度量特征属性，那么X和Y的相异度定义为：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_uJS0Psi.png\" width=\"190\" height=\"18\">，其中R为实数域。也就是说相异度是两个元素对实数域的一个映射，所映射的实数定量表示两个元素的相异度。<br></p><p>下面介绍不同类型变量相异度计算方法。<br></p><p>标量也就是无方向意义的数字，也叫标度变量。现在先考虑元素的所有特征属性都是标量的情况。例如，计算X={2,1,102}和Y={1,3,2}的相异度。一种很自然的想法是用两者的欧几里得距离来作为相异度，欧几里得距离的定义如下：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_wZjJYsQ.png\" width=\"418\" height=\"23\"><br></p><p>其意义就是两个元素在欧氏空间中的集合距离，因为其直观易懂且可解释性强，被广泛用于标识两个标量元素的相异度。将上面两个示例数据代入公式，可得两者的欧氏距离为：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_l49IV5G.png\" width=\"432\" height=\"23\"><br></p><p>&nbsp;除欧氏距离外，常用作度量标量相异度的还有曼哈顿距离和闵可夫斯基距离，两者定义如下：<br></p><p>&nbsp;曼哈顿距离：<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_iCNsd5a.png\" width=\"364\" height=\"19\"></p><p>闵可夫斯基距离：<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_Fo2fyuB.png\" width=\"408\" height=\"23\"><br></p><p>欧氏距离和曼哈顿距离可以看做是闵可夫斯基距离在p=2和p=1下的特例。另外这三种距离都可以加权，这个很容易理解，不再赘述。<br></p><p>下面要说一下标量的规格化问题。上面这样计算相异度的方式有一点问题，就是取值范围大的属性对距离的影响高于取值范围小的属性。例如上述例子中第三个属性的取值跨度远大于前两个，这样不利于真实反映真实的相异度，为了解决这个问题，一般要对属性值进行规格化。所谓规格化就是将各个属性值按比例映射到相同的取值区间，这样是为了平衡各个属性对距离的影响。通常将各个属性均映射到[0,1]区间，映射公式为：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_Ey0U1AS.png\" width=\"188\" height=\"43\"><br></p><p>其中max(ai)和min(ai)表示所有元素项中第i个属性的最大值和最小值。例如，将示例中的元素规格化到[0,1]区间后，就变成了X’={1,0,1}，Y’={0,1,0}，重新计算欧氏距离约为1.732。<br></p><p>&nbsp;所谓二元变量是只能取0和1两种值变量，有点类似布尔值，通常用来标识是或不是这种二值属性。对于二元变量，上一节提到的距离不能很好标识其相异度，我们需要一种更适合的标识。一种常用的方法是用元素相同序位同值属性的比例来标识其相异度。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 设有X={1,0,0,0,1,0,1,1}，Y={0,0,0,1,1,1,1,1}，可以看到，两个元素第2、3、5、7和8个属性取值相同，而第1、4和6个取值不同，那么相异度可以标识为3/8=0.375。一般的，对于二元变量，相异度可用“取值不同的同位属性数/单个元素的属性位数”标识。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 上面所说的相异度应该叫做对称二元相异度。现实中还有一种情况，就是我们只关心两者都取1的情况，而认为两者都取0的属性并不意味着两者更相似。例如在根据病情对病人聚类时，如果两个人都患有肺癌，我们认为两个人增强了相似度，但如果两个人都没患肺癌，并不觉得这加强了两人的相似性，在这种情况下，改用“取值不同的同位属性数/(单个元素的属性位数-同取0的位数)”来标识相异度，这叫做非对称二元相异度。如果用1减去非对称二元相异度，则得到非对称二元相似度，也叫Jaccard系数，是一个非常重要的概念。</p><p>&nbsp; &nbsp;分类变量是二元变量的推广，类似于程序中的枚举变量，但各个值没有数字或序数意义，如颜色、民族等等，对于分类变量，用“取值不同的同位属性数/单个元素的全部属性数”来标识其相异度。<br></p><p>&nbsp;序数变量是具有序数意义的分类变量，通常可以按照一定顺序意义排列，如冠军、亚军和季军。对于序数变量，一般为每个值分配一个数，叫做这个值的秩，然后以秩代替原值当做标量属性计算相异度。<br></p><p>对于向量，由于它不仅有大小而且有方向，所以闵可夫斯基距离不是度量其相异度的好办法，一种流行的做法是用两个向量的余弦度量，其度量公式为：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_ZZ63rQ8.png\" width=\"158\" height=\"45\"><br></p><p>其中||X||表示X的欧几里得范数。要注意，余弦度量度量的不是两者的相异度，而是相似度！<br></p><p>在讨论完了相异度计算的问题，就可以正式定义聚类问题了。<br></p><p>所谓聚类问题，就是给定一个元素集合D，其中每个元素具有n个可观察属性，使用某种算法将D划分成k个子集，要求每个子集内部的元素之间相异度尽可能低，而不同子集的元素相异度尽可能高。其中每个子集叫做一个簇。<br></p><p>与分类不同，分类是示例式学习，要求分类前明确各个类别，并断言每个元素映射到一个类别，而聚类是观察式学习，在聚类前可以不知道类别甚至不给定类别数量，是无监督学习的一种。目前聚类广泛应用于统计学、生物学、数据库技术和市场营销等领域，相应的算法也非常的多。本文仅介绍一种最简单的聚类算法——k均值（k-means）算法。<br></p><p>&nbsp;k均值算法的计算过程非常直观：&nbsp;&nbsp;</p><p>&nbsp;&nbsp;&nbsp; 1、从D中随机取k个元素，作为k个簇的各自的中心。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>&nbsp; &nbsp; 2、分别计算剩下的元素到k个簇中心的相异度，将这些元素分别划归到相异度最低的簇。&nbsp; &nbsp; &nbsp;</p><p>&nbsp; &nbsp;&nbsp;3、根据聚类结果，重新计算k个簇各自的中心，计算方法是取簇中所有元素各自维度的算术平均数。</p><p>&nbsp; &nbsp; 4、将D中全部元素按照新的中心重新聚类。</p><p>&nbsp; &nbsp; 5、重复第4步，直到聚类结果不再变化。</p><p>&nbsp; &nbsp; 6、将结果输出。</p><p>由于算法比较直观，没有什么可以过多讲解的。下面，我们来看看k-means算法一个有趣的应用示例：中国男足近几年到底在亚洲处于几流水平？<br></p><p>今年中国男足可算是杯具到家了，几乎到了过街老鼠人人喊打的地步。对于目前中国男足在亚洲的地位，各方也是各执一词，有人说中国男足亚洲二流，有人说三流，还有人说根本不入流，更有人说其实不比日韩差多少，是亚洲一流。既然争论不能解决问题，我们就让数据告诉我们结果吧。<br></p><p>下图是我采集的亚洲15只球队在2005年-2010年间大型杯赛的战绩（由于澳大利亚是后来加入亚足联的，所以这里没有收录）。<br></p><p><img alt=\"屏幕快照 2017-12-25 下午9.23.26.png\" src=\"/uploads/2017/12/25/2017-12-25-92326.png\" width=\"500\" height=\"265.6441717791411\"><br></p><p>&nbsp;其中包括两次世界杯和一次亚洲杯。我提前对数据做了如下预处理：对于世界杯，进入决赛圈则取其最终排名，没有进入决赛圈的，打入预选赛十强赛赋予40，预选赛小组未出线的赋予50。对于亚洲杯，前四名取其排名，八强赋予5，十六强赋予9，预选赛没出现的赋予17。这样做是为了使得所有数据变为标量，便于后续聚类。<br></p><p>下面先对数据进行[0,1]规格化，下面是规格化后的数据：<br></p><p><img alt=\"屏幕快照 2017-12-25 下午9.24.11.png\" src=\"/uploads/2017/12/25/2017-12-25-92411.png\" width=\"500\" height=\"269.61394769613946\"><br></p><p>接着用k-means算法进行聚类。设k=3，即将这15支球队分成三个集团。<br></p><p>现抽取日本、巴林和泰国的值作为三个簇的种子，即初始化三个簇的中心为A：{0.3, 0, 0.19}，B：{0.7, 0.76, 0.5}和C：{1, 1, 0.5}。下面，计算所有球队分别对三个中心点的相异度，这里以欧氏距离度量。下面是我用程序求取的结果：<br></p><p><img alt=\"屏幕快照 2017-12-25 下午9.25.37.png\" src=\"/uploads/2017/12/25/2017-12-25-92537.png\" width=\"500\" height=\"413.85767790262173\"><br></p><p>从做到右依次表示各支球队到当前中心点的欧氏距离，将每支球队分到最近的簇，可对各支球队做如下聚类：<br></p><p>中国C，日本A，韩国A，伊朗A，沙特A，伊拉克C，卡塔尔C，阿联酋C，乌兹别克斯坦B，泰国C，越南C，阿曼C，巴林B，朝鲜B，印尼C。<br></p><p>第一次聚类结果：<br></p><p>&nbsp; A：日本，韩国，伊朗，沙特；</p><p>&nbsp; B：乌兹别克斯坦，巴林，朝鲜；</p><p>&nbsp; &nbsp;C：中国，伊拉克，卡塔尔，阿联酋，泰国，越南，阿曼，印尼。<br></p><p>下面根据第一次聚类结果，调整各个簇的中心点。<br></p><p>A簇的新中心点为：{(0.3+0+0.24+0.3)/4=0.21, (0+0.15+0.76+0.76)/4=0.4175, (0.19+0.13+0.25+0.06)/4=0.1575} = {0.21, 0.4175, 0.1575}<br></p><p>用同样的方法计算得到B和C簇的新中心点分别为{0.7, 0.7333, 0.4167}，{1, 0.94, 0.40625}。<br></p><p>用调整后的中心点再次进行聚类，得到：<br></p><p><img alt=\"屏幕快照 2017-12-25 下午9.27.23.png\" src=\"/uploads/2017/12/25/2017-12-25-92723.png\" width=\"500\" height=\"341.40969162995594\"><br></p><p>第二次迭代后的结果为：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 中国C，日本A，韩国A，伊朗A，沙特A，伊拉克C，卡塔尔C，阿联酋C，乌兹别克斯坦B，泰国C，越南C，阿曼C，巴林B，朝鲜B，印尼C。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 结果无变化，说明结果已收敛，于是给出最终聚类结果：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 亚洲一流：日本，韩国，伊朗，沙特&nbsp;</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 亚洲二流：乌兹别克斯坦，巴林，朝鲜</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 亚洲三流：中国，伊拉克，卡塔尔，阿联酋，泰国，越南，阿曼，印尼</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 看来数据告诉我们，说国足近几年处在亚洲三流水平真的是没有冤枉他们，至少从国际杯赛战绩是这样的。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其实上面的分析数据不仅告诉了我们聚类信息，还提供了一些其它有趣的信息，例如从中可以定量分析出各个球队之间的差距，例如，在亚洲一流队伍中，日本与沙特水平最接近，而伊朗则相距他们较远，这也和近几年伊朗没落的实际相符。另外，乌兹别克斯坦和巴林虽然没有打进近两届世界杯，不过凭借预算赛和亚洲杯上的出色表现占据B组一席之地，而朝鲜由于打入了2010世界杯决赛圈而有幸进入B组，可是同样奇迹般夺得2007年亚洲杯的伊拉克却被分在三流，看来亚洲杯冠军的分量还不如打进世界杯决赛圈重啊。其它有趣的信息，有兴趣的朋友可以进一步挖掘。<br></p>',1,'2017-12-25 13:18:00','2017-12-25 13:29:13',0,'https://www.cnblogs.com/leoo2sk/archive/2010/09/20/k-means.html','wang','admin',1007),(19,'AdaBoost自适应算法','AdaBoost-summary','<h3>浅谈 Adaboost 算法<br></h3><h4>Boosting 算法的起源<br></h4><p>boost 算法系列的起源来自于PAC Learnability(PAC 可学习性)。这套理论主要研究的是什么时候一个问题是可被学习的，当然也会探讨针对可学习的问题的具体的学习算法。这套理论是由Valiant提出来的。</p><p>PAC 定义了学习算法的强弱</p><p>弱学习算法---识别错误率小于1/2(即准确率仅比随机猜测略高的学习算法)&nbsp;</p><p>&nbsp;强学习算法---识别准确率很高并能在多项式时间内完成的学习算法</p><p>同时 ,Valiant和 Kearns首次提出了 PAC学习模型中弱学习算法和强学习算法的等价性问题,即任意给定仅比随机猜测略好的弱学习算法 ,是否可以将其提升为强学习算法 ? 如果二者等价 ,那么只需找到一个比随机猜测略好的弱学习算法就可以将其提升为强学习算法 ,而不必寻找很难获得的强学习算法。 也就是这种猜测，让无数牛人去设计算法来验证PAC理论的正确性。</p><p>不过很长一段时间都没有一个切实可行的办法来实现这个理想。细节决定成败，再好的理论也需要有效的算法来执行。终于功夫不负有心人， Schapire在1996年提出一个有效的算法真正实现了这个夙愿，它的名字叫AdaBoost。AdaBoost把多个不同的决策树用一种非随机的方式组合起来，表现出惊人的性能！第一，把决策树的准确率大大提高，可以与SVM媲美。第二，速度快，且基本不用调参数。第三，几乎不Overfitting。我估计当时Breiman和Friedman肯定高兴坏了，因为眼看着他们提出的CART正在被SVM比下去的时候，AdaBoost让决策树起死回生！Breiman情不自禁地在他的论文里赞扬AdaBoost是最好的现货方法（off-the-shelf，即“拿下了就可以用”的意思）。(这段话摘自统计学习那些事)</p><h4>Boosting算法的发展历史<br></h4><p>Boosting算法是一种把若干个分类器整合为一个分类器的方法，在boosting算法产生之前，还出现过两种比较重要的将多个分类器整合 为一个分类器的方法，即boostrapping方法和bagging方法。我们先简要介绍一下bootstrapping方法和bagging方法。</p><p>1）bootstrapping方法的主要过程&nbsp;</p><p>　　主要步骤：</p><p>&nbsp;　　i)重复地从一个样本集合D中采样n个样本&nbsp;</p><p>　　ii)针对每次采样的子样本集，进行统计学习，获得假设Hi&nbsp;</p><p>　　iii)将若干个假设进行组合，形成最终的假设Hfinal&nbsp;</p><p>　　iv)将最终的假设用于具体的分类任务</p><p>2）bagging方法的主要过程 -----bagging可以有多种抽取方法</p><p>主要思路：</p><p>&nbsp;　　i)训练分类器　　从整体样本集合中，抽样n*&nbsp;&lt;&nbsp;N个样本 针对抽样的集合训练分类器Ci&nbsp;</p><p>　　ii)分类器进行投票，最终的结果是分类器投票的优胜结果&nbsp;</p><p>　　但是，上述这两种方法，都只是将分类器进行简单的组合，实际上，并没有发挥出分类器组合的威力来。直到1989年，Yoav Freund与 Robert Schapire提出了一种可行的将弱分类器组合为强分类器的方法。并由此而获得了2003年的哥德尔奖（Godel price）。</p><p>&nbsp;　　Schapire还提出了一种早期的boosting算法，其主要过程如下：&nbsp;</p><p>　　i)从样本整体集合D中，不放回的随机抽样n1&nbsp;&lt;&nbsp;n个样本，得到集合&nbsp;D1</p><p>&nbsp;　　训练弱分类器C1&nbsp;</p><p>　　ii)从样本整体集合D中，抽取&nbsp;n2&nbsp;&lt;&nbsp;n个样本，其中合并进一半被C1&nbsp;分类错误的样本。得到样本集合D2　　训练弱分类器C2&nbsp;</p><p>　　iii)抽取D样本集合中，C1&nbsp;和&nbsp;C2&nbsp;分类不一致样本，组成D3　　训练弱分类器C3&nbsp;</p><p>　　iv)用三个分类器做投票，得到最后分类结果　　到了1995年，Freund and schapire提出了现在的adaboost算法，其主要框架可以描述为：</p><p>&nbsp;　　i)循环迭代多次　　更新样本分布　　寻找当前分布下的最优弱分类器　　计算弱分类器误差率&nbsp;</p><p>　　ii)聚合多次训练的弱分类器</p><h4>Adaboost 算法<br></h4><p>&nbsp;AdaBoost 是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器，即弱分类器，然后把这些弱分类器集合起来，构造一个更强的最终分类器。(很多博客里说的三个臭皮匠赛过诸葛亮)&nbsp;</p><p>&nbsp; 算法本身是改变数据分布实现的，它根据每次训练集之中的每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改权值的新数据送给下层分类器进行训练，然后将每次训练得到的分类器融合起来，作为最后的决策分类器。</p><p>&nbsp;完整的adaboost算法如下</p><p><img alt=\"屏幕快照 2017-12-25 下午9.38.28.png\" src=\"/uploads/2017/12/25/2017-12-25-93828.png\" width=\"500\" height=\"347.05075445816186\"></p><p>简单来说，Adaboost有很多优点:</p><p>1)adaboost是一种有很高精度的分类器</p><p>2)可以使用各种方法构建子分类器，adaboost算法提供的是框架　　</p><p>3)当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单　　</p><p>4)简单，不用做特征筛选　　</p><p>5)不用担心overfitting！</p><p>Adaboost 举例</p><p>也许你看了上面的介绍或许还是对adaboost算法云里雾里的，没关系，百度大牛举了一个很简单的例子，你看了就会对这个算法整体上很清晰了。</p><p>下面我们举一个简单的例子来看看adaboost的实现过程：</p><p><img alt=\"屏幕快照 2017-12-25 下午9.40.01.png\" src=\"/uploads/2017/12/25/2017-12-25-94001.png\" width=\"436\" height=\"358\"></p><p>图中，“+”和“-”分别表示两种类别，在这个过程中，我们使用水平或者垂直的直线作为分类器，来进行分类。</p><p>第一步：</p><p><img alt=\"屏幕快照 2017-12-25 下午9.40.16.png\" src=\"/uploads/2017/12/25/2017-12-25-94016.png\" width=\"837\" height=\"323\"></p><p>&nbsp; &nbsp; &nbsp; 根据分类的正确率，得到一个新的样本分布D2­，一个子分类器h1&nbsp;</p><p>　　其中划圈的样本表示被分错的。在右边的途中，比较大的“+”表示对该样本做了加权。</p><p>&nbsp;也许你对上面的ɛ1，ɑ1怎么算的也不是很理解。下面我们算一下，不要嫌我啰嗦，我最开始就是这样思考的，只有自己把算法演算一遍，你才会真正的懂这个算法的核心，后面我会再次提到这个。</p><p>算法最开始给了一个均匀分布 D 。所以h1 里的每个点的值是0.1。ok，当划分后，有三个点划分错了，根据算法误差表达式<img alt=\"屏幕快照 2017-12-25 下午9.42.12.png\" src=\"/uploads/2017/12/25/2017-12-25-94212.png\" width=\"218\" height=\"45\">得到 误差为分错了的三个点的值之和，所以ɛ1=(0.1+0.1+0.1)=0.3，而ɑ1 根据表达式&nbsp;的可以算出来为0.42. 然后就根据算法 把分错的点权值变大。如此迭代，最终完成adaboost算法。</p><p>第二步：</p><p><img alt=\"屏幕快照 2017-12-25 下午9.40.16.png\" src=\"/uploads/2017/12/25/2017-12-25-94016_c1DoLvY.png\" width=\"837\" height=\"323\"></p><p>根据分类的正确率，得到一个新的样本分布D3，一个子分类器h2</p><p>第三步：</p><p><img alt=\"屏幕快照 2017-12-25 下午9.40.24.png\" src=\"/uploads/2017/12/25/2017-12-25-94024.png\" width=\"579\" height=\"362\"></p><p>得到一个子分类器h3　　整合所有子分类器：</p><p><img alt=\"屏幕快照 2017-12-25 下午9.40.29.png\" src=\"/uploads/2017/12/25/2017-12-25-94029.png\" width=\"743\" height=\"430\"></p><p>因此可以得到整合的结果，从结果中看，及时简单的分类器，组合起来也能获得很好的分类效果，在例子中所有的。</p><h4>Adaboost 疑惑和思考<br></h4><p>到这里，也许你已经对adaboost算法有了大致的理解。但是也许你会有个问题，为什么每次迭代都要把分错的点的权值变大呢？这样有什么好处呢？不这样不行吗? 这就是我当时的想法，为什么呢？我看了好几篇介绍adaboost 的博客，都没有解答我的疑惑，也许大牛认为太简单了，不值一提，或者他们并没有意识到这个问题而一笔带过了。然后我仔细一想，也许提高错误点可以让后面的分类器权值更高。然后看了adaboost算法，和我最初的想法很接近，但不全是。 注意到算法最后的表到式为</p><p><img alt=\"屏幕快照 2017-12-25 下午9.44.53.png\" src=\"/uploads/2017/12/25/2017-12-25-94453.png\" width=\"202\" height=\"52\"></p><p>，这里面的a 表示的权值，是由<img alt=\"屏幕快照 2017-12-25 下午9.44.56.png\" src=\"/uploads/2017/12/25/2017-12-25-94456.png\" width=\"179\" height=\"48\">得到的。</p><p>而a是关于误差的表达式，到这里就可以得到比较清晰的答案了，所有的一切都指向了误差。提高错误点的权值，当下一次分类器再次分错了这些点之后，会提高整体的错误率，这样就导致 a 变的很小，最终导致这个分类器在整个混合分类器的权值变低。也就是说，这个算法让优秀的分类器占整体的权值更高，而挫的分类器权值更低。这个就很符合常理了。到此，我认为对adaboost已经有了一个透彻的理解了。</p><h4>总结<br></h4><p>最后，我们可以总结下adaboost算法的一些实际可以使用的场景：</p><p>1）用于二分类或多分类的应用场景&nbsp;</p><p>2）用于做分类任务的baseline　　无脑化，简单，不会overfitting，不用调分类器　</p><p>3）用于特征选择（feature selection)　</p><p>4）Boosting框架用于对badcase的修正　</p><p>　只需要增加新的分类器，不需要变动原有分类器　</p><p>　由于adaboost算法是一种实现简单，应用也很简单的算法。Adaboost算法通过组合弱分类器而得到强分类器，同时具有分类错误率上界随着训练增加而稳定下降，不会过拟合等的性质，应该说是一种很适合于在各种分类场景下应用的算法。</p>',1,'2017-12-25 13:29:00','2017-12-25 13:46:16',1,'0','wang','admin',1008),(20,'EM算法','em-summary','<h3>EM算法<br></h3><h4>最大似然<br></h4><p>&nbsp; &nbsp; &nbsp; &nbsp; 假设我们需要调查我们学校的男生和女生的身高分布。你怎么做啊？你说那么多人不可能一个一个去问吧，肯定是抽样了。假设你在校园里随便地活捉了100个男生和100个女生。他们共200个人（也就是200个身高的样本数据，为了方便表示，下面，我说“人”的意思就是对应的身高）都在教室里面了。那下一步怎么办啊？你开始喊：“男的左边，女的右边，其他的站中间！”。然后你就先统计抽样得到的100个男生的身高。假设他们的身高是服从高斯分布的。但是这个分布的均值u和方差∂2我们不知道，这两个参数就是我们要估计的。记作θ=[u,&nbsp;∂]T。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 用数学的语言来说就是：在学校那么多男生（身高）中，我们独立地按照概率密度p(x|θ)抽取100了个（身高），组成样本集X，我们想通过样本集X来估计出未知参数θ。这里概率密度p(x|θ)我们知道了是高斯分布N(u,∂)的形式，其中的未知参数是θ=[u,&nbsp;∂]T。抽到的样本集是X={x1,x2,…,xN}，其中xi表示抽到的第i个人的身高，这里N就是100，表示抽到的样本个数。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 由于每个样本都是独立地从p(x|θ)中抽取的，换句话说这100个男生中的任何一个，都是我随便捉的，从我的角度来看这些男生之间是没有关系的。那么，我从学校那么多男生中为什么就恰好抽到了这100个人呢？抽到这100个人的概率是多少呢？因为这些男生（的身高）是服从同一个高斯分布p(x|θ)的。那么我抽到男生A（的身高）的概率是p(xA|θ)，抽到男生B的概率是p(xB|θ)，那因为他们是独立的，所以很明显，我同时抽到男生A和男生B的概率是p(xA|θ)* p(xB|θ)，同理，我同时抽到这100个男生的概率就是他们各自概率的乘积了。用数学家的口吻说就是从分布是p(x|θ)的总体样本中抽取到这100个样本的概率，也就是样本集X中各个样本的联合概率，用下式表示：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_cMMWxFl.png\" width=\"375\" height=\"63\"></p><p>这个概率反映了，在概率密度函数的参数是θ时，得到X这组样本的概率。因为这里X是已知的，也就是说我抽取到的这100个人的身高可以测出来，也就是已知的了。而θ是未知了，则上面这个公式只有θ是未知数，所以它是θ的函数。这个函数放映的是在不同的参数θ取值下，取得当前这个样本集的可能性，因此称为参数θ相对于样本集X的似然函数（likehood function）。记为L(θ)。</p><p>这里出现了一个概念，似然函数。还记得我们的目标吗？我们需要在已经抽到这一组样本X的条件下，估计参数θ的值。怎么估计呢？似然函数有啥用呢？那咱们先来了解下似然的概念。直接举个例子：</p><p>某位同学与一位猎人一起外出打猎，一只野兔从前方窜过。只听一声枪响，野兔应声到下，如果要你推测，这一发命中的子弹是谁打的？你就会想，只发一枪便打中，由于猎人命中的概率一般大于这位同学命中的概率，看来这一枪是猎人射中的。</p><p>&nbsp;这个例子所作的推断就体现了极大似然法的基本思想。</p><p>&nbsp;再例如：下课了，一群男女同学分别去厕所了。然后，你闲着无聊，想知道课间是男生上厕所的人多还是女生上厕所的人比较多，然后你就跑去蹲在男厕和女厕的门口。蹲了五分钟，突然一个美女走出来，你狂喜，跑过来告诉我，课间女生上厕所的人比较多，你要不相信你可以进去数数。呵呵，我才没那么蠢跑进去数呢，到时还不得上头条。我问你是怎么知道的。你说：“5分钟了，出来的是女生，女生啊，那么女生出来的概率肯定是最大的了，或者说比男生要大，那么女厕所的人肯定比男厕所的人多”。看到了没，你已经运用最大似然估计了。你通过观察到女生先出来，那么什么情况下，女生会先出来呢？肯定是女生出来的概率最大的时候了，那什么时候女生出来的概率最大啊，那肯定是女厕所比男厕所多人的时候了，这个就是你估计到的参数了。</p><p>&nbsp;从上面这两个例子，你得到了什么结论？</p><p>回到男生身高那个例子。在学校那么男生中，我一抽就抽到这100个男生（表示身高），而不是其他人，那是不是表示在整个学校中，这100个人（的身高）出现的概率最大啊。那么这个概率怎么表示？哦，就是上面那个似然函数L(θ)。所以，我们就只需要找到一个参数θ，其对应的似然函数L(θ)最大，也就是说抽到这100个男生（的身高）概率最大。这个叫做θ的最大似然估计量，记为：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_mMhRsXg.png\" width=\"161\" height=\"49\"></p><p>有时，可以看到L(θ)是连乘的，所以为了便于分析，还可以定义对数似然函数，将其变成连加的：&nbsp;</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_yGkQUw5.png\" width=\"408\" height=\"69\"></p><p>好了，现在我们知道了，要求θ，只需要使θ的似然函数L(θ)极大化，然后极大值对应的θ就是我们的估计。这里就回到了求最值的问题了。怎么求一个函数的最值？当然是求导，然后让导数为0，那么解这个方程得到的θ就是了（当然，前提是函数L(θ)连续可微）。那如果θ是包含多个参数的向量那怎么处理啊？当然是求L(θ)对所有参数的偏导数，也就是梯度了，那么n个未知的参数，就有n个方程，方程组的解就是似然函数的极值点了，当然就得到这n个参数了。</p><p>最大似然估计你可以把它看作是一个反推。多数情况下我们是根据已知条件来推算结果，而最大似然估计是已经知道了结果，然后寻求使该结果出现的可能性最大的条件，以此作为估计值。比如，如果其他条件一定的话，抽烟者发生肺癌的危险时不抽烟者的5倍，那么如果现在我已经知道有个人是肺癌，我想问你这个人抽烟还是不抽烟。你怎么判断？你可能对这个人一无所知，你所知道的只有一件事，那就是抽烟更容易发生肺癌，那么你会猜测这个人不抽烟吗？我相信你更有可能会说，这个人抽烟。为什么？这就是“最大可能”，我只能说他“最有可能”是抽烟的，“他是抽烟的”这一估计值才是“最有可能”得到“肺癌”这样的结果。这就是最大似然估计。</p><p>好了，极大似然估计就讲到这，总结一下：</p><p>&nbsp;极大似然估计，只是一种概率论在统计学的应用，它是参数估计的方法之一。说的是已知某个随机样本满足某种概率分布，但是其中具体的参数不清楚，参数估计就是通过若干次试验，观察其结果，利用结果推出参数的大概值。最大似然估计是建立在这样的思想上：已知某个参数能使这个样本出现的概率最大，我们当然不会再去选择其他小概率的样本，所以干脆就把这个参数作为估计的真实值。</p><p>求最大似然函数估计值的一般步骤：</p><p>&nbsp;（1）写出似然函数；</p><p>&nbsp;（2）对似然函数取对数，并整理；</p><p>&nbsp;（3）求导数，令导数为0，得到似然方程；</p><p>&nbsp;（4）解似然方程，得到的参数即为所求；</p><h4>EM算法<br></h4><p>&nbsp;好了，重新回到上面那个身高分布估计的问题。现在，通过抽取得到的那100个男生的身高和已知的其身高服从高斯分布，我们通过最大化其似然函数，就可以得到了对应高斯分布的参数θ=[u,&nbsp;∂]T了。那么，对于我们学校的女生的身高分布也可以用同样的方法得到了。</p><p>再回到例子本身，如果没有“男的左边，女的右边，其他的站中间！”这个步骤，或者说我抽到这200个人中，某些男生和某些女生一见钟情，已经好上了，纠缠起来了。咱们也不想那么残忍，硬把他们拉扯开。那现在这200个人已经混到一起了，这时候，你从这200个人（的身高）里面随便给我指一个人（的身高），我都无法确定这个人（的身高）是男生（的身高）还是女生（的身高）。也就是说你不知道抽取的那200个人里面的每一个人到底是从男生的那个身高分布里面抽取的，还是女生的那个身高分布抽取的。用数学的语言就是，抽取得到的每个样本都不知道是从哪个分布抽取的。</p><p>&nbsp;这个时候，对于每一个样本或者你抽取到的人，就有两个东西需要猜测或者估计的了，一是这个人是男的还是女的？二是男生和女生对应的身高的高斯分布的参数是多少？</p><p>只有当我们知道了哪些人属于同一个高斯分布的时候，我们才能够对这个分布的参数作出靠谱的预测，例如刚开始的最大似然所说的，但现在两种高斯分布的人混在一块了，我们又不知道哪些人属于第一个高斯分布，哪些属于第二个，所以就没法估计这两个分布的参数。反过来，只有当我们对这两个分布的参数作出了准确的估计的时候，才能知道到底哪些人属于第一个分布，那些人属于第二个分布。</p><p>&nbsp;这就成了一个先有鸡还是先有蛋的问题了。鸡说，没有我，谁把你生出来的啊。蛋不服，说，没有我，你从哪蹦出来啊。（呵呵，这是一个哲学问题。当然了，后来科学家说先有蛋，因为鸡蛋是鸟蛋进化的）。为了解决这个你依赖我，我依赖你的循环依赖问题，总得有一方要先打破僵局，说，不管了，我先随便整一个值出来，看你怎么变，然后我再根据你的变化调整我的变化，然后如此迭代着不断互相推导，最终就会收敛到一个解。这就是</p><p>&nbsp;不知道大家能否理解其中的思想，我再来啰嗦一下。其实这个思想无处在不啊。</p><p>例如，小时候，老妈给一大袋糖果给你，叫你和你姐姐等分，然后你懒得去点糖果的个数，所以你也就不知道每个人到底该分多少个。咱们一般怎么做呢？先把一袋糖果目测的分为两袋，然后把两袋糖果拿在左右手，看哪个重，如果右手重，那很明显右手这代糖果多了，然后你再在右手这袋糖果中抓一把放到左手这袋，然后再感受下哪个重，然后再从重的那袋抓一小把放进轻的那一袋，继续下去，直到你感觉两袋糖果差不多相等了为止。呵呵，然后为了体现公平，你还让你姐姐先选了。</p><p>例如，小时候，老妈给一大袋糖果给你，叫你和你姐姐等分，然后你懒得去点糖果的个数，所以你也就不知道每个人到底该分多少个。咱们一般怎么做呢？先把一袋糖果目测的分为两袋，然后把两袋糖果拿在左右手，看哪个重，如果右手重，那很明显右手这代糖果多了，然后你再在右手这袋糖果中抓一把放到左手这袋，然后再感受下哪个重，然后再从重的那袋抓一小把放进轻的那一袋，继续下去，直到你感觉两袋糖果差不多相等了为止。呵呵，然后为了体现公平，你还让你姐姐先选了。</p><p>&nbsp;EM的意思是“Expectation Maximization”，在我们上面这个问题里面，我们是先随便猜一下男生（身高）的正态分布的参数：如均值和方差是多少。例如男生的均值是1米7，方差是0.1米（当然了，刚开始肯定没那么准），然后计算出每个人更可能属于第一个还是第二个正态分布中的（例如，这个人的身高是1米8，那很明显，他最大可能属于男生的那个分布），这个是属于Expectation一步。有了每个人的归属，或者说我们已经大概地按上面的方法将这200个人分为男生和女生两部分，我们就可以根据之前说的最大似然那样，通过这些被大概分为男生的n个人来重新估计第一个分布的参数，女生的那个分布同样方法重新估计。这个是Maximization。然后，当我们更新了这两个分布的时候，每一个属于这两个分布的概率又变了，那么我们就再需要调整E步……如此往复，直到参数基本不再发生变化为止。</p><p>&nbsp;这里把每个人（样本）的完整描述看做是三元组yi={xi,zi1,zi2}，其中，xi是第i个样本的观测值，也就是对应的这个人的身高，是可以观测到的值。zi1和zi2表示男生和女生这两个高斯分布中哪个被用来产生值xi，就是说这两个值标记这个人到底是男生还是女生（的身高分布产生的）。这两个值我们是不知道的，是隐含变量。确切的说，zij在xi由第j个高斯分布产生时值为1，否则为0。例如一个样本的观测值为1.8，然后他来自男生的那个高斯分布，那么我们可以将这个样本表示为{1.8, 1, 0}。如果zi1和zi2的值已知，也就是说每个人我已经标记为男生或者女生了，那么我们就可以利用上面说的最大似然算法来估计他们各自高斯分布的参数。但是它们未知，因此我们只能用EM算法。</p><p>&nbsp;咱们现在不是因为那个恶心的隐含变量（抽取得到的每个样本都不知道是从哪个分布抽取的）使得本来简单的可以求解的问题变复杂了，求解不了吗。那怎么办呢？人类解决问题的思路都是想能否把复杂的问题简单化。好，那么现在把这个复杂的问题逆回来，我假设已经知道这个隐含变量了，哎，那么求解那个分布的参数是不是很容易了，直接按上面说的最大似然估计就好了。那你就问我了，这个隐含变量是未知的，你怎么就来一个假设说已知呢？你这种假设是没有根据的。呵呵，我知道，所以我们可以先给这个给分布弄一个初始值，然后求这个隐含变量的期望，当成是这个隐含变量的已知值，那么现在就可以用最大似然求解那个分布的参数了吧，那假设这个参数比之前的那个随机的参数要好，它更能表达真实的分布，那么我们再通过这个参数确定的分布去求这个隐含变量的期望，然后再最大化，得到另一个更优的参数，……迭代，就能得到一个皆大欢喜的结果了。</p><p>&nbsp;这时候你就不服了，说你老迭代迭代的，你咋知道新的参数的估计就比原来的好啊？为什么这种方法行得通呢？有没有失效的时候呢？什么时候失效呢？用到这个方法需要注意什么问题呢？呵呵，一下子抛出那么多问题，搞得我适应不过来了，不过这证明了你有很好的搞研究的潜质啊。呵呵，其实这些问题就是数学家需要解决的问题。在数学上是可以稳当的证明的或者得出结论的。那咱们用数学来把上面的问题重新描述下。（在这里可以知道，不管多么复杂或者简单的物理世界的思想，都需要通过数学工具进行建模抽象才得以使用并发挥其强大的作用，而且，这里面蕴含的数学往往能带给你更多想象不到的东西，这就是数学的精妙所在啊）</p><h4>EM算法推导<br></h4><p>&nbsp;假设我们有一个样本集{x(1),…,x(m)}，包含m个独立的样本。但每个样本i对应的类别z(i)是未知的（相当于聚类），也即隐含变量。故我们需要估计概率模型p(x,z)的参数θ，但是由于里面包含隐含变量z，所以很难用最大似然求解，但如果z知道了，那我们就很容易求解了。</p><p>&nbsp;对于参数估计，我们本质上还是想获得一个使似然函数最大化的那个参数θ，现在与最大似然不同的只是似然函数式中多了一个未知的变量z，见下式（1）。也就是说我们的目标是找到适合的θ和z让L(θ)最大。那我们也许会想，你就是多了一个未知的变量而已啊，我也可以分别对未知的θ和z分别求偏导，再令其等于0，求解出来不也一样吗？</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_vBqK3Iy.png\" width=\"682\" height=\"242\"></p><p>&nbsp; 本质上我们是需要最大化（1）式（对（1）式，我们回忆下联合概率密度下某个变量的边缘概率密度函数的求解，注意这里z也是随机变量。对每一个样本i的所有可能类别z求等式右边的联合概率密度函数和，也就得到等式左边为随机变量x的边缘概率密度），也就是似然函数，但是可以看到里面有“和的对数”，求导后形式会非常复杂（自己可以想象下log(f1(x)+ f2(x)+ f3(x)+…)复合函数的求导），所以很难求解得到未知参数z和θ。那OK，我们可否对（1）式做一些改变呢？我们看（2）式，（2）式只是分子分母同乘以一个相等的函数，还是有“和的对数”啊，还是求解不了，那为什么要这么做呢？咱们先不管，看（3）式，发现（3）式变成了“对数的和”，那这样求导就容易了。我们注意点，还发现等号变成了不等号，为什么能这么变呢？这就是Jensen不等式的大显神威的地方。</p><p>Jensen不等式：</p><p>设f是定义域为实数的函数，如果对于所有的实数x。如果对于所有的实数x，f(x)的二次导数大于等于0，那么f是凸函数。当x是向量时，如果其hessian矩阵H是半正定的，那么f是凸函数。如果只大于0，不等于0，那么称f是严格凸函数。Jensen不等式表述如下：</p><p>如果f是凸函数，X是随机变量，那么：E[f(X)]&gt;=f(E[X])特别地，如果f是严格凸函数，当且仅当X是常量时，上式取等号。</p><p>如果用图表示会很清晰：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_fbDCWO2.png\" width=\"478\" height=\"363\"></p><p>&nbsp;图中，实线f是凸函数，X是随机变量，有0.5的概率是a，有0.5的概率是b。（就像掷硬币一样）。X的期望值就是a和b的中值了，图中可以看到E[f(X)]&gt;=f(E[X])成立。</p><p>当f是（严格）凹函数当且仅当-f是（严格）凸函数。</p><p>&nbsp;Jensen不等式应用于凹函数时，不等号方向反向。</p><p>&nbsp;回到公式（2），因为f(x)=log x为凹函数（其二次导数为-1/x2&lt;0）。</p><p>（2）式中<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_bca4LOb.png\" width=\"579\" height=\"65\">的期望，（考虑到E(X)=∑x*p(x)，f(X)是X的函数，则E(f(X))=∑f(x)*p(x)），又<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_VVYZJwK.png\" width=\"149\" height=\"40\">，所以就可以得到公式（3）的不等式了（若不明白，请拿起笔，呵呵）：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_EqaqahC.png\" width=\"761\" height=\"108\"></p><p>OK，到这里，现在式（3）就容易地求导了，但是式（2）和式（3）是不等号啊，式（2）的最大值不是式（3）的最大值啊，而我们想得到式（2）的最大值，那怎么办呢？</p><p>&nbsp;现在我们就需要一点想象力了，上面的式（2）和式（3）不等式可以写成：似然函数L(θ)&gt;=J(z,Q)，那么我们可以通过不断的最大化这个下界J，来使得L(θ)不断提高，最终达到它的最大值。</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_gatWArC.png\" width=\"500\" height=\"263.9225181598063\"></p><p>见上图，我们固定θ，调整Q(z)使下界J(z,Q)上升至与L(θ)在此点θ处相等（绿色曲线到蓝色曲线），然后固定Q(z)，调整θ使下界J(z,Q)达到最大值（θt到θt+1），然后再固定θ，调整Q(z)……直到收敛到似然函数L(θ)的最大值处的θ*。这里有两个问题：什么时候下界J(z,Q)与L(θ)在此点θ处相等？为什么一定会收敛？</p><p>首先第一个问题，在Jensen不等式中说到，当自变量X是常数的时候，等式成立。而在这里，即：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_j8tSCJ1.png\" width=\"309\" height=\"121\"></p><p>再推导下，由于<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_jsFYkjk.png\" width=\"149\" height=\"40\">（因为Q是随机变量z(i)的概率密度函数），则可以得到：分子的和等于c（分子分母都对所有z(i)求和：多个等式分子分母相加不变，这个认为每个样例的两个概率比值都是c），则：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_sJJ0uSn.png\" width=\"454\" height=\"276\"></p><p>至此，我们推出了在固定参数θ后，使下界拉升的Q(z)的计算公式就是后验概率，解决了Q(z)如何选择的问题。这一步就是E步，建立L(θ)的下界。接下来的M步，就是在给定Q(z)后，调整θ，去极大化L(θ)的下界J（在固定Q(z)后，下界还可以调整的更大）。那么一般的EM算法的步骤如下：</p><h4>EM算法（Expectation-maximization）：<br></h4><p>期望最大算法是一种从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。</p><p>EM的算法流程：</p><p>初始化分布参数θ；重复以下步骤直到收敛：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; E步骤：根据参数初始值或上一次迭代的模型参数来计算出隐性变量的后验概率，其实就是隐性变量的期望。作为隐藏变量的现估计值：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_bqBEQvE.png\" width=\"334\" height=\"75\"></p><p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;M步骤：将似然函数最大化以获得新的参数值：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_ZAaig6t.png\" width=\"626\" height=\"119\"></p><p>&nbsp;这个不断的迭代，就可以得到使似然函数L(θ)最大化的参数θ了。那就得回答刚才的第二个问题了，它会收敛吗？</p><p>感性的说，因为下界不断提高，所以极大似然估计单调增加，那么最终我们会到达最大似然估计的最大值。理性分析的话，就会得到下面的东西：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_8eTFh8d.png\" width=\"879\" height=\"262\"></p><p>具体如何证明的，看推导过程参考：<a href=\"http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html\" target=\"_blank\">Andrew Ng《The EM algorithm》</a></p><h4>EM算法另一种理解<br></h4><p>坐标上升法（Coordinate ascent）：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_Vm3zMXC.png\" width=\"512\" height=\"411\"></p><p>图中的直线式迭代优化的路径，可以看到每一步都会向最优值前进一步，而且前进路线是平行于坐标轴的，因为每一步只优化一个变量。</p><p>&nbsp;这犹如在x-y坐标系中找一个曲线的极值，然而曲线函数不能直接求导，因此什么梯度下降方法就不适用了。但固定一个变量后，另外一个可以通过求导得到，因此可以使用坐标上升法，一次固定一个变量，对另外的求极值，最后逐步逼近极值。对应到EM上，E步：固定θ，优化Q；M步：固定Q，优化θ；交替将极值推向最大。</p><h4>EM的应用<br></h4><p>EM算法有很多的应用，最广泛的就是GMM混合高斯模型、聚类、HMM等等。具体可以参考JerryLead的cnblog中的Machine Learning专栏：（EM算法）The EM Algorithm混合高斯模型（Mixtures of Gaussians）和EM算法K-means聚类算法</p>',1,'2017-12-25 13:46:00','2017-12-25 14:08:05',1,'0','wang','admin',1009),(21,'感知机','perceptron','<h3>感知机</h3><h4>概念</h4><p>感知机是二分类模型，输入实例的特征向量，输出实例的±类别。</p><h4>定义<br></h4><p>假设输入空间是<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_mnxSW7T.png\" width=\"63\" height=\"25\">，输出空间是<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_DMiPHw0.png\" width=\"108\" height=\"25\">，x和y分属这两个空间，那么由输入空间到输出空间的如下函数：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_qIVpSPa.png\" width=\"177\" height=\"30\"></p><p>称为感知机。其中，w和b称为感知机模型参数，<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_8u1DH19.png\" width=\"60\" height=\"23\">叫做权值或权值向量，<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_nuMIBZg.png\" width=\"51\" height=\"20\">叫做偏置，w·x表示向量w和x的内积。sign是一个函数：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_fExChdg.png\" width=\"209\" height=\"70\"></p><p>感知机的几何解释是，线性方程</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_p3GKQLO.png\" width=\"105\" height=\"25\"></p><p>将特征空间划分为正负两个部分：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_gkRqf1W.png\" width=\"382\" height=\"307\"></p><p>这个平面（2维时退化为直线）称为分离超平面。</p><h4>感知机学习策略<br></h4><p>数据集的线性可分性</p><p>定义&nbsp;</p><p>给定数据集</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_CSpiBz1.png\" width=\"287\" height=\"34\"></p><p>其中<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_V1j9UZC.png\" width=\"390\" height=\"28\">如果存在某个超平面S</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_qKLtVmo.png\" width=\"112\" height=\"23\"></p><p>能够完全正确地将正负实例点全部分割开来，则称T线性可分，否则称T线性不可分。</p><p>感知机学习策略</p><p>假定数据集线性可分，我们希望找到一个合理的损失函数。</p><p>一个朴素的想法是采用误分类点的总数，但是这样的损失函数不是参数w，b的连续可导函数，不可导自然不能把握函数的变化，也就不易优化（不知道什么时候该终止训练，或终止的时机不是最优的）。</p><p>另一个想法是选择所有误分类点到超平面S的总距离。为此，先定义点x0到平面S的距离：\'</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_d6kAYCn.png\" width=\"153\" height=\"64\"></p><p>分母<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_tNybHEu.png\" width=\"34\" height=\"36\">是w的L2范数，所谓L2范数，指的是向量各元素的平方和然后求平方根（长度）。这个式子很好理解，回忆中学学过的点到平面的距离：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_BuKSLJr.png\" width=\"178\" height=\"40\"></p><p>此处的点到超平面S的距离的几何意义就是上述距离在多维空间的推广。</p><p>又因为，如果点i被误分类，一定有</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_x4QJBDa.png\" width=\"156\" height=\"23\"></p><p>成立，所以我们去掉了绝对值符号，得到误分类点到超平面S的距离公式</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_a0sVByC.png\" width=\"153\" height=\"59\"></p><p>假设所有误分类点构成集合M，那么所有误分类点到超平面S的总距离为</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_SarRFYm.png\" width=\"205\" height=\"67\"></p><p>分母作用不大，反正一定是正的，不考虑分母，就得到了感知机学习的损失函数：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_GQV1fHh.png\" width=\"241\" height=\"46\"></p><h4>感知机学习算法<br></h4><p>原始形式</p><p>感知机学习算法是对以下最优化问题的算法：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_qZqIxHM.png\" width=\"263\" height=\"47\"></p><p>感知机学习算法是误分类驱动的，先随机选取一个超平面，然后用梯度下降法不断极小化上述损失函数。损失函数的梯度由：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_DaUfNN4.png\" width=\"204\" height=\"109\"></p><p>给出。所谓梯度，是一个向量，指向的是标量场增长最快的方向，长度是最大变化率。所谓标量场，指的是空间中任意一个点的属性都可以用一个标量表示的场（个人理解该标量为函数的输出）。</p><p>随机选一个误分类点i，对参数w，b进行更新：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_tPnzCLs.png\" width=\"140\" height=\"89\"></p><p>上式<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_ZvFeUuo.png\" width=\"114\" height=\"26\">是学习率。损失函数的参数加上梯度上升的反方向，于是就梯度下降了。所以，上述迭代可以使损失函数不断减小，直到为0。于是得到了原始形式的感知机学习算法：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_NRJpuNu.png\" width=\"716\" height=\"296\"></p><p>对于此算法，使用下面的例子作为测试数据：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_DclXDCn.png\" width=\"705\" height=\"466\"></p><p>给出Python实现和可视化代码如下：</p><p>感知机算法代码</p><p>终于到了最激动人心的时刻了，有了上述知识，就可以完美地可视化这个简单的算法：</p><pre><code>#&nbsp;-*-&nbsp;coding:utf-8&nbsp;-*-\r\n#&nbsp;Filename:&nbsp;train2.1.py\r\n#&nbsp;Author：hankcs\r\n#&nbsp;Date:&nbsp;2015/1/30&nbsp;16:29\r\nimport&nbsp;copy\r\nfrom&nbsp;matplotlib&nbsp;import&nbsp;pyplot&nbsp;as&nbsp;plt\r\nfrom&nbsp;matplotlib&nbsp;import&nbsp;animation\r\n&nbsp;\r\ntraining_set&nbsp;=&nbsp;[[(3,&nbsp;3),&nbsp;1],&nbsp;[(4,&nbsp;3),&nbsp;1],&nbsp;[(1,&nbsp;1),&nbsp;-1]]\r\nw&nbsp;=&nbsp;[0,&nbsp;0]\r\nb&nbsp;=&nbsp;0\r\nhistory&nbsp;=&nbsp;[]\r\n&nbsp;\r\n&nbsp;\r\ndef&nbsp;update(item):\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;update&nbsp;parameters&nbsp;using&nbsp;stochastic&nbsp;gradient&nbsp;descent\r\n&nbsp;&nbsp;&nbsp;&nbsp;:param&nbsp;item:&nbsp;an&nbsp;item&nbsp;which&nbsp;is&nbsp;classified&nbsp;into&nbsp;wrong&nbsp;class\r\n&nbsp;&nbsp;&nbsp;&nbsp;:return:&nbsp;nothing\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;global&nbsp;w,&nbsp;b,&nbsp;history\r\n&nbsp;&nbsp;&nbsp;&nbsp;w[0]&nbsp;+=&nbsp;1&nbsp;*&nbsp;item[1]&nbsp;*&nbsp;item[0][0]\r\n&nbsp;&nbsp;&nbsp;&nbsp;w[1]&nbsp;+=&nbsp;1&nbsp;*&nbsp;item[1]&nbsp;*&nbsp;item[0][1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;+=&nbsp;1&nbsp;*&nbsp;item[1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;print&nbsp;w,&nbsp;b\r\n&nbsp;&nbsp;&nbsp;&nbsp;history.append([copy.copy(w),&nbsp;b])\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;you&nbsp;can&nbsp;uncomment&nbsp;this&nbsp;line&nbsp;to&nbsp;check&nbsp;the&nbsp;process&nbsp;of&nbsp;stochastic&nbsp;gradient&nbsp;descent\r\n&nbsp;\r\n&nbsp;\r\ndef&nbsp;cal(item):\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;calculate&nbsp;the&nbsp;functional&nbsp;distance&nbsp;between&nbsp;\'item\'&nbsp;an&nbsp;the&nbsp;dicision&nbsp;surface.&nbsp;output&nbsp;yi(w*xi+b).\r\n&nbsp;&nbsp;&nbsp;&nbsp;:param&nbsp;item:\r\n&nbsp;&nbsp;&nbsp;&nbsp;:return:\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;res&nbsp;=&nbsp;0\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(len(item[0])):\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res&nbsp;+=&nbsp;item[0][i]&nbsp;*&nbsp;w[i]\r\n&nbsp;&nbsp;&nbsp;&nbsp;res&nbsp;+=&nbsp;b\r\n&nbsp;&nbsp;&nbsp;&nbsp;res&nbsp;*=&nbsp;item[1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;res\r\n&nbsp;\r\n&nbsp;\r\ndef&nbsp;check():\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;check&nbsp;if&nbsp;the&nbsp;hyperplane&nbsp;can&nbsp;classify&nbsp;the&nbsp;examples&nbsp;correctly\r\n&nbsp;&nbsp;&nbsp;&nbsp;:return:&nbsp;true&nbsp;if&nbsp;it&nbsp;can\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;flag&nbsp;=&nbsp;False\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;item&nbsp;in&nbsp;training_set:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;cal(item)&nbsp;&lt;=&nbsp;0:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;flag&nbsp;=&nbsp;True\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;update(item)\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;draw&nbsp;a&nbsp;graph&nbsp;to&nbsp;show&nbsp;the&nbsp;process\r\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;not&nbsp;flag:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print&nbsp;\"RESULT:&nbsp;w:&nbsp;\"&nbsp;+&nbsp;str(w)&nbsp;+&nbsp;\"&nbsp;b:&nbsp;\"&nbsp;+&nbsp;str(b)\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;flag\r\n&nbsp;\r\n&nbsp;\r\nif&nbsp;__name__&nbsp;==&nbsp;\"__main__\":\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1000):\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;not&nbsp;check():&nbsp;break\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;first&nbsp;set&nbsp;up&nbsp;the&nbsp;figure,&nbsp;the&nbsp;axis,&nbsp;and&nbsp;the&nbsp;plot&nbsp;element&nbsp;we&nbsp;want&nbsp;to&nbsp;animate\r\n&nbsp;&nbsp;&nbsp;&nbsp;fig&nbsp;=&nbsp;plt.figure()\r\n&nbsp;&nbsp;&nbsp;&nbsp;ax&nbsp;=&nbsp;plt.axes(xlim=(0,&nbsp;2),&nbsp;ylim=(-2,&nbsp;2))\r\n&nbsp;&nbsp;&nbsp;&nbsp;line,&nbsp;=&nbsp;ax.plot([],&nbsp;[],&nbsp;\'g\',&nbsp;lw=2)\r\n&nbsp;&nbsp;&nbsp;&nbsp;label&nbsp;=&nbsp;ax.text([],&nbsp;[],&nbsp;\'\')\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;initialization&nbsp;function:&nbsp;plot&nbsp;the&nbsp;background&nbsp;of&nbsp;each&nbsp;frame\r\n&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;init():\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;line.set_data([],&nbsp;[])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x,&nbsp;y,&nbsp;x_,&nbsp;y_&nbsp;=&nbsp;[],&nbsp;[],&nbsp;[],&nbsp;[]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;p&nbsp;in&nbsp;training_set:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;p[1]&nbsp;&gt;&nbsp;0:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x.append(p[0][0])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y.append(p[0][1])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x_.append(p[0][0])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y_.append(p[0][1])\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(x,&nbsp;y,&nbsp;\'bo\',&nbsp;x_,&nbsp;y_,&nbsp;\'rx\')\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.axis([-6,&nbsp;6,&nbsp;-6,&nbsp;6])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.grid(True)\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel(\'x\')\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel(\'y\')\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.title(\'Perceptron&nbsp;Algorithm&nbsp;(www.hankcs.com)\')\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;line,&nbsp;label\r\n&nbsp;\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;animation&nbsp;function.&nbsp;&nbsp;this&nbsp;is&nbsp;called&nbsp;sequentially\r\n&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;animate(i):\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;global&nbsp;history,&nbsp;ax,&nbsp;line,&nbsp;label\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;=&nbsp;history[i][0]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;=&nbsp;history[i][1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;w[1]&nbsp;==&nbsp;0:&nbsp;return&nbsp;line,&nbsp;label\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x1&nbsp;=&nbsp;-7\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y1&nbsp;=&nbsp;-(b&nbsp;+&nbsp;w[0]&nbsp;*&nbsp;x1)&nbsp;/&nbsp;w[1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x2&nbsp;=&nbsp;7\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y2&nbsp;=&nbsp;-(b&nbsp;+&nbsp;w[0]&nbsp;*&nbsp;x2)&nbsp;/&nbsp;w[1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;line.set_data([x1,&nbsp;x2],&nbsp;[y1,&nbsp;y2])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x1&nbsp;=&nbsp;0\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y1&nbsp;=&nbsp;-(b&nbsp;+&nbsp;w[0]&nbsp;*&nbsp;x1)&nbsp;/&nbsp;w[1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label.set_text(history[i])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label.set_position([x1,&nbsp;y1])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;line,&nbsp;label\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;call&nbsp;the&nbsp;animator.&nbsp;&nbsp;blit=true&nbsp;means&nbsp;only&nbsp;re-draw&nbsp;the&nbsp;parts&nbsp;that&nbsp;have&nbsp;changed.\r\n&nbsp;&nbsp;&nbsp;&nbsp;print&nbsp;history\r\n&nbsp;&nbsp;&nbsp;&nbsp;anim&nbsp;=&nbsp;animation.FuncAnimation(fig,&nbsp;animate,&nbsp;init_func=init,&nbsp;frames=len(history),&nbsp;interval=1000,&nbsp;repeat=True,\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blit=True)\r\n&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\r\n&nbsp;&nbsp;&nbsp;&nbsp;anim.save(\'perceptron.gif\',&nbsp;fps=2,&nbsp;writer=\'imagemagick\')<br></code></pre><p>可视化<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_pWOC89c.png\" width=\"800\" height=\"600\"><br></p><p>可见超平面被误分类点所吸引，朝着它移动，使得两者距离逐步减小，直到正确分类为止。通过这个动画，是不是对感知机的梯度下降算法有了更直观的感悟呢？<br></p><h4>算法的收敛性<br></h4><p>记输入向量加进常数1的拓充形式<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_8HX1ZAq.png\" width=\"90\" height=\"25\">，其最大长度为<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_tMS8d5O.png\" width=\"108\" height=\"36\">，记感知机的参数向量<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_Ydabhoz.png\" width=\"100\" height=\"28\">，设满足条件<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_62etCxh.png\" width=\"73\" height=\"36\">的超平面可以将数据集完全正确地分类，定义最小值伽马：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_2Rgsvmw.png\" width=\"281\" height=\"31\"><br></p><p>则误分类次数k满足：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_cu7k2hH.png\" width=\"99\" height=\"73\"><br></p><p>证明请参考《统计学习方法》P31。<br></p><h4>感知机学习算法的对偶形式<br></h4><p>对偶指的是，将w和b表示为测试数据i的线性组合形式，通过求解系数得到w和b。具体说来，如果对误分类点i逐步修改wb修改了n次，则w，b关于i的增量分别为<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_GszcMaI.png\" width=\"107\" height=\"23\">，这里<img alt=\"image.png\" src=\"/uploads/2017/12/25/image_ppkEB8g.png\" width=\"67\" height=\"22\">，则最终求解到的参数分别表示为：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_70GN5xJ.png\" width=\"116\" height=\"117\"></p><p>于是有算法2.2：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_pC7a3fq.png\" width=\"723\" height=\"457\"></p><p>感知机对偶算法代码</p><p>涉及到比较多的矩阵计算，于是用NumPy比较多：</p><pre><code>#&nbsp;-*-&nbsp;coding:utf-8&nbsp;-*-\r\n#&nbsp;Filename:&nbsp;train2.2.py\r\n#&nbsp;Author：hankcs\r\n#&nbsp;Date:&nbsp;2015/1/31&nbsp;15:15\r\nimport&nbsp;numpy&nbsp;as&nbsp;np\r\nfrom&nbsp;matplotlib&nbsp;import&nbsp;pyplot&nbsp;as&nbsp;plt\r\nfrom&nbsp;matplotlib&nbsp;import&nbsp;animation\r\n&nbsp;\r\n#&nbsp;An&nbsp;example&nbsp;in&nbsp;that&nbsp;book,&nbsp;the&nbsp;training&nbsp;set&nbsp;and&nbsp;parameters\'&nbsp;sizes&nbsp;are&nbsp;fixed\r\ntraining_set&nbsp;=&nbsp;np.array([[[3,&nbsp;3],&nbsp;1],&nbsp;[[4,&nbsp;3],&nbsp;1],&nbsp;[[1,&nbsp;1],&nbsp;-1]])\r\n&nbsp;\r\na&nbsp;=&nbsp;np.zeros(len(training_set),&nbsp;np.float)\r\nb&nbsp;=&nbsp;0.0\r\nGram&nbsp;=&nbsp;None\r\ny&nbsp;=&nbsp;np.array(training_set[:,&nbsp;1])\r\nx&nbsp;=&nbsp;np.empty((len(training_set),&nbsp;2),&nbsp;np.float)\r\nfor&nbsp;i&nbsp;in&nbsp;range(len(training_set)):\r\n&nbsp;&nbsp;&nbsp;&nbsp;x[i]&nbsp;=&nbsp;training_set[i][0]\r\nhistory&nbsp;=&nbsp;[]\r\n&nbsp;\r\ndef&nbsp;cal_gram():\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;calculate&nbsp;the&nbsp;Gram&nbsp;matrix\r\n&nbsp;&nbsp;&nbsp;&nbsp;:return:\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;=&nbsp;np.empty((len(training_set),&nbsp;len(training_set)),&nbsp;np.int)\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(len(training_set)):\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;j&nbsp;in&nbsp;range(len(training_set)):\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;g[i][j]&nbsp;=&nbsp;np.dot(training_set[i][0],&nbsp;training_set[j][0])\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;g\r\n&nbsp;\r\n&nbsp;\r\ndef&nbsp;update(i):\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;update&nbsp;parameters&nbsp;using&nbsp;stochastic&nbsp;gradient&nbsp;descent\r\n&nbsp;&nbsp;&nbsp;&nbsp;:param&nbsp;i:\r\n&nbsp;&nbsp;&nbsp;&nbsp;:return:\r\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\r\n&nbsp;&nbsp;&nbsp;&nbsp;global&nbsp;a,&nbsp;b\r\n&nbsp;&nbsp;&nbsp;&nbsp;a[i]&nbsp;+=&nbsp;1\r\n&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;=&nbsp;b&nbsp;+&nbsp;y[i]\r\n&nbsp;&nbsp;&nbsp;&nbsp;history.append([np.dot(a&nbsp;*&nbsp;y,&nbsp;x),&nbsp;b])\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;print&nbsp;a,&nbsp;b&nbsp;#&nbsp;you&nbsp;can&nbsp;uncomment&nbsp;this&nbsp;line&nbsp;to&nbsp;check&nbsp;the&nbsp;process&nbsp;of&nbsp;stochastic&nbsp;gradient&nbsp;descent\r\n&nbsp;\r\n&nbsp;\r\n#&nbsp;calculate&nbsp;the&nbsp;judge&nbsp;condition\r\ndef&nbsp;cal(i):\r\n&nbsp;&nbsp;&nbsp;&nbsp;global&nbsp;a,&nbsp;b,&nbsp;x,&nbsp;y\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;res&nbsp;=&nbsp;np.dot(a&nbsp;*&nbsp;y,&nbsp;Gram[i])\r\n&nbsp;&nbsp;&nbsp;&nbsp;res&nbsp;=&nbsp;(res&nbsp;+&nbsp;b)&nbsp;*&nbsp;y[i]\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;res\r\n&nbsp;\r\n&nbsp;\r\n#&nbsp;check&nbsp;if&nbsp;the&nbsp;hyperplane&nbsp;can&nbsp;classify&nbsp;the&nbsp;examples&nbsp;correctly\r\ndef&nbsp;check():\r\n&nbsp;&nbsp;&nbsp;&nbsp;global&nbsp;a,&nbsp;b,&nbsp;x,&nbsp;y\r\n&nbsp;&nbsp;&nbsp;&nbsp;flag&nbsp;=&nbsp;False\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(len(training_set)):\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;cal(i)&nbsp;&lt;=&nbsp;0:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;flag&nbsp;=&nbsp;True\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;update(i)\r\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;not&nbsp;flag:\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;=&nbsp;np.dot(a&nbsp;*&nbsp;y,&nbsp;x)\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print&nbsp;\"RESULT:&nbsp;w:&nbsp;\"&nbsp;+&nbsp;str(w)&nbsp;+&nbsp;\"&nbsp;b:&nbsp;\"&nbsp;+&nbsp;str(b)\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;False\r\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;True\r\n&nbsp;\r\n&nbsp;\r\nif&nbsp;__name__&nbsp;==&nbsp;\"__main__\":\r\n&nbsp;&nbsp;&nbsp;&nbsp;Gram&nbsp;=&nbsp;cal_gram()&nbsp;&nbsp;#&nbsp;initialize&nbsp;the&nbsp;Gram&nbsp;matrix\r\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1000):\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;not&nbsp;check():&nbsp;break\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;draw&nbsp;an&nbsp;animation&nbsp;to&nbsp;show&nbsp;how&nbsp;it&nbsp;works,&nbsp;the&nbsp;data&nbsp;comes&nbsp;from&nbsp;history\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;first&nbsp;set&nbsp;up&nbsp;the&nbsp;figure,&nbsp;the&nbsp;axis,&nbsp;and&nbsp;the&nbsp;plot&nbsp;element&nbsp;we&nbsp;want&nbsp;to&nbsp;animate\r\n&nbsp;&nbsp;&nbsp;&nbsp;fig&nbsp;=&nbsp;plt.figure()\r\n&nbsp;&nbsp;&nbsp;&nbsp;ax&nbsp;=&nbsp;plt.axes(xlim=(0,&nbsp;2),&nbsp;ylim=(-2,&nbsp;2))\r\n&nbsp;&nbsp;&nbsp;&nbsp;line,&nbsp;=&nbsp;ax.plot([],&nbsp;[],&nbsp;\'g\',&nbsp;lw=2)\r\n&nbsp;&nbsp;&nbsp;&nbsp;label&nbsp;=&nbsp;ax.text([],&nbsp;[],&nbsp;\'\')\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;initialization&nbsp;function:&nbsp;plot&nbsp;the&nbsp;background&nbsp;of&nbsp;each&nbsp;frame\r\n&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;init():\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;line.set_data([],&nbsp;[])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x,&nbsp;y,&nbsp;x_,&nbsp;y_&nbsp;=&nbsp;[],&nbsp;[],&nbsp;[],&nbsp;[]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;p&nbsp;in&nbsp;training_set:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;p[1]&nbsp;&gt;&nbsp;0:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x.append(p[0][0])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y.append(p[0][1])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x_.append(p[0][0])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y_.append(p[0][1])\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(x,&nbsp;y,&nbsp;\'bo\',&nbsp;x_,&nbsp;y_,&nbsp;\'rx\')\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.axis([-6,&nbsp;6,&nbsp;-6,&nbsp;6])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.grid(True)\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel(\'x\')\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel(\'y\')\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.title(\'Perceptron&nbsp;Algorithm&nbsp;2&nbsp;(www.hankcs.com)\')\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;line,&nbsp;label\r\n&nbsp;\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;animation&nbsp;function.&nbsp;&nbsp;this&nbsp;is&nbsp;called&nbsp;sequentially\r\n&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;animate(i):\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;global&nbsp;history,&nbsp;ax,&nbsp;line,&nbsp;label\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;=&nbsp;history[i][0]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;=&nbsp;history[i][1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;w[1]&nbsp;==&nbsp;0:&nbsp;return&nbsp;line,&nbsp;label\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x1&nbsp;=&nbsp;-7.0\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y1&nbsp;=&nbsp;-(b&nbsp;+&nbsp;w[0]&nbsp;*&nbsp;x1)&nbsp;/&nbsp;w[1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x2&nbsp;=&nbsp;7.0\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y2&nbsp;=&nbsp;-(b&nbsp;+&nbsp;w[0]&nbsp;*&nbsp;x2)&nbsp;/&nbsp;w[1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;line.set_data([x1,&nbsp;x2],&nbsp;[y1,&nbsp;y2])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x1&nbsp;=&nbsp;0.0\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y1&nbsp;=&nbsp;-(b&nbsp;+&nbsp;w[0]&nbsp;*&nbsp;x1)&nbsp;/&nbsp;w[1]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label.set_text(str(history[i][0])&nbsp;+&nbsp;\'&nbsp;\'&nbsp;+&nbsp;str(b))\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label.set_position([x1,&nbsp;y1])\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;line,&nbsp;label\r\n&nbsp;\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;call&nbsp;the&nbsp;animator.&nbsp;&nbsp;blit=true&nbsp;means&nbsp;only&nbsp;re-draw&nbsp;the&nbsp;parts&nbsp;that&nbsp;have&nbsp;changed.\r\n&nbsp;&nbsp;&nbsp;&nbsp;anim&nbsp;=&nbsp;animation.FuncAnimation(fig,&nbsp;animate,&nbsp;init_func=init,&nbsp;frames=len(history),&nbsp;interval=1000,&nbsp;repeat=True,\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blit=True)\r\n&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\r\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;anim.save(\'perceptron2.gif\',&nbsp;fps=2,&nbsp;writer=\'imagemagick\')<br></code></pre><p>可视化：</p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_A8m6gb1.png\" width=\"815\" height=\"615\"><br></p><p>与算法1的结果相同，我们也可以将数据集改一下：<br></p><p>training_set&nbsp;=&nbsp;np.array([[[3,&nbsp;3],&nbsp;1],&nbsp;[[4,&nbsp;3],&nbsp;1],&nbsp;[[1,&nbsp;1],&nbsp;-1],&nbsp;[[5,&nbsp;2],&nbsp;-1]])<br></p><p>会得到一个复杂一些的结果：<br></p><p><img alt=\"image.png\" src=\"/uploads/2017/12/25/image_PXbCHI4.png\" width=\"800\" height=\"600\"><br></p><p>读后感<br></p><p>通过最简单的模型，学习到ML中的常用概念和常见流程。<br></p>',1,'2017-12-25 14:08:00','2017-12-25 14:22:15',0,'http://www.hankcs.com/ml/the-perceptron.html','wang','admin',1010);
/*!40000 ALTER TABLE `ai_article` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `ai_cate`
--

DROP TABLE IF EXISTS `ai_cate`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `ai_cate` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(20) COLLATE utf8_unicode_ci NOT NULL,
  `enname` varchar(30) COLLATE utf8_unicode_ci NOT NULL,
  `ai_cate_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `name` (`name`)
) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `ai_cate`
--

LOCK TABLES `ai_cate` WRITE;
/*!40000 ALTER TABLE `ai_cate` DISABLE KEYS */;
INSERT INTO `ai_cate` VALUES (1,'机器学习','machinelearning',1),(2,'自然语言处理','nlp',2),(3,'机器视觉','machinevision',3),(4,'语音识别','voicerecognition',4),(5,'机器人','robot',5),(6,'无人驾驶','autodrive',6);
/*!40000 ALTER TABLE `ai_cate` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `ai_subcate`
--

DROP TABLE IF EXISTS `ai_subcate`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `ai_subcate` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(20) COLLATE utf8_unicode_ci NOT NULL,
  `enname` varchar(30) COLLATE utf8_unicode_ci NOT NULL,
  `summary` text COLLATE utf8_unicode_ci NOT NULL,
  `ai_subcate_id` int(11) NOT NULL,
  `ai_cate_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `name` (`name`)
) ENGINE=InnoDB AUTO_INCREMENT=11 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `ai_subcate`
--

LOCK TABLES `ai_subcate` WRITE;
/*!40000 ALTER TABLE `ai_subcate` DISABLE KEYS */;
INSERT INTO `ai_subcate` VALUES (1,'线性回归','linearregression','样本数据中因变量与自变量的关系大体呈线性的一种回归分析',1001,1),(2,'逻辑回归','logisticregression','将数据拟合到一个Logistic函数进行分类的算法',1002,1),(3,'决策树','decesiontree','通过递归选取最大熵增的特征对数据进行分类的一种决策方法',1003,1),(4,'支持向量机','svm','通过间隔最大化实现数据分类的一种监督学习算法',1004,1),(5,'朴素贝叶斯','naivebayes','根据先验概率最大进行分类的算法',1005,1),(6,'k近邻','knn','根据样本最邻近的k个样本的类别进行分类的算法',1006,1),(7,'k均值','kmeans','选取K个聚类中心并不断调整至最佳的分类算法',1007,1),(8,'AdaBoost','adaboost','通过多个弱分类器组合成一个强分类器',1008,1),(9,'EM算法','em','对带有预估参数的变量求最大期望来不断优化预估参数',1009,1),(10,'感知机','perceptron','通过求最小的损失函数获取一个将训练数据的正负实例完全分开的超平面',1010,1);
/*!40000 ALTER TABLE `ai_subcate` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `ai_user`
--

DROP TABLE IF EXISTS `ai_user`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `ai_user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `password` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `reg_date` datetime DEFAULT NULL,
  `last_login` datetime DEFAULT NULL,
  `name` varchar(30) COLLATE utf8_unicode_ci NOT NULL,
  `email` varchar(254) COLLATE utf8_unicode_ci NOT NULL,
  `phone` int(11) NOT NULL DEFAULT '0',
  `qq` int(11) NOT NULL DEFAULT '0',
  `weixin` varchar(30) COLLATE utf8_unicode_ci NOT NULL,
  `username` varchar(150) COLLATE utf8_unicode_ci NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `username` (`username`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `ai_user`
--

LOCK TABLES `ai_user` WRITE;
/*!40000 ALTER TABLE `ai_user` DISABLE KEYS */;
INSERT INTO `ai_user` VALUES (1,'111111','2017-12-03 00:00:00',NULL,'','xqnq2007@163.com',0,0,'','admin');
/*!40000 ALTER TABLE `ai_user` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_group`
--

DROP TABLE IF EXISTS `auth_group`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_group` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(80) COLLATE utf8_unicode_ci NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `name` (`name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_group`
--

LOCK TABLES `auth_group` WRITE;
/*!40000 ALTER TABLE `auth_group` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_group` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_group_permissions`
--

DROP TABLE IF EXISTS `auth_group_permissions`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_group_permissions` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `group_id` int(11) NOT NULL,
  `permission_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `auth_group_permissions_group_id_0cd325b0_uniq` (`group_id`,`permission_id`),
  KEY `auth_group_permissions_0e939a4f` (`group_id`),
  KEY `auth_group_permissions_8373b171` (`permission_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_group_permissions`
--

LOCK TABLES `auth_group_permissions` WRITE;
/*!40000 ALTER TABLE `auth_group_permissions` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_group_permissions` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_permission`
--

DROP TABLE IF EXISTS `auth_permission`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_permission` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `content_type_id` int(11) NOT NULL,
  `codename` varchar(100) COLLATE utf8_unicode_ci NOT NULL,
  `name` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `auth_permission_content_type_id_01ab375a_uniq` (`content_type_id`,`codename`),
  KEY `auth_permission_417f1b1c` (`content_type_id`)
) ENGINE=InnoDB AUTO_INCREMENT=46 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_permission`
--

LOCK TABLES `auth_permission` WRITE;
/*!40000 ALTER TABLE `auth_permission` DISABLE KEYS */;
INSERT INTO `auth_permission` VALUES (1,1,'add_logentry','Can add log entry'),(2,1,'change_logentry','Can change log entry'),(3,1,'delete_logentry','Can delete log entry'),(4,2,'add_permission','Can add permission'),(5,2,'change_permission','Can change permission'),(6,2,'delete_permission','Can delete permission'),(7,3,'add_group','Can add group'),(8,3,'change_group','Can change group'),(9,3,'delete_group','Can delete group'),(10,4,'add_user','Can add user'),(11,4,'change_user','Can change user'),(12,4,'delete_user','Can delete user'),(13,5,'add_contenttype','Can add content type'),(14,5,'change_contenttype','Can change content type'),(15,5,'delete_contenttype','Can delete content type'),(16,6,'add_session','Can add session'),(17,6,'change_session','Can change session'),(18,6,'delete_session','Can delete session'),(19,7,'add_article','Can add 文章'),(20,7,'change_article','Can change 文章'),(21,7,'delete_article','Can delete 文章'),(22,8,'add_comment','Can add 评论'),(23,8,'change_comment','Can change 评论'),(24,8,'delete_comment','Can delete 评论'),(25,9,'add_category','Can add 版块'),(26,9,'change_category','Can change 版块'),(27,9,'delete_category','Can delete 版块'),(28,10,'add_userprofile','Can add 用户'),(29,10,'change_userprofile','Can change 用户'),(30,10,'delete_userprofile','Can delete 用户');
/*!40000 ALTER TABLE `auth_permission` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_user`
--

DROP TABLE IF EXISTS `auth_user`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `password` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `last_login` datetime DEFAULT NULL,
  `is_superuser` tinyint(1) NOT NULL,
  `first_name` varchar(30) COLLATE utf8_unicode_ci NOT NULL,
  `last_name` varchar(30) COLLATE utf8_unicode_ci NOT NULL,
  `email` varchar(254) COLLATE utf8_unicode_ci NOT NULL,
  `is_staff` tinyint(1) NOT NULL,
  `is_active` tinyint(1) NOT NULL,
  `date_joined` datetime NOT NULL,
  `username` varchar(150) COLLATE utf8_unicode_ci NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `username` (`username`)
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_user`
--

LOCK TABLES `auth_user` WRITE;
/*!40000 ALTER TABLE `auth_user` DISABLE KEYS */;
INSERT INTO `auth_user` VALUES (1,'pbkdf2_sha256$36000$Cr0YDDYDrejV$V7+vP3L6LJUoR8T3eOh2TqZ9O/kKctCKNKqBLGg2nqo=','2018-02-02 12:38:11',1,'','','',1,1,'2016-06-10 10:46:14','admin'),(2,'pbkdf2_sha256$24000$C1IKJKB4gZzt$W1hNIKIyt8+X9lCn1d24xh8RgfCljh3jUfeO9PEa3GY=','2016-06-10 11:19:31',0,'','','',0,1,'2016-06-10 10:51:24','alex'),(3,'pbkdf2_sha256$24000$6WuN8wsVSF6w$WBXIfbXlvq0ao3XYv2FK/30Yw4iGr1tkwfPrHKDGocQ=','2016-06-10 11:20:40',0,'','','',0,1,'2016-06-10 10:51:45','eric'),(4,'pbkdf2_sha256$24000$c0b7GnXlzzrO$hcqSvoaUB8WmgV/b4y5xFvxR0CgOADkfh7RZCbkI8f0=','2016-06-10 11:21:39',0,'','','',0,1,'2016-06-10 10:57:47','zengchunyun');
/*!40000 ALTER TABLE `auth_user` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_user_groups`
--

DROP TABLE IF EXISTS `auth_user_groups`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_user_groups` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NOT NULL,
  `group_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `auth_user_groups_user_id_94350c0c_uniq` (`user_id`,`group_id`),
  KEY `auth_user_groups_0e939a4f` (`group_id`),
  KEY `auth_user_groups_e8701ad4` (`user_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_user_groups`
--

LOCK TABLES `auth_user_groups` WRITE;
/*!40000 ALTER TABLE `auth_user_groups` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_user_groups` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_user_user_permissions`
--

DROP TABLE IF EXISTS `auth_user_user_permissions`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_user_user_permissions` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NOT NULL,
  `permission_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `auth_user_user_permissions_user_id_14a6b632_uniq` (`user_id`,`permission_id`),
  KEY `auth_user_user_permissions_8373b171` (`permission_id`),
  KEY `auth_user_user_permissions_e8701ad4` (`user_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_user_user_permissions`
--

LOCK TABLES `auth_user_user_permissions` WRITE;
/*!40000 ALTER TABLE `auth_user_user_permissions` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_user_user_permissions` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bbs_article`
--

DROP TABLE IF EXISTS `bbs_article`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bbs_article` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  `brief` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `content` text COLLATE utf8_unicode_ci NOT NULL,
  `pub_date` datetime DEFAULT NULL,
  `last_modify` datetime NOT NULL,
  `priority` int(11) NOT NULL,
  `head_img` varchar(100) COLLATE utf8_unicode_ci NOT NULL,
  `status` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `author_id` int(11) NOT NULL,
  `category_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `bbs_article_4f331e2f` (`author_id`),
  KEY `bbs_article_b583a629` (`category_id`)
) ENGINE=InnoDB AUTO_INCREMENT=20 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bbs_article`
--

LOCK TABLES `bbs_article` WRITE;
/*!40000 ALTER TABLE `bbs_article` DISABLE KEYS */;
INSERT INTO `bbs_article` VALUES (1,'分答的世界尽头与冷酷仙境','这才一个月，分答团队也许该开始考虑取舍了','有段时间没出现这样的现象级产品了。就分答的现状，分析已经很多，颇有一些共识。老问题也被重新提起：共享经济怎么搞，知识该不该收费等等。\n\n\n\n知识论斤卖还是论个卖\n\n\n\n分答一开张就收费，尤为引人注目，甚至被笑吃相难看。但吃相不重要，重要的是安利什么内容。如同给年轻人做职业咨询，总是建议先想清楚五年十年后的规划，再反推现在的抉择。分答的愿景也要放在更大的趋势中讨论。\n\n\n\n互联网发展至今，貌似免费是趋势。其实只是信息的复制成本趋近于零，而知识的生产成本更高了好嘛，创新就更稀缺。要覆盖成本、创造营收，目前主流模式是第三方付费，所谓“羊毛出在猪身上”。这种模式的关键在于，获得足够多的免费受众，用数量的微利变现，来覆盖知识生产的高额成本。','2016-06-10 10:55:00','2016-06-10 10:55:54',1000,'uploads/101547843513_1.jpg','published',1,2),(2,'《大圣归来》之后为何没再出动画爆款？细数中国动画产业背后的尴尬','原创动画公司生存压力大，投入高、变现能力差','近期，米粒影业爆出C轮40亿估值，树立了中国动画公司估值的新标杆。算的上是自去年的《大圣归来》以来中国动画产业的又一小高潮。借着IP热、二次元热、VR热等东风，动画这个之前不怎么受待见的行业就逐渐变得热闹起来。\n\n\n\n背靠资本市场弹药库的上市公司、拥有丰厚现金流的游戏公司开始在动漫领域接连发力，投资案例此起彼伏。而动画电影的立项备案也开始大干快上。仅今年至3月底即有75部动画电影备案。\n\n\n\n不过扭头看了看三板挂牌的三十余家动画企业的报表，画风有点不对。14年收入破亿的有四家，收入小于50万占近三分之一。利润破亿的仅一家，一半亏损。当然三板鱼龙混杂不能代表全部，但我们拜访的不少动画行业佼佼者中也鲜见盈利者。\n\n\n\n那么问题来了，中国动画产业到底是个什么情况？产业链是怎样划分的？具体的变现模式如何？','2016-06-10 10:56:00','2016-06-10 10:57:14',1000,'uploads/102624642790_1.jpg','published',2,2),(3,'考拉FM大裁员，印证了移动电台的寒冬？','裁员40人，上午通知，下午办手续，这么大动作不过是两个星期前的决定','考拉FM，这个曾被誉为“音频七雄”之一的移动电台，几乎只用了一上午的时间，就完成了成立以来最大规模的一次裁员。\n\n\n\n今天，小娱偶然发现一位考拉FM的编辑在朋友圈发了离职的消息。后来一打听才知道，这并不是一次主动离职，而是考拉裁员，“整个考拉音娱中心全被撤掉”。\n\n\n\n分析这次人事变动背后的原因，其实逻辑并不难理解。一方面是音乐版权费用高，跟移动音乐APP相比，移动网络电台的音乐并不具备更大的优势。\n\n\n\n另一方面，在考拉FM营收有限的情况下，砍掉占成本比重达9%的音娱板块，可以把更大的精力和资金，重点用在发展车载音频的研发和实验上。\n\n对于考拉来说，整个车联网上考拉算较有先发优势的，比如其上游端背靠的是车语传媒，有交通电台广告代理、整频运营两项业务（据悉已是传统广播的前三）；下游端在车联网中（消费场景端），又与十几家汽车厂商达成了合作。\n\n\n\n但是，目前车联网的盈利前景，受制于硬件条件，仍遥遥无期。','2016-06-10 10:59:00','2016-06-10 10:59:53',1000,'uploads/105744052646_1.jpg','published',4,3),(5,'为什么看好直播+电商？这里有两大理由，以及四个技术难题','离开秀场模式，电商的直播会颠覆现有场景和关系','如日中天的直播业务，正在与不同互联网行业结合起来，形成“直播+”经济。\n\n\n\n直播+娱乐已很成熟，PC时代的9158做到上市，移动端的陌陌直播业务上线一年不到，已成主要营收来源，直播+娱乐吸金能力可见一斑。直播+营销被许多综合类直播平台所看重，越来越多的品牌开始在美拍等平台砸钱做营销，取得不错效果。还有一个正在崛起的则是“直播+电商”，通过直播卖东西被坊间热议，前几天看到虎嗅上有一篇文章说，直播+电商是绕过BAT的另一个机会，有人对此不以为然，认为直播+电商是一个伪命题，更别说要绕过BAT了。\n\n\n\n不看好直播电商的大抵有两种逻辑：\n\n\n\n一是直播+电商效果不好。直播+电商，本质就是电视+电商，即所谓的T2O模式（TV to Online）模式，连电视这么强势的媒体都玩不转，更别说直播。眼下直播+电商带来销量很困难，销量是电商的终极目标。\n\n\n\n二是直播只是宣传方式，跟文字、图片等没有本质区别，而电商的商业本质并没有变化，过去并不存在着文字+电商，图片+电商的说法，“直播+电商”只是一个伪概念。\n\n\n\n对于上述两种逻辑，笔者均不以为然。\n\n\n\n电视媒体做电商不成功，与直播+电商能否成功并无必然联系，直播看上去确实就是“互联网电视台”，但移动互联网让它又完全不同于传统电视，还有关键要看谁来做这个事情。认为直播是宣传方式的，说的其实是直播+营销。如果阿里巴巴等巨头接受了直播+电商，就完全不一样了，直播不是宣传方式，而是电商的基础设施，如同购物车、商品图片一样，不可或缺。','2016-06-10 11:01:00','2016-06-10 11:01:44',1000,'uploads/185202536951_1.jpg','published',3,5),(6,'我们迎来了不仅答案不对，连问题都不对的时代','问题都由别人来提出，答案就不要试图自己想了','两天前的晚上，我与朋友们展开了一场讨论。这场讨论很快激烈起来，并很快扩散到各自的朋友圈，引来了一些同行的围观。\n\n\n\n我们争论的问题很简单——我们要不要代替读者提出问题？说得简单一些，在读者点击一篇文章之前，他看到的首先是文章的标题。在这个标题里，我们需要把文章的矛盾集中体现，用一个问句带出来吗？\n\n\n\n比如这样：《黑人在 Airbnb 上租不到房？房东：没那么严重》\n\n\n\n有人认为，在标题提出问题，会明确告知读者文章在讲什么事情，从而吸引他们的兴趣。但也有人认为，这种标题只能让读者记住内容，却无法让人记住文章本身。\n\n\n\n无可争辩的是，提问式的标题是一个保险，是保证点击的一种主流方法。一个精雕细琢，结合文章内容「总结」「凝练」乃至「升华」出来的标题，十分适合看完正文以后令人回味，对根本连正文也不看的人却毫无意义。大家都那么忙，利用碎片时间读些可看可不看的文章，标题的首要目的应该是激发读者兴趣、让他点进来再说，而非怀着「你既然看到这篇文就一定会认真阅读」的天真期待。\n\n\n\n不过，值得顾虑之处在于，代替读者提问、代替读者思考，写作者自身将会逐渐扮演一个「重要而非必要」的角色——他可以展示自己的价值，却无法凸显自己的存在。假如通过模式化、套路化的标题就可树立形象吸引粉丝，那么任何出产内容的人，通过套路都可吸引粉丝了。粉丝最终会流向何方，答案也显而易见——谁也无法留住这么轻易就得来的东西。','2016-06-10 11:02:00','2016-06-10 11:02:45',1000,'uploads/215705606997_1.jpg','published',1,6),(8,'《魔兽》之后或许是《英雄联盟》','试水成功后，腾讯表示“不排除”将《英雄联盟》影视化','在《魔兽》取得首日大捷后，不禁让业界思考谁会成为下一个影游联动的主角？腾讯给出的一种可能的答案是：《英雄联盟》。\n\n\n\n“为了部落”，“为了联盟”是最近朋友圈等社交网络中，被刷屏频率最高的词汇。根据6月8日的最新数据统计，《魔兽》凭借1.3万场的排片量，零点场票房达到了5540万元，超越《速激7》5247万元的新纪录。目前，豆瓣上的《魔兽》评分也被粉丝们刷到了8.9分的高分。\n\n\n\n《魔兽》是腾讯影业参与投资的第二部作品，相比于参与投资的首部作品《火影忍者》，《魔兽》无论是在大众影响力、票房规模上都更具规模，案例也更具说服力。\n\n\n\n在完成《魔兽》电影项目的积累后，腾讯方面表示，不排除将《英雄联盟》进行影视化改编的可能性，但要尊重游戏IP开发运营的规律，目前还没到释放影视价值的阶段，而在整个开发运营的过程中更要尊重拳头的意见。','2016-06-10 11:05:00','2016-06-10 11:05:28',1000,'uploads/111749379200.jpg','published',3,5),(9,'暴雪的秘密','除了“暴雪出品必属精品”，暴雪的秘密还有更多','“美国进口礼盒装大菠萝3个，精装典藏你懂的！”淘宝上，标价2488元的一个菠萝图片旁边这样写道。5月，淘宝页面上突然多了一溜奇怪的菠萝图片，配上一句心照不宣的神秘暗语。大菠萝3，是电子游戏开发商暴雪娱乐公司5月15日新发售的RPG游戏《暗黑破坏神3》（Diablo III）的谐音。\n\n\n\n在《暗黑3》上市前就有分析师就预测，这游戏在今年年内将售出350万份。\n\n\n\n年内？你太天真了少年。《暗黑3》发售首日销量就突破了350万份，首周销量超过630万，成为PC游戏史上首日和首周销量最高的游戏。这些统计里，还没包括参与暴雪另一促销活动中中奖的120多万名玩家。\n\n\n\n过去20年里，全球游戏业经历了从最初的任天堂红白机的风靡到Westwood、3DO等单机游戏工作室辉煌一时又逐渐没落，再到网络游戏时代EA、维旺迪等游戏巨头们逐鹿江湖。风云变幻中无数曾经伟大的工作室和他们的经典作品都成为了历史。唯有暴雪公司，在20年里从最初只有3个人的工作室成长为全球游戏业的巨人，依靠《魔兽争霸》、《暗黑破坏神》、《星际争霸》、《魔兽世界》等一系列经典作品，在全球游戏玩家当中赢得“暴雪出品，必属精品”的口碑，把自己推上了游戏帝国的地位。','2016-06-10 11:06:00','2016-06-10 11:06:33',1000,'uploads/0718054mpmhljbzlcjxvjb.jpg','published',4,6),(10,'把人脑比做计算机，让意识永生？半个世纪我们都错了？','这是一个我们都在讲的故事。','无论他们怎样努力，大脑科学家和认知心理学家永远没办法在人脑里找到贝多芬第五交响曲的拷贝文件――单词、图像、语法规则或其他任何的环境感知也是如此。当然，人脑并不是空空荡荡的。但是人脑并不包含大部分人们认为它含有的东西――甚至简单如“内存”都没有。\n\n\n\n我们关于人脑的粗略理解，有着悠久的历史根源，但是1940年代计算机的发明让我们变得尤其疑惑。在超过一个半世纪的时间里，心理学家、语言学家、神经科学家和其他人类行为的学者专家认为，人脑像计算机一样工作。\n\n\n\n这种说法欠缺考虑，我们来试想一下婴儿的大脑。因为进化的关系，人类新生儿，和任何哺乳动物的新生婴儿一样，在来到这个世界的时候已经准备好有效地与之互动。婴儿的视觉是模糊的，但是对人脸会有特别的注意力，而且能够很快地分辨自己的母亲，更倾向语言的声音，而不是语言之外的声音，能够将一个基本的有语义的声音，从其他的声音中区别出来。我们人类，毫无疑问，生来就要建立社会连接。\n\n\n\n一个健康的新生儿，也具有其他许多的感知能力——对于生存来说十分重要的、与生俱来的某些反应。比如会把头转向抚摸脸部的方向，吮吸进到嘴里的任何东西，浸入水中的时候则憋住呼吸，紧紧攥住手里的东西，握力几乎能够支持自己的体重。最重要的是，新生儿都具有强大的学习机制，能够让他们很快地做出改变，与周围的世界有效互动。尽管和人类祖先所面对的环境相比，这个世界已经非常不同了。','2016-06-10 11:07:00','2016-06-10 11:07:27',1000,'uploads/064903700884.jpg','published',1,2),(11,'分答对标的不是知乎也不是微博，而是电竞主播们的肉松饼','如果有人巴望着靠分答这个新平台起飞的话，该冷静冷静了','<p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;>剩下的就是站内流量，目前看，<span style=font-weight: 700;>分答在站内为不同答主提供的流量，与这些答主从站外带来的流量相比，几乎可以忽略不计。</span></p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;><br></p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;>我统计了一下，这些分答红人的流量“来源”大概有那么几类<span class=text-remarks label=备注 style=color: rgb(153, 153, 153);>（详细排名和统计附在文章后）</span>：</p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;><br></p><ul class= list-paddingleft-2 style=margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding: 0px 0px 0px 15px; list-style-type: none; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;><li><p style=margin-bottom: 0px;><span style=font-weight: 700;>社会地位</span><span class=text-remarks label=备注 style=color: rgb(153, 153, 153);>（代表如王思聪、章子怡）</span></p></li><li><p style=margin-bottom: 0px;><span style=font-weight: 700;>专业身份</span><span class=text-remarks label=备注 style=color: rgb(153, 153, 153);>（如医生属于这一类，能够解决刚需的）</span></p></li><li><p style=margin-bottom: 0px;><span style=font-weight: 700;>其他平台的KOL</span><span class=text-remarks label=备注 style=color: rgb(153, 153, 153);>（知乎、微信公众号、微博……）</span></p></li></ul><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;><br></p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;>至少目前来看，还没有人能真正依靠“知识”或者说“内容”在分答取得可观流量，要靠自身向分答导入流量。</p>','2016-02-15 00:00:00','2016-06-10 11:46:10',1000,'uploads/1141199257.jpg','published',4,2),(12,'小鱼多莉能为皮克斯扳回一局吗？数据说话，也许可以','映前的统计数据与《疯狂动物城》接近','<p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;>时隔4年，皮克斯再度驾临暑期档：《海底总动员2：寻找多莉》将成为今年第4部中美同步公映的动画电影，稍早则是《功夫熊猫3》、《疯狂动物城》和《愤怒的小鸟》；而打入寸土寸金的6月也是自《勇敢传说》以来所仅见，彼时正是初次“国产保护月”大幕拉开的前夜。</p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;><img src=data:image/jpeg;base64,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 data-filename=142304146323.jpg style=width: 666px;><br></p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;>作为世界上最为知名的动画厂牌之一，成立30年的皮克斯迄今共出品了16部长片作品，全球票房累计已达96.995亿美元，市场影响力毋庸置疑。不过在和迪斯尼联姻10年之后，<span style=font-weight: 700;>皮克斯为人称道的“原创”标签正在逐渐剥落，取而代之的是经典作品“系列化”的路线</span>，而《海底总动员2：寻找多莉》便是这波续集大潮中的开山之作。关于皮克斯未来的制作计划，可点击文末“阅读原文”了解。<br></p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;><br></p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;>但在国内，皮克斯却一直困于停滞不前的票房怪圈中：截至目前，2013年上映的《怪兽大学》依旧以20967.42万人民币位居皮克斯内部首位，<span style=font-weight: 700;>这一成绩在当时尚且能排在动画序列的第6位，但现在已经被甩出前20名了</span>。</p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;><br></p><p style=margin-bottom: 0px; color: rgb(51, 51, 51); font-family: Arial, 微软雅黑, \'Microsoft yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', \'Microsoft Yahei\', \'Hiragino Sans GB\', \'冬青黑体简体中文 w3\', STXihei, 华文细黑, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 16px; line-height: 30px;>可堪比较的是，师出同门迪斯尼的《疯狂动物城》已将类型标杆提升至15亿的高位，而去年延后3个半月上映的《头脑特工队》却连破亿的目标都未能达成，沦为“叫好不叫座”现象的又一牺牲品。</p><div><br></div>','2016-02-15 00:00:00','2016-06-10 11:55:26',1000,'uploads/093837004854.jpg','published',4,5),(17,'击败了DotA2顶级玩家，这意味着AI的又一次突破吗？',NULL,'当我昨天看到OpenAI的人工智能，在一项奖金2400万美元的电子竞技赛事上，击败DotA2人类顶级高手时，整个人感觉超兴奋。\r\n\r\n这是因为，一方面我是一个电子竞技的粉丝。尽管没玩过DotA 2，但我经常在Twitch上观看其他其他电竞赛事，高中时我还当过一阵半职业选手。\r\n\r\n更重要是的，像DotA这类多人在线战术竞技游戏（MOBA），以及星际2这类实时策略游戏（RTS），通常被认为远超目前人工智能的驾驭能力。因为这两类游戏需要长期战略决策、多人合作，比国际象棋、围棋有着更复杂的状态和动作空间。\r\n\r\nDeepMind已经在星际2上研究了一段时间，前不久刚刚发布了新的进展，但目前为止，相关研究还没有取得重大突破。大家普遍认为，距离人工智能在星际2上吊打人类顶级玩家，至少还有一两年的时间。\r\n\r\n这就是OpenAI这个成果如此令人震惊的原因。这是怎么回事？最有有什么人工智能方面的突破是我没有注意到的么？于是我开始研究这个DotA 2人工智能到底干了什么，它是如何训练的，以及在什么样的游戏环境中运行。\r\n\r\n我的结论是：这是一个令人印象深刻的成就。但不是一次AI上的突破。\r\n\r\n通过这篇文章，我想提供一个关于此事的清醒解释。实际上，过度炒作人工智能的进步才是真正危险的事情。例如，下面这位在推特上的发言，才是真正的误导。\r\n\r\n\r\n\r\n这是伊隆·马斯克的推特，这位硅谷钢铁侠不单创办了特斯拉，而且创办了OpenAI。上面这篇推特中，马斯克大意是说：OpenAI搞出了史上首个击败电子竞技顶级玩家的人工智能。这比搞国际象棋和围棋什么的复杂多了。\r\n\r\n\r\n在第二条推特中，马斯克再次发表曾被AI届猛轰的观点：没人喜欢被管制，但对公众构成危险的一切（汽车、飞机、食品、药物等）都应该受到管制。AI也是一样。\r\n\r\n当然，马斯克还发了一条，就不翻译了，贴图如下\r\n\r\n\r\n\r\n首先要声明的是，我今天要谈及的炒作或者误导，并不是OpenAI研究人员的错误。OpenAI一直在研究方面都有诸多贡献。目前，OpenAI还没有公布他们解决方案的细节，所以外界很容易就会得出错误的结论。\r\n\r\n现在开始切入正题。我们先来看看DotA 2的人工智能程序，到底解决了一个多困难的问题？尤其是与AlphaGo相比。\r\n\r\n1v1不能与5v5相提并论\r\n\r\n在正常的DotA 2游戏中，两个对抗的队伍各由五名玩家组成。游戏过程中需要高级策略、团队沟通和协调，一局比赛通常要45分钟。\r\n\r\n而这次人工智能击败人类的比赛，采用了1v1的模式，这种模式有太多限制。例如双方基本上只能沿着单线前进，并尝试击杀对方，游戏过程几分钟就结束了。\r\n\r\n在1v1模式中，击败对手主要靠机械技能和短期策略，并不涉及长期规划和协调，而后者才是对当前AI技术来说最具挑战性的部分。\r\n\r\n事实上，在这次的人机DotA 2对抗中，可以采用的有效动作数量，少于围棋人机大战；有效的状态空间（目前局面情况），如果以智能的方式表示，应该比围棋要小。\r\n\r\nAI可以获取更多信息\r\n\r\nOpenAI的人工智能程序，极有可能是构建在DotA 2原有的机器人接口之上，可以获取更多人类玩家看不到的信息。即使OpenAI的研究人员限制了这些信息的获取，人工智能仍然能够得到比人类更精准的信息。\r\n\r\n例如技能的施放，人类玩家必须紧盯屏幕，并且估算与对手之间的距离。而AI知道确切的距离，并且能立即决定是否施放技能。获得精准的数字信息是一个很大的优势。其实对战过程中你就能看到，AI有几次攻击都是在最大距离上展开。\r\n\r\n反应时间\r\n\r\nAI可以立即作出反应，人类不行。再加上刚才说的信息优势，AI的优势进一步扩大了。比方，一旦对手逃离攻击范围，AI可以立刻取消攻击命令。\r\n\r\n使用单一英雄\r\n\r\nDotA 2中有上百种不同的英雄角色，各具不同的能力和优势。而AI掌握的只是其中一个英雄：Shadow Fiend（影魔）。影魔通常会立刻展开攻击，而不是在一段时间内学习掌握更复杂的攻击技能，这更加有利于发挥AI在信息和反应方面的优势。\r\n\r\n所以，鉴于1v1主要比拼机械技能，AI击败人类玩家并不奇怪。鉴于游戏环境被严格限制，造成一些列战术和策略也被限制，而且对战中几乎没有必要进行长期规划或协调。\r\n\r\n\r\n\r\n再次重申我的结论：这次AI击败DotA玩家，比在围棋中击败人类冠军要容易得多。人类没有在AI领域突然取得突破。\r\n\r\n这次在DotA对抗中之所以AI获胜，是因为研究人员聪明的设置了问题，使得AI可以绕过目前人工智能的技术限制。\r\n\r\n据说这个OpenAI训练这个AI打DotA花了2周。与之相比，AlphaGo在Google的GPU集群上进行了数月的分布式大规模训练。两个程序之间的计算要求有着数量级的区别。\r\n\r\n最后夸夸这个会玩DotA的AI，到底有何精彩之处？\r\n\r\n完全通过自学训练\r\n\r\nAI不需要任何训练数据，也不会从人类的比赛中学习。整个学习过程随机开始，并且通过和自己对抗进行学习。虽然这不是什么新技术，但令人惊讶的是，AI学会了人类玩家已经在使用的技术。这很酷。\r\n\r\nAI可能还有其他技术，甚至人类都不知道。这与我们在AlphaGo中看到的类似，围棋选手已经开始学习AI的下棋方式。\r\n\r\nAI+电竞的重要一步\r\n\r\n在具有挑战性的环境中（例如DotA 2和星际2）来测试AI技术是非常重要的。AI可以为游戏提供更多的价值，游戏也会助推AI更快发展。\r\n\r\n不完美信息\r\n\r\n在DotA对决中，人类玩家智能看到地图的一小部分，视线受到妨碍。AI可能也一样，虽然还不清楚OpenAI如何处理这个问题的细节。\r\n\r\n这意味着与围棋、国际象棋、Atari游戏机等环境不同，AI在DotA中处于一个部分可观察的环境，而无法获知关于游戏当前状态的完整信息。这类问题通常难以解决，话虽如此，但目前还不清楚1v1的DotA 2比赛中，视野的重要性到底几何。\r\n\r\n不管怎样，非常期待看到OpenAI关于这次比赛的技术报告。','2017-08-14 02:56:00','2017-08-14 02:57:01',1000,'uploads/dota2.jpg','published',2,4),(18,'下次你看到的烂片，可能是人工智能写的剧本',NULL,'— “他既坐在地板上，又身处星空之中。”\r\n\r\n— “他看着我，又移开了目光。”\r\n\r\n\r\n\r\n如果你在电影节看到一部有上述台词的短片，一定会认为这是哪位新锐编剧撰写的实验性作品。\r\n\r\n你猜对了一半，这的确是一部实验性作品，可它的编剧不是人类，而是人工智能。\r\n\r\n在去年的伦敦科幻电影节（ Sci-Fi London Film Festival），有一项48小时内电影创作挑战”，主办方提供随机的名字和一小段对话，参与者根据这些信息，在48小时内撰写出剧本并拍摄出来。\r\n\r\n拥有上述台词的短片，是导演Oscar Sharp和人工智能编剧Benjamin的作品。\r\n\r\n在这部短片中，三位主角穿着Cult十足的未来服装，说着毫无逻辑的台词。剧情似乎是一段三角恋情，还涉及了谋杀。台词中重复出现了很多次“I don\'t know”、“What do you mean”，似乎剧中人物也和观众一样，不能理解其他角色说的话。这一有趣的现象似乎是人工智能的“左右互搏”。\r\n\r\n其实实现这一功能所用的技术很简单，只需一个基于长短期记忆（LSTM）的神经网络模型，然后输入大量文本，人工智能就可以“学会”写作。Benjamin正是被输入了大量上世纪90年代的科幻电影，最后写出了这部作品。\r\n\r\nLSTM作为时间递归神经网络的一种，能够判断信息是否有用，将有用的信息记住，没有用的“遗忘”，适合于处理和预测时间序列中间隔和延迟相对较长的重要事件。\r\n\r\n\r\n\r\n所以，基于LSTM算法生成的文本更具有原创性，而不是单纯的语料重新排列组合。黑镜中描写的人工智能学习逝者社交网站资料后“成为”逝者，或是最近很火的微软小冰出诗集，很有可能都应用了这种技术。\r\n\r\n当然，LSTM算法目前还存在着不少问题，比如需要大量内存来“储存记忆”，当内存有限时，一些很重要的信息同样也会被遗忘掉。这就导致虽然Benjamin读了大量剧本，但出产的作品依然有些不伦不类。\r\n\r\n又比如对一些于无法预测的词汇，LSTM表现的很无力，这就导致了Benjamin不会给剧中人物起名字，而是用H、C等字母代替。\r\n\r\n总之，剧本这种涉及到情节逻辑、对话、人物动作等等多种元素的长文本对于LSTM而言还是太复杂，到了诗歌、对话、歌词等等领域，LSTM的表现更好。\r\n\r\n\r\n（同一题材，很难分辨两个作品哪个出自AI之手）\r\n\r\n虽然普通人对于这部短剧欣赏不来，但艺术届有不少人给予了这部短片很高的平价。人工智能对于人类感情、科技认知的理解就如同上世纪欧美导演对于东方的想象——充满了夸张、错位和疏离感。和知名的Cult片《上海异人娼馆》中，对老上海的荒诞想象有异曲同工之处。\r\n\r\n\r\n\r\n在电影节上，有人甚至将这部作品和《等待戈多》作比对，对于导演和编辑来说这已经是无上的荣耀。不过从观众的角度来看，这部作品和《等待戈多》最大的共同点就是都让人看不懂。\r\n\r\n总之，让人工智能代替人写剧本目前来看是有点困难，但在创作中，人工智能是个很好的协作者。尤其在信息的总结、提炼、归纳方面，人工智能的效率比人类要高很多。让我们看几千部科幻片，可能要花上几个月的时间，可对于Benjamin，也就是几个小时的事。\r\n\r\n对于那些天天在网文网站读千篇一律的小说，从中挑出优胜作品的编辑来说，或许很快就能被人工智能拯救。同样，在IP挑选、比赛作品筛选等等需要耗费大量时间观看/阅读作品的工作中，未来也会有人工智能的一席之地。','2017-08-14 02:57:00','2017-08-14 03:03:20',1000,'uploads/movie.jpg','published',2,4),(19,'盒马鲜生在扩张，但步调别乱很重要',NULL,'云的新儿子盒马鲜生已经超过一岁半了，到今天，在全国也陆陆续续开了 15 家门店。 \r\n\r\n但它开始受到的关注突然飙升，还是在今年 7 月 14 日。随着马云站在宣传牌下不住点头「太好吃了，要带到飞机上去慢慢吃」视频的流传，以及天猫官博的官宣，这个品牌终于被推到了聚光灯下。\r\n\r\n\r\n\r\n 盒马鲜生原本是上海本地的一家生鲜超市，由前京东物流总监侯毅创立，并在 2016 年 3 月完成了阿里的 1.5 亿美元融资。\r\n\r\n 体验：线上如切丝，线下如抽丝 \r\n\r\n如侯毅所说，盒马鲜生是「四不像模式」，既是线下的超市、餐饮店，又是线上的电商和外卖。\r\n\r\n 爱范儿下载了 app，也去了线下门店，体验了一段时间。 \r\n\r\n\r\n\r\napp 端分类页面简洁清爽，寻找自己想要的商品也不费劲，下单后直接付款即可，与其他电商 app 上的购买操作无异。不过与最初所宣传的半小时内送达不同，现在似乎调整为了最快 1h 内送达，我两次购买都花了大概 40min 到 1h 的送达时间。 \r\n\r\n\r\n\r\n也可以提前预约晚点送到，最晚支持 21 点送达。 \r\n\r\n个人感觉较为特别的一点是：没有起送价门槛，且统一包邮。即使只买一包 2 块钱的小白菜，依然免配送费送上门。 \r\n\r\n总结就是，在线上的体验如切丝般利落爽快，手起刀落，手就已经剁了…… \r\n\r\n然而，与畅快的线上购买体验相对应的，却是如抽丝般杂乱而消耗耐心的线下体验。\r\n\r\n以北京十里堡店的海鲜现场加工为例。\r\n\r\n（北京十里堡店最简略版过程）\r\n\r\n下电梯进入盒马地盘之后，先去左上角位置找一个站在接待台前的人，与之交流表明需要排队（加工食物的队列），道具排号纸+1。\r\n\r\n官方指引写的是先选购海鲜，再拿号排队，不过由于人太多了，所以即使先拿号再选购也不用担心过号。\r\n\r\n折返，寻找购物篮（可省略）。前往海鲜区，拨开人群见蟹明。但总会发现其中许多商品是不可现场烹饪的。\r\n\r\n\r\n\r\n最后发现可选范围剩生蚝鲍鱼某某鱼、龙虾大虾皮皮虾和蟹这几大类生猛海鲜。选购之后，折返到海鲜区中区右边一个有电子秤的小角落，排队上秤。\r\n\r\n再走到海鲜区和加工区的夹角，等待叫号的工作人员喊到你的号码。如果你运气好，也许会听到「78、78 有没有……79 呢……80 有没有？」这种一分钟过 6 个号以上的情况。\r\n\r\n\r\n\r\n等叫到你的号码，就可以放到加工区一端，拿到感应器，然后……才是开始真正的漫长等待时间。\r\n等到加工完毕，把熟食带到附近落座区，找到空座位，就算通关了。\r\n\r\n\r\n\r\n第一次去的人也许会更辛苦一些，因为现场人多，关键性过关地点也都分布较散，不容易一眼看到。\r\n除了海鲜加工，附近还有小火锅、原麦山丘等餐饮可选，饿了的时候也可以选择。\r\n\r\n用户定位和购买场景是什么？\r\n\r\n显然，盒马对于线上的重视高于线下，这一点从门店中随处可见的 app 下载引导牌也可以看出来。\r\n门店的地址也不像其他餐饮店一样设在大型商场，而是设在密集居民区附近，与「3 公里内配送」相契合。\r\n\r\n就线下购物行为而言，你很难想象，除了阿里本身带来的 IP 流量，顾客还有多少理由会选择去盒马的线下门店。\r\n\r\n单纯想吃熟食嘛，盒马的优势就只有价格了。可选食物范围窄、等待时间长、服务质量差、流程繁琐、座位不足……这些原因，都足以使得顾客出门左转，找家烤肉或者羊蝎子直接入座等吃了。\r\n\r\n如果是想购买生鲜产品，在手机下单绝对比跑到店里选购要来得省力甚至省时。\r\n另外，由于其选址和服务模式的原因，「逛完街买完衣服顺便找点吃的」这种情况不会很多。\r\n\r\n那么线下门店的最主要作用就只有两点了：展示商品，使得顾客能直观地看到商品质量并现场体验尝鲜；一个带有仓储功能的配送中心。\r\n\r\n侯毅说过，未来他们将会在中国开设 2000 家以上门店，并采用自营 + 合资的方式。\r\n\r\n通过这 2000 家以上的门店，他们可以覆盖到足够的居民区，成为越来越多人在回到家之前提前买菜的电商渠道选择之一。\r\n\r\n这是线下门店天花板下方的传送带，用户在 app 下单之后，商品会被送上传送带，进行打包分派，以保证配送的效率。\r\n\r\n商品的包装也都是有固定规格的，常见 300g 装、500g 装，适合小家庭。\r\n参考这些设定选择，一个最典型普通的盒马用户场景应该是这样的：一对收入尚可、对价格不敏感但对食物品质要求较高的小情侣或者小夫妻，在下班时先提前在网上下单，买好今晚的菜和水果，如果想起家里刚好至今用完了，也可以顺便加进购物车，反正免邮费送上门。\r\n\r\n对老年人就没那么友好了。线上端自不必说，学会一个新 app 的操作逻辑对许多长辈来说不是件易事。但就连线下门店随处可见的二维码都在彰显着：我们主要服务互联网人群。想要现金支付？哎好吧好吧，那就开个特殊通道吧。\r\n\r\n实际上，现在还是有许多大家庭都是子女上班，退休的父母出街买菜做饭，盒马无疑将这部分用户落下了。虽说可以年轻人先在手机下单买好，爸妈在家等快递，但总归还是没有传统的线下菜市场方便。\r\n\r\n结合近日央媒对「无现金」一词的指导，盒马线下门店的支付方式也许会进一步放宽，「等等老年人」。\r\n\r\n是噱头还是趋势？\r\n\r\n2011 年 2 月，IT 风险投资人约翰 · 杜尔 (John Doerr) 提出了新概念 SoLoMo，指 Social (社交的)、Local (本地的)、Mobile (移动的)三种概念混合的产物。随后这一概念风靡全球，被人们认定为互联网未来的发展趋势。\r\n\r\n发微博也要签个到添加位置可以算一个例子。虽然就我个人而言，我还是宁愿把陌生人社交和隐私相关的信息分得开一点。\r\n\r\n在去年的云栖大会上，马云也说过这样一段话，将另一个概念带了出来：\r\n纯电商时代很快会结束，未来的十年、二十年，没有电子商务这一说，只有新零售这一说，也就是说线上线下和物流必须结合在一起，才能诞生真正的新零售，线下的企业必须走到线上去，线上的企业必须走到线下来，线上线下加上现代物流合在一起，才能真正创造出新的零售起来。\r\n\r\n这一理念与 SoLoMo 概念正好相契合。他认为，未来的线上和线下必须结合在一起，而盒马也正是他铺出「新零售」这一概念之后重要的第一步。\r\n\r\n然而，其实做到了线上与线下相结合的，不止盒马鲜生一个。\r\n\r\n早在 2015 年，多点（Dmall）便成立并覆盖许多城市了，收纳华润、物美、美廉美、新一佳等商超，2 小时送达；\r\n永辉也在线下已经稳定的基础之上，推出了「超级物种」，30 分钟送达；\r\n京东到家以第三方入驻的方式，直接对接顾客与各大小生鲜提供商，从沃尔玛到某菜园都有，配送时间大多维持在 40min – 50min。\r\n\r\n再加上本来生活、每日优鲜等生鲜电商，刚开了 15 家店还只送 3km 范围内的盒马面临的竞争非常激烈。\r\n\r\n对它而言，现阶段手里最大的牌也就是互联网概念、商品品质以及马云的脸了。\r\n\r\n\r\n（图自：天猫官博）\r\n\r\n概念令人新鲜，名人带来关注流量，大企业抬高心理预期，而「有盒马购新鲜」这句 slogan，才是最能吸引消费者持续购买的原因。\r\n\r\n在一到高峰期外卖就可能迟到的这种大背景之下，当客户群体不断发展壮大，门店也加快扩张时，盒马配送团队的送达时间能否一直保持稳定的物流能力？而在线下门店中晾着被挑挑拣拣的蔬果们，以及被放进购物篮又扔回水池的海鲜们，又能否足够坚强地保持着悦人的挺拔体态？\r\n\r\n如果盒马能把新鲜和快速送达执行到底，甚至使得消费者出现「在盒马买绝对不用担心失望」的认知，它在众多生鲜电商中将会是不可取代的一位。但如果管理上出现问题，物流或是商品品质没跟上，漫天的差评便会袭来。\r\n\r\n如何在稳步扩张的同时不失了步调，是盒马现在需要重视的问题。','2017-08-14 03:03:00','2017-08-14 03:04:01',1000,'uploads/hema.jpg','published',2,4);
/*!40000 ALTER TABLE `bbs_article` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bbs_category`
--

DROP TABLE IF EXISTS `bbs_category`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bbs_category` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(64) COLLATE utf8_unicode_ci NOT NULL,
  `brief` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `set_as_top_menu` tinyint(1) NOT NULL,
  `position_index` smallint(6) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `name` (`name`)
) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bbs_category`
--

LOCK TABLES `bbs_category` WRITE;
/*!40000 ALTER TABLE `bbs_category` DISABLE KEYS */;
INSERT INTO `bbs_category` VALUES (1,'全部','',1,1),(2,'42区','',1,2),(3,'段子','',1,3),(4,'图片','',1,4),(5,'挨踢1024','',1,5),(6,'你问我答','',1,6);
/*!40000 ALTER TABLE `bbs_category` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bbs_category_admins`
--

DROP TABLE IF EXISTS `bbs_category_admins`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bbs_category_admins` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `category_id` int(11) NOT NULL,
  `userprofile_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `bbs_category_admins_category_id_bfda4129_uniq` (`category_id`,`userprofile_id`),
  KEY `bbs_category_admins_9c2a73e9` (`userprofile_id`),
  KEY `bbs_category_admins_b583a629` (`category_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bbs_category_admins`
--

LOCK TABLES `bbs_category_admins` WRITE;
/*!40000 ALTER TABLE `bbs_category_admins` DISABLE KEYS */;
/*!40000 ALTER TABLE `bbs_category_admins` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bbs_comment`
--

DROP TABLE IF EXISTS `bbs_comment`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bbs_comment` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `comment_type` int(11) NOT NULL,
  `comment` text COLLATE utf8_unicode_ci,
  `date` datetime NOT NULL,
  `article_id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  `parent_comment_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `bbs_comment_3a87a439` (`parent_comment_id`),
  KEY `bbs_comment_a00c1b00` (`article_id`),
  KEY `bbs_comment_e8701ad4` (`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=94 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bbs_comment`
--

LOCK TABLES `bbs_comment` WRITE;
/*!40000 ALTER TABLE `bbs_comment` DISABLE KEYS */;
INSERT INTO `bbs_comment` VALUES (1,2,'','2016-06-10 11:10:12',1,2,NULL),(2,2,'','2016-06-10 11:10:14',2,2,NULL),(3,2,'','2016-06-10 11:10:15',3,2,NULL),(5,2,'','2016-06-10 11:10:17',5,2,NULL),(6,2,'','2016-06-10 11:10:19',6,2,NULL),(8,2,'','2016-06-10 11:10:22',8,2,NULL),(9,2,'','2016-06-10 11:10:23',9,2,NULL),(10,2,'','2016-06-10 11:10:23',9,2,NULL),(11,2,'','2016-06-10 11:10:23',9,2,NULL),(12,2,'','2016-06-10 11:10:24',10,2,NULL),(13,2,'','2016-06-10 11:10:25',10,2,NULL),(14,2,'','2016-06-10 11:10:25',10,2,NULL),(15,2,'','2016-06-10 11:10:25',10,2,NULL),(16,2,'','2016-06-10 11:10:25',10,2,NULL),(17,2,'','2016-06-10 11:10:25',10,2,NULL),(18,2,'','2016-06-10 11:10:26',9,2,NULL),(19,2,'','2016-06-10 11:10:26',9,2,NULL),(20,2,'','2016-06-10 11:10:28',8,2,NULL),(21,2,'','2016-06-10 11:10:28',8,2,NULL),(22,2,'','2016-06-10 11:10:28',8,2,NULL),(27,2,'','2016-06-10 11:10:31',6,2,NULL),(28,2,'','2016-06-10 11:10:31',6,2,NULL),(29,2,'','2016-06-10 11:10:31',6,2,NULL),(30,2,'','2016-06-10 11:10:32',5,2,NULL),(31,2,'','2016-06-10 11:10:32',5,2,NULL),(32,2,'','2016-06-10 11:10:33',5,2,NULL),(33,2,'','2016-06-10 11:10:33',5,2,NULL),(34,2,'','2016-06-10 11:10:33',5,2,NULL),(35,2,'','2016-06-10 11:10:34',1,2,NULL),(36,2,'','2016-06-10 11:10:34',1,2,NULL),(37,2,'','2016-06-10 11:10:35',1,2,NULL),(38,2,'','2016-06-10 11:10:35',1,2,NULL),(39,2,'','2016-06-10 11:10:35',1,2,NULL),(40,2,'','2016-06-10 11:10:36',2,2,NULL),(41,2,'','2016-06-10 11:10:36',2,2,NULL),(42,2,'','2016-06-10 11:10:36',2,2,NULL),(43,2,'','2016-06-10 11:10:36',2,2,NULL),(44,2,'','2016-06-10 11:10:37',2,2,NULL),(45,2,'','2016-06-10 11:10:37',2,2,NULL),(46,2,'','2016-06-10 11:10:37',2,2,NULL),(47,2,'','2016-06-10 11:10:38',3,2,NULL),(48,2,'','2016-06-10 11:10:38',3,2,NULL),(49,2,'','2016-06-10 11:10:38',3,2,NULL),(50,2,'','2016-06-10 11:10:39',3,2,NULL),(51,2,'','2016-06-10 11:10:39',3,2,NULL),(52,2,'','2016-06-10 11:10:39',3,2,NULL),(53,2,'','2016-06-10 11:10:39',3,2,NULL),(59,1,'是吗颠三倒四','2016-06-10 11:11:00',1,2,NULL),(60,1,'第三方地方地方','2016-06-10 11:11:31',1,1,NULL),(61,1,'附近的妇科地方','2016-06-10 11:13:39',2,2,NULL),(62,1,'的纷纷扰扰','2016-06-10 11:13:50',2,2,NULL),(63,1,'房东夫妇地方','2016-06-10 11:14:22',2,2,NULL),(64,1,'颠三倒四舒服','2016-06-10 11:15:18',2,2,NULL),(65,1,'会更好更好','2016-06-10 11:16:53',2,2,NULL),(66,1,'ok了吧是当时的时代','2016-06-10 11:18:49',2,2,61),(67,1,'可以第三季度结束的','2016-06-10 11:19:44',1,1,59),(68,1,'顺便带上圣诞节咖啡','2016-06-10 11:19:52',1,1,60),(69,1,'大是大非没得放假诶哦热热','2016-06-10 11:19:59',1,1,68),(70,1,'都开始了热熔胶哦儿','2016-06-10 11:20:04',1,1,69),(71,1,'拉达梅斯柳德米拉时代','2016-06-10 11:20:12',1,1,68),(72,1,'电脑上看电脑看斯诺克','2016-06-10 11:20:23',1,1,60),(73,1,'今年可能看见吃的饭','2016-06-10 11:20:52',1,3,NULL),(74,1,'嗯我肯看见我呢我','2016-06-10 11:20:58',1,3,71),(75,1,'哦交融而哦儿','2016-06-10 11:21:06',1,3,NULL),(76,1,'那是你的可能我就饿北京','2016-06-10 11:21:11',1,3,60),(77,1,'上电脑课上你的课','2016-06-10 11:21:18',1,3,59),(78,1,'可牛屙 hi 次代表乌俄吧','2016-06-10 11:21:24',1,3,67),(79,1,'可我呢为全额我','2016-06-10 11:21:50',1,4,76),(80,1,'京东问 i 我呢哦为','2016-06-10 11:21:55',1,4,70),(81,1,'in 单位 i 俄拟对你的呢人','2016-06-10 11:22:07',2,4,62),(82,1,'大模 is 你都 i 而您如同认同','2016-06-10 11:22:13',2,4,63),(83,1,'皇帝是男的你嗯热','2016-06-10 11:22:17',2,4,82),(84,1,'你不低浓度年历史的饭','2016-06-10 11:22:22',2,4,64),(85,1,'谁能懂儿聊天没有人讨厌','2016-06-10 11:22:27',2,4,65),(86,1,'纳斯达克都能发光','2016-06-10 11:22:37',3,4,NULL),(87,1,'美佛儿就哦儿儿女','2016-06-10 11:22:43',3,4,86),(88,1,'默契农委哦嗯为','2016-06-10 11:22:47',3,4,86),(89,1,'男的哦是弄嗯日日天','2016-06-10 11:22:52',3,4,88),(90,1,'那我弄内容儿','2016-06-10 11:22:57',3,4,86),(91,1,'当你 i 热闹嗯突然标题日本','2016-06-10 11:23:04',3,4,NULL),(92,1,'嗯，感觉不错 啊，哈哈只只只只人','2017-08-14 07:36:01',19,2,NULL),(93,1,'你好啊啊啊承在厅枯椅s','2017-08-14 07:36:29',17,2,NULL);
/*!40000 ALTER TABLE `bbs_comment` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bbs_userprofile`
--

DROP TABLE IF EXISTS `bbs_userprofile`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bbs_userprofile` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `signature` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `head_img` varchar(100) COLLATE utf8_unicode_ci DEFAULT NULL,
  `user_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `user_id` (`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bbs_userprofile`
--

LOCK TABLES `bbs_userprofile` WRITE;
/*!40000 ALTER TABLE `bbs_userprofile` DISABLE KEYS */;
INSERT INTO `bbs_userprofile` VALUES (1,'Alex Li','','uploads/head1_M6phtgg.jpg',2),(2,'管理员','','uploads/head2_5dMmZtG.jpg',1),(3,'Eric Wang','','uploads/head6.jpg',3),(4,'曾春云','','uploads/head8.jpg',4);
/*!40000 ALTER TABLE `bbs_userprofile` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_admin_log`
--

DROP TABLE IF EXISTS `django_admin_log`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `django_admin_log` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `object_id` text COLLATE utf8_unicode_ci,
  `object_repr` varchar(200) COLLATE utf8_unicode_ci NOT NULL,
  `action_flag` smallint(5) unsigned NOT NULL,
  `change_message` text COLLATE utf8_unicode_ci NOT NULL,
  `content_type_id` int(11) DEFAULT NULL,
  `user_id` int(11) NOT NULL,
  `action_time` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `django_admin_log_417f1b1c` (`content_type_id`),
  KEY `django_admin_log_e8701ad4` (`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=110 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_admin_log`
--

LOCK TABLES `django_admin_log` WRITE;
/*!40000 ALTER TABLE `django_admin_log` DISABLE KEYS */;
INSERT INTO `django_admin_log` VALUES (1,'1','全部',1,'已添加。',9,1,'2016-06-10 10:49:26'),(2,'2','42区',1,'已添加。',9,1,'2016-06-10 10:49:59'),(3,'3','段子',1,'已添加。',9,1,'2016-06-10 10:50:09'),(4,'4','图片',1,'已添加。',9,1,'2016-06-10 10:50:19'),(5,'5','挨踢1024',1,'已添加。',9,1,'2016-06-10 10:50:34'),(6,'6','你问我答',1,'已添加。',9,1,'2016-06-10 10:50:44'),(7,'2','alex',1,'已添加。',4,1,'2016-06-10 10:51:24'),(8,'3','eric',1,'已添加。',4,1,'2016-06-10 10:51:45'),(9,'1','Alex Li',1,'已添加。',10,1,'2016-06-10 10:52:36'),(10,'2','管理员',1,'已添加。',10,1,'2016-06-10 10:52:52'),(11,'3','Eric Wang',1,'已添加。',10,1,'2016-06-10 10:53:26'),(12,'1','分答的世界尽头与冷酷仙境',1,'已添加。',7,1,'2016-06-10 10:55:54'),(13,'2','《大圣归来》之后为何没再出动画爆款？细数中国动画产业背后的尴尬',1,'已添加。',7,1,'2016-06-10 10:57:14'),(14,'4','zengchunyun',1,'已添加。',4,1,'2016-06-10 10:57:47'),(15,'4','曾春云',1,'已添加。',10,1,'2016-06-10 10:58:31'),(16,'3','考拉FM大裁员，印证了移动电台的寒冬？',1,'已添加。',7,1,'2016-06-10 10:59:53'),(17,'4','在微信朋友圈看不到真诚？这些社交App让你不用装',1,'已添加。',7,1,'2016-06-10 11:00:40'),(18,'5','为什么看好直播+电商？这里有两大理由，以及四个技术难题',1,'已添加。',7,1,'2016-06-10 11:01:44'),(19,'6','我们迎来了不仅答案不对，连问题都不对的时代',1,'已添加。',7,1,'2016-06-10 11:02:45'),(20,'7','开课 | 链家副总陶红兵：我来揭示「购房雷区及资产增值的秘密」',1,'已添加。',7,1,'2016-06-10 11:04:17'),(21,'8','《魔兽》之后或许是《英雄联盟》',1,'已添加。',7,1,'2016-06-10 11:05:28'),(22,'9','暴雪的秘密',1,'已添加。',7,1,'2016-06-10 11:06:33'),(23,'10','把人脑比做计算机，让意识永生？半个世纪我们都错了？',1,'已添加。',7,1,'2016-06-10 11:07:27'),(24,'15','无人驾驶客机能为航空业省350亿美元 有人敢坐吗',1,'[{\"added\": {}}]',7,1,'2017-08-13 15:17:51'),(25,'16','机器人致人类失业系列！这次是超市的补货员',1,'[{\"added\": {}}]',7,1,'2017-08-14 02:22:45'),(26,'7','开课 | 链家副总陶红兵：我来揭示「购房雷区及资产增值的秘密」',3,'',7,1,'2017-08-14 02:33:27'),(27,'17','击败了DotA2顶级玩家，这意味着AI的又一次突破吗？',1,'[{\"added\": {}}]',7,1,'2017-08-14 02:57:01'),(28,'18','下次你看到的烂片，可能是人工智能写的剧本',1,'[{\"added\": {}}]',7,1,'2017-08-14 03:03:21'),(29,'19','盒马鲜生在扩张，但步调别乱很重要',1,'[{\"added\": {}}]',7,1,'2017-08-14 03:04:01'),(30,'4','在微信朋友圈看不到真诚？这些社交App让你不用装',3,'',7,1,'2017-08-14 03:04:26'),(31,'16','机器人致人类失业系列！这次是超市的补货员',3,'',7,1,'2017-08-14 03:04:56'),(32,'15','无人驾驶客机能为航空业省350亿美元 有人敢坐吗',3,'',7,1,'2017-08-14 03:05:21');
/*!40000 ALTER TABLE `django_admin_log` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_content_type`
--

DROP TABLE IF EXISTS `django_content_type`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `django_content_type` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `app_label` varchar(100) COLLATE utf8_unicode_ci NOT NULL,
  `model` varchar(100) COLLATE utf8_unicode_ci NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `django_content_type_app_label_76bd3d3b_uniq` (`app_label`,`model`)
) ENGINE=InnoDB AUTO_INCREMENT=17 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_content_type`
--

LOCK TABLES `django_content_type` WRITE;
/*!40000 ALTER TABLE `django_content_type` DISABLE KEYS */;
INSERT INTO `django_content_type` VALUES (1,'admin','logentry'),(16,'aitutorial','aiarticle'),(3,'auth','group'),(2,'auth','permission'),(4,'auth','user'),(7,'bbs','article'),(9,'bbs','category'),(8,'bbs','comment'),(10,'bbs','userprofile'),(5,'contenttypes','contenttype'),(6,'sessions','session');
/*!40000 ALTER TABLE `django_content_type` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_migrations`
--

DROP TABLE IF EXISTS `django_migrations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `django_migrations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `app` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  `name` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  `applied` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=18 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_migrations`
--

LOCK TABLES `django_migrations` WRITE;
/*!40000 ALTER TABLE `django_migrations` DISABLE KEYS */;
INSERT INTO `django_migrations` VALUES (1,'contenttypes','0001_initial','2016-06-10 10:45:57'),(2,'auth','0001_initial','2016-06-10 10:45:57'),(3,'admin','0001_initial','2016-06-10 10:45:57'),(4,'admin','0002_logentry_remove_auto_add','2016-06-10 10:45:57'),(5,'contenttypes','0002_remove_content_type_name','2016-06-10 10:45:57'),(6,'auth','0002_alter_permission_name_max_length','2016-06-10 10:45:57'),(7,'auth','0003_alter_user_email_max_length','2016-06-10 10:45:57'),(8,'auth','0004_alter_user_username_opts','2016-06-10 10:45:57'),(9,'auth','0005_alter_user_last_login_null','2016-06-10 10:45:57'),(10,'auth','0006_require_contenttypes_0002','2016-06-10 10:45:57'),(11,'auth','0007_alter_validators_add_error_messages','2016-06-10 10:45:57'),(12,'bbs','0001_initial','2016-06-10 10:45:57'),(13,'sessions','0001_initial','2016-06-10 10:45:57'),(14,'auth','0008_alter_user_username_max_length','2017-08-13 15:18:24');
/*!40000 ALTER TABLE `django_migrations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_session`
--

DROP TABLE IF EXISTS `django_session`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `django_session` (
  `session_key` varchar(40) COLLATE utf8_unicode_ci NOT NULL,
  `session_data` text COLLATE utf8_unicode_ci NOT NULL,
  `expire_date` datetime NOT NULL,
  PRIMARY KEY (`session_key`),
  KEY `django_session_de54fa62` (`expire_date`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_session`
--

LOCK TABLES `django_session` WRITE;
/*!40000 ALTER TABLE `django_session` DISABLE KEYS */;
INSERT INTO `django_session` VALUES ('5amttw38p7gtm8mm3s9onok2b9gb6009','MmIzZjhmYTk3OTUyMDkwNTBmMmE2MDZkZjY5MWFkNTJjNzAyZWZkYjp7Il9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9oYXNoIjoiZDAzNzY4ODgyM2EyYmI2N2E4NWEyN2Y3MmUyMjEzYTFjYjU5YzY2YyIsIl9hdXRoX3VzZXJfaWQiOiI0In0=','2016-06-24 11:21:39'),('i8eugffwehgp609t68g1o6qpuhw9san6','MTU3MGYxZThlZGY0MjJkNmE0NzZhNWNjNTQ0ZGMzNzc3NTZkMWY0NTp7Il9hdXRoX3VzZXJfaGFzaCI6IjMyNzU1MGE4ODg0NWM2NjgyNjI3ZGIwMjc5NGViYTY3Yjc1M2MyOWIiLCJfYXV0aF91c2VyX2JhY2tlbmQiOiJkamFuZ28uY29udHJpYi5hdXRoLmJhY2tlbmRzLk1vZGVsQmFja2VuZCIsIl9hdXRoX3VzZXJfaWQiOiIxIn0=','2017-08-27 08:59:05'),('ouyjljboz54wcg7onhjpmjn2wjjjd6fv','MTU3MGYxZThlZGY0MjJkNmE0NzZhNWNjNTQ0ZGMzNzc3NTZkMWY0NTp7Il9hdXRoX3VzZXJfaGFzaCI6IjMyNzU1MGE4ODg0NWM2NjgyNjI3ZGIwMjc5NGViYTY3Yjc1M2MyOWIiLCJfYXV0aF91c2VyX2JhY2tlbmQiOiJkamFuZ28uY29udHJpYi5hdXRoLmJhY2tlbmRzLk1vZGVsQmFja2VuZCIsIl9hdXRoX3VzZXJfaWQiOiIxIn0=','2018-02-16 12:38:11');
/*!40000 ALTER TABLE `django_session` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2018-10-21 15:45:23
